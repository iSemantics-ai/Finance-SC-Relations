{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas openai torch scikit-learn dvc dvc-s3\n",
    "#!pip install openpyxl retry python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_concept_finder = \"\"\"Your task is to find the concepts expressed in the sentences from the below concepts\n",
    "\n",
    "# Information on concepts\n",
    "-  Concepts are like classification labels for classification making the concepts more general and less descriptive of individual sentences. \n",
    "\n",
    "# List of concepts in { }, seperated by comma -  \n",
    "{ 'investments in another company',  'financial statements', 'buy or sale of shares' , 'sale of assets',  'financing or loans',  'mergers or acquisitions', \n",
    "'supply or purchase agreement', 'services agreement',  'exclusive rights or agreement',  'changes in agreement', \n",
    "'agreement with another company',  'contracts in business',  'partnership with another company',   'joint venture or development',  'receivable or payable amount to accounts', \n",
    "'outstanding payment',  'potential earnings',  'contributors to revenue ',  'sources of revenue', 'yearly revenue numbers',  'sales performance',  'impact on revenue',  'purchase of products', \n",
    "'product distributors',  'supply channels', 'supply chain',  'dependency on customers', 'outsourcing operation',  'product manufacturing',  'production or operation', \n",
    "'product description',  'product usage',  'product pricing and cost', 'product marketing', 'royalties', \n",
    "'intellectual property',  'licensing agreement',  'product licensing', 'lease agreement', 'real estate lease', 'lease transactions',  'business risks', 'regulatory compliance',  'government regulations', \n",
    "'research and development', 'legal proceedings', 'stock ownership' }\n",
    "\n",
    "\n",
    "# Rules to find the concepts\n",
    "- Strictly use only information given in the input sentences\n",
    "- Strictly find the concepts from given concepts only\n",
    "- Check all above concepts one by one if they are expressed in the sentence\n",
    "- Finally find  most relevant maximum 3 concepts that are expressed in Sentence. \n",
    "- A Sentence can have only one concept \n",
    "- Write one line explanation using the detected concepts\n",
    "\n",
    "# Output rules\n",
    "- `list of concepts` is list of detected concepts \n",
    "- Write output in json object with three keys - `index`, `concepts`, `concept explanation`\n",
    "- Output should be strict json object that can be parsed\n",
    "\n",
    "\n",
    "## output\n",
    "Return JSON list of json objects with following format given in ``` quote -\n",
    "```[\n",
    "    {'index' : '< sentence index number given in the input Sentences >' ,\n",
    "     'concepts': [ concept1, concept2, concept3] ,\n",
    "     'concept explanation': 'one line explanation'\n",
    "    }\n",
    "   ]```\n",
    "\n",
    "#Input\n",
    "Sentences are given below in tripe back quotes. they are separated by \\n and prefixed by index\n",
    "```\n",
    "{sentences}\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from typing import Tuple, List, Text, Dict\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from retry import retry\n",
    "\n",
    "\n",
    "@retry(tries=3, delay=1)\n",
    "def get_completion_2(prompt:Text,\n",
    "                        temperature:float=0,\n",
    "                        model=\"gpt-3.5-turbo\")->str:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = None\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model,\n",
    "        messages=messages,\n",
    "        temperature= temperature,    #this is the degree of randomness of the model's output\n",
    "        request_timeout = 90\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "global sent_concepts_out_star\n",
    "sent_concepts_out_star = []\n",
    "\n",
    "def generate_concepts(data: pd.DataFrame,\n",
    "                       prompt_1: Text)-> pd.DataFrame:\n",
    "    \n",
    "    batch_size = 10\n",
    "    sentences_in_batch = []\n",
    "    global sent_concepts_out_star \n",
    "    sent_concepts_out_star = []\n",
    "\n",
    "    output = []\n",
    "    # Iterate over the frame rows\n",
    "    for i, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Generating concepts\"):\n",
    "        row = row.to_dict()\n",
    "        \n",
    "        sentences_in_batch.append(f\"{row['index']}    {row['sentence']}\")\n",
    "        # continue till batch fills\n",
    "        if len(sentences_in_batch) == batch_size or i == (data.shape[0] -1):\n",
    "            sentences_txt = \"\\n\".join(sentences_in_batch)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        report_prompt_1 = copy(prompt_1)\n",
    "        report_prompt_1 = report_prompt_1.replace(\"{sentences}\", sentences_txt)\n",
    "                \n",
    "        retry_on_parse_err = False        \n",
    "        attempt_count = 0\n",
    "        while attempt_count == 0 or retry_on_parse_err:\n",
    "            try:\n",
    "                prompt_1_completion = get_completion_2(prompt=report_prompt_1)        \n",
    "                sent_concept_list = deserialize_json_list(prompt_1_completion)                      \n",
    "   \n",
    "            except:\n",
    "                # don't retry of already retried\n",
    "                if retry_on_parse_err == True:                      \n",
    "                    retry_on_parse_err = False\n",
    "                    sent_concept_list = []\n",
    "                    print(\"Not retrying after 2nd error\")\n",
    "                else:\n",
    "                    print(\"Retrying after 1st error\")\n",
    "                    retry_on_parse_err = True\n",
    "            \n",
    "            attempt_count += 1\n",
    "        \n",
    "        if sent_concept_list:\n",
    "            sent_concepts_out_star += sent_concept_list\n",
    "\n",
    "        # Reset \n",
    "        sentences_in_batch = []         \n",
    "        \n",
    "    return sent_concepts_out_star\n",
    "\n",
    "\n",
    "def deserialize_json_list(ser_relations):    \n",
    "    # the string representation of the list of dictionaries\n",
    "    string_list_of_dicts = ser_relations\n",
    "    # regular expression to match a dictionary\n",
    "    dict_regex = r\"\\{[^{}]+\\}\"\n",
    "    # find all dictionaries in the string\n",
    "    dict_strings = re.findall(dict_regex, string_list_of_dicts)\n",
    "    # deserialize each dictionary into a Python object\n",
    "    list_of_dicts = []\n",
    "    for dict_string in dict_strings:\n",
    "        try:\n",
    "            list_of_dicts.append(json.loads(re.sub(r\"(?<!\\w)'|'(?!\\w)\", '\"', dict_string)))\n",
    "        except:\n",
    "            try:\n",
    "                list_of_dicts.append(json.loads(re.sub(r\"(?<!\\w)'|'(?!\\w)\", '\"', dict_string.replace('\"', '\\\\\"'))))\n",
    "            except:\n",
    "                continue\n",
    "    return list_of_dicts\n",
    "\n",
    "\n",
    "def generate_concepts_wrapper(data):\n",
    "    \n",
    "    global sent_concepts_out_star\n",
    "    sent_concepts_out_star = []\n",
    "\n",
    "    # run prompts to find relations\n",
    "    sent_concepts_out = generate_concepts(data, prompt_concept_finder)\n",
    "    \n",
    "    sent_concepts_dict = {}\n",
    "\n",
    "    for sent_concepts in sent_concepts_out:\n",
    "        sent_concepts_dict[sent_concepts[\"index\"]] = sent_concepts\n",
    "\n",
    "    output = []  \n",
    "    for i, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        row = row.to_dict()\n",
    "        index_str = str(row[\"index\"])\n",
    "        if index_str in sent_concepts_dict:\n",
    "            row[\"concepts\"] = sent_concepts_dict[index_str][\"concepts\"]\n",
    "            row[\"concept explanation\"] = sent_concepts_dict[index_str][\"concept explanation\"]\n",
    "        else:\n",
    "            row[\"concepts\"] = []\n",
    "            row[\"concept explanation\"] = \"\"\n",
    "        \n",
    "        output.append(row)\n",
    "  \n",
    "    return pd.DataFrame(output)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['accessionnumber', 'cik', 'reporter_name', 'reported_company',\n",
       "       'sentence_id', 'sentence', 'relation', 'score', 'sents_scores',\n",
       "       'agreration_results', 'winning_relation',\n",
       "       'matched_reported_company_old', 'reported_company_old', 'old_relation',\n",
       "       'explanation', 'relation_completion', 'relations', 'llm_relation_label',\n",
       "       'llm_winning_relation', 'old_llm_align', 'new_llm_align', 'Comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f'../DemoNotebooks/test_pipeline_data/filings_gt_25_relns/final_report_conflict_with_old_relation_llm.xlsx'\n",
    "\n",
    "# Save the DataFrame to Excel\n",
    "data = pd.read_excel(file_path)  # Set index=False if you don't want to save the index as a separate column\n",
    "\n",
    "#data = data[:10]\n",
    "\n",
    "print(data.shape)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"index\"] = data.index\n",
    "output = generate_concepts_wrapper(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = f'../DemoNotebooks/test_pipeline_data/filings_gt_25_relns/final_report_conflict_with_old_relation_llm_concepts.xlsx'\n",
    "#output.to_excel(file_path, index=False)  # Set index=False if you don't want to save the index as a separate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../data_with_concepts/EXP LLM v2.3 Label_1_0 errors.xlsx\")\n",
    "output = generate_concepts_wrapper(data)\n",
    "\n",
    "\n",
    "output.to_excel(\"../data_with_concepts/EXP LLM v2.3 Label_1_0 errors.xlsx\", index=False)  # Set index=False if you don't want to save the index as a separate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3682, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating concepts: 100%|██████████| 100/100 [04:16<00:00,  2.57s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 17714.68it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:14<00:00,  1.94s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 30413.34it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:37<00:00,  1.57s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 29604.07it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:01<00:00,  1.81s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 29267.35it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:43<00:00,  1.63s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 31555.10it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:36<00:00,  1.56s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 28095.01it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:56<00:00,  1.77s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 30544.01it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:01<00:00,  1.82s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 30192.23it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:48<00:00,  1.68s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 28370.56it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:08<00:00,  1.88s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 16414.78it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:23<00:00,  2.04s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 29402.76it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:55<00:00,  1.76s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 28610.53it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:49<00:00,  1.69s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 28044.29it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:43<00:00,  1.63s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 32288.71it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:41<00:00,  2.22s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 26788.68it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [05:25<00:00,  3.25s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 23746.27it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:48<00:00,  1.68s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 26020.87it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [04:47<00:00,  2.87s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 27848.77it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:46<00:00,  1.67s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 31378.05it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [04:53<00:00,  2.94s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 21204.77it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [02:55<00:00,  1.75s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 27824.76it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:52<00:00,  2.32s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 19948.18it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:16<00:00,  1.96s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 8565.22it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:37<00:00,  2.18s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 15135.33it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:57<00:00,  2.37s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9640.53it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [04:58<00:00,  2.99s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 9167.68it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:09<00:00,  1.90s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 16260.14it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:38<00:00,  2.18s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 6910.92it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:35<00:00,  2.16s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 10128.48it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:39<00:00,  2.19s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 23224.27it/s]\n",
      "Generating concepts: 100%|██████████| 100/100 [03:28<00:00,  2.09s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 22485.95it/s]\n",
      "Generating concepts: 100%|██████████| 82/82 [02:24<00:00,  1.77s/it]\n",
      "100%|██████████| 82/82 [00:00<00:00, 21089.83it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "for start_idx in range(500, 3700, batch_size):\n",
    "    \n",
    "    data = pd.read_excel(\"../data_with_concepts/lg_sents_from_huge_set/huge_train_dedup_80_lg_sent.xlsx\")\n",
    "    data = data[start_idx:start_idx+batch_size]\n",
    "\n",
    "    output = generate_concepts_wrapper(data)\n",
    "    \n",
    "    file_path = f'../data_with_concepts/lg_sents_from_huge_set/1_batches/huge_train_dedup_80_lg_sent_{start_idx}_{start_idx+batch_size}.xlsx'\n",
    "    # # Save the DataFrame to Excel\n",
    "    output.to_excel(file_path, index=False)  # Set index=False if you don't want to save the index as a separate column\n",
    "\n",
    "\n",
    "# df_arr = [] \n",
    "\n",
    "# for start_idx in range(0, 3700, batch_size):\n",
    "#     df_arr.append(pd.read_excel(f\"../data_with_concepts/lg_sents_from_huge_set/1_batches/huge_train_dedup_80_lg_sent_{start_idx}_{start_idx+batch_size}.xlsx\"))\n",
    "    \n",
    "# output = pd.concat(df_arr, ignore_index=True)\n",
    "# output = output.sort_values(by=['index'])\n",
    "\n",
    "# file_path = '../data_with_concepts/lg_sents_from_huge_set/huge_train_dedup_80_lg_sent_concepts.xlsx'\n",
    "# output.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2609, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train cs relation concepts files\n",
    "\n",
    "data1 = pd.read_excel(\"../final_train_data/llm_relations_all_label_1_v2_3.xlsx\")\n",
    "data1 = data1[data1[\"align\"] == True][[\"index\", \"concepts\"]]\n",
    "\n",
    "data2 = pd.read_excel(\"../final_train_data/huge_train_llm_aligned_v2_3_0_1300.xlsx\")\n",
    "data2 = data2[[\"index\", \"concepts\"]]\n",
    "\n",
    "data3 = pd.read_excel(\"../final_train_data/huge_train_complex_sents_llm_v2_3.xlsx\")\n",
    "data3 = data3[data3[\"align\"] == True][[\"index\", \"concepts\"]]\n",
    "\n",
    "\n",
    "output = pd.concat([data3, data2, data3], ignore_index=True)\n",
    "output['concepts'] = output['concepts'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train other relation concepts files\n",
    "\n",
    "data1 = pd.read_excel(\"final_train_data/llm_relations_other_from_label_0_v2_3.xlsx\")\n",
    "data1 = data1[[\"index\", \"concepts\"]]\n",
    "\n",
    "data2 = pd.read_excel(\"final_train_data/llm_relations_other_relation_v2_3.xlsx\")\n",
    "data2 = data2[[\"index\", \"concepts\"]]\n",
    "\n",
    "data3 = pd.read_excel(\"final_train_data/huge_other_train_complex_sents.xlsx\")\n",
    "data3 = data3[[\"index\", \"concepts\"]]\n",
    "\n",
    "\n",
    "output = pd.concat([data1, data2, data3], ignore_index=True)\n",
    "output['concepts'] = output['concepts'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3597, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:00<00:00, 35507.17it/s]\n",
      "100%|██████████| 454/454 [00:00<00:00, 42592.24it/s]\n",
      "100%|██████████| 454/454 [00:00<00:00, 49208.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the concept_df dataframe, \n",
    "# Input - output dataframe with \"concepts\" column \n",
    "\n",
    "concept_df_dict = defaultdict(int)\n",
    "\n",
    "# 1 concept df\n",
    "for i, row in tqdm(output.iterrows(), total=output.shape[0]):   \n",
    "   for concept in row[\"concepts\"]:\n",
    "    concept_df_dict[concept] += 1\n",
    "concept_df = pd.DataFrame({'concept1': list(concept_df_dict.keys()),\n",
    "                           'df1': list(concept_df_dict.values())})\n",
    "concept_df = concept_df.sort_values(by=['df1'], ascending=False)\n",
    "#concept_df = concept_df[concept_df['df1'] > 4]\n",
    "\n",
    "# 2 concept df\n",
    "concept_df_dict = defaultdict(int)\n",
    "for i, row in tqdm(output.iterrows(), total=output.shape[0]):   \n",
    "   if len(row[\"concepts\"]) > 1:\n",
    "        concept_tuples = list(combinations(row[\"concepts\"], 2))\n",
    "        for c_tuple in concept_tuples:\n",
    "                concept_df_dict[c_tuple] += 1\n",
    "\n",
    "# Sort dictionary by values in descending order\n",
    "concept_df_dict = dict(sorted(concept_df_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# Filter dictionary by values \n",
    "concept_df_dict = {key: value for key, value in concept_df_dict.items() if value > 4}\n",
    "\n",
    "pad_list = [\"\"] * (concept_df.shape[0] - len(concept_df_dict))\n",
    "concept_df[\"concept2\"] = list(concept_df_dict.keys()) + pad_list\n",
    "concept_df[\"df2\"] = list(concept_df_dict.values()) + pad_list\n",
    "\n",
    "# 3 concept df\n",
    "concept_df_dict = defaultdict(int)\n",
    "for i, row in tqdm(output.iterrows(), total=output.shape[0]):   \n",
    "   if len(row[\"concepts\"]) > 2:\n",
    "        concept_tuples = list(combinations(row[\"concepts\"], 3))\n",
    "        for c_tuple in concept_tuples:\n",
    "                concept_df_dict[c_tuple] += 1\n",
    "\n",
    "# Sort dictionary by values in descending order\n",
    "concept_df_dict = dict(sorted(concept_df_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# Filter dictionary by values \n",
    "concept_df_dict = {key: value for key, value in concept_df_dict.items() if value > 4}\n",
    "\n",
    "pad_list = [\"\"] * (concept_df.shape[0] - len(concept_df_dict))\n",
    "concept_df[\"concept3\"] = list(concept_df_dict.keys()) + pad_list\n",
    "concept_df[\"df3\"] = list(concept_df_dict.values()) + pad_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write concept_df to file\n",
    "\n",
    "concept_df.to_excel(\"../data_with_concepts/concepts_df_test_error.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_df.to_excel(\"data_with_concepts/concepts_df_other.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence classification using detected concepts and concepts mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_classes = ['legal_and_regulatory',\n",
    " 'royalties',\n",
    " 'licensing_and_ip',\n",
    " 'real_estate',\n",
    " 'supply_purchase_agreement',\n",
    " 'services agreement',\n",
    " 'agreement_and_partnership',\n",
    " 'product_related',\n",
    " 'supply_chain',\n",
    " 'investment_related',\n",
    " 'revenue']\n",
    "\n",
    "remaining_classes = ['financial_statements', 'unknown']\n",
    "\n",
    "\n",
    "concept_class_dict = {\n",
    "    'legal_and_regulatory': {'1st_preference': ['government regulations',\n",
    "                                           'legal proceedings',\n",
    "                                           'regulatory compliance'],\n",
    "                        '2nd_preference': []},\n",
    "'royalties': {'1st_preference': ['royalties'], '2nd_preference': []},\n",
    " 'licensing_and_ip': {'1st_preference': ['exclusive rights or agreement',\n",
    "                                         'licensing agreement',\n",
    "                                         'intellectual property',\n",
    "                                         'product licensing',\n",
    "                                         'product marketing'],\n",
    "                      '2nd_preference': [\"research and development\"]},\n",
    " 'real_estate': {'1st_preference': ['lease agreement',\n",
    "                                    'lease transactions',\n",
    "                                    'real estate lease'],\n",
    "                 '2nd_preference': []},\n",
    " 'supply_purchase_agreement': {'1st_preference': ['supply_purchase_agreement'],\n",
    "                               '2nd_preference': []},\n",
    " 'services agreement': {'1st_preference': ['services agreement'],\n",
    "                        '2nd_preference': []},                               \n",
    " 'agreement_and_partnership': {'1st_preference': ['contracts in business',\n",
    "                                    'partnership with another company',\n",
    "                                    'joint venture or development',\n",
    "                                    'collaboration agreement'],\n",
    "                 '2nd_preference': ['agreement with another company', 'changes in agreement']},\n",
    " 'product_related': {'1st_preference': ['product manufacturing',\n",
    "                                        'outsourcing operation',\n",
    "                                        'production or operation',\n",
    "                                        'product pricing and cost',\n",
    "                                        'product description'],\n",
    "                     '2nd_preference': []},\n",
    "  'supply_chain': {'1st_preference': ['supply channels',\n",
    "                                     'supply chain',\n",
    "                                     'product distributors',\n",
    "                                     'distribution agreement',\n",
    "                                     'purchase of products'],\n",
    "                  '2nd_preference': []},\n",
    "'investment_related': {'1st_preference': ['mergers or acquisitions', 'financing or loans', \n",
    "                                          'stock ownership', 'investments in another company', 'sale of assets', \n",
    "                                          'buy or sale of shares', 'acquisition', 'acquisition of another company'],\n",
    "                    '2nd_preference': []},          \n",
    "\n",
    " 'revenue': {'1st_preference': ['sources of revenue',\n",
    "                                'contributors to revenue',\n",
    "                                'yearly revenue numbers',\n",
    "                                'impact on revenue',\n",
    "                                'sales performance',\n",
    "                                'revenue recognition',\n",
    "                                'potential earnings',\n",
    "                                'receivable or payable amount to accounts',\n",
    "                                'outstanding payment',\n",
    "                                'milestone payments'],\n",
    "             '2nd_preference': ['dependency on customers']},\n",
    "\n",
    "  'financial_statements': {'1st_preference': ['financial statements'],\n",
    "                          '2nd_preference': []},\n",
    " 'unknown': {'1st_preference': [], '2nd_preference': []}\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_concept_class_from_1st_preference(sent_detected_concepts, concept_class_dict, concept_classes):\n",
    "    # strict match: check if detected_concept is part of 1st_preference of concept class\n",
    "    for detected_concept in sent_detected_concepts:\n",
    "        for concept_class in concept_classes:\n",
    "            if detected_concept in concept_class_dict.get(concept_class)[\"1st_preference\"]:\n",
    "                return concept_class\n",
    "\n",
    "def find_concept_class_from_2nd_preference(sent_detected_concepts, concept_class_dict, concept_classes):\n",
    "    # strict match: check if detected_concept is part of 2nd_preference of concept class\n",
    "    for detected_concept in sent_detected_concepts:\n",
    "        for concept_class in concept_classes:\n",
    "            if detected_concept in concept_class_dict.get(concept_class)[\"2nd_preference\"]:\n",
    "                return concept_class\n",
    "\n",
    "def find_concept_class_from_any_preference(sent_detected_concepts, concept_class_dict, concept_classes):\n",
    "    \n",
    "    # relaxed match: check if concept_class that we know is substring of detected_concept of the sentence \n",
    "    for detected_concept in sent_detected_concepts:\n",
    "        for concept_class in concept_classes:\n",
    "            for concept_class_val in (concept_class_dict.get(concept_class)[\"1st_preference\"] + \n",
    "                                      concept_class_dict.get(concept_class)[\"2nd_preference\"]):\n",
    "                    if concept_class_val in  detected_concept:                    \n",
    "                        return concept_class\n",
    "\n",
    "\n",
    "def find_concept_class(sent_detected_concepts, concept_class_dict, \n",
    "                       concept_classes, remaining_classes):\n",
    "    if not sent_detected_concepts:\n",
    "        return 'unknown'\n",
    "    \n",
    "    concept_class = find_concept_class_from_1st_preference(sent_detected_concepts, \n",
    "                                                           concept_class_dict, concept_classes) \n",
    "    if concept_class:\n",
    "        return concept_class\n",
    "    \n",
    "    concept_class = find_concept_class_from_2nd_preference(sent_detected_concepts, \n",
    "                                                           concept_class_dict, concept_classes) \n",
    "    if concept_class:\n",
    "        return concept_class\n",
    "    \n",
    "    concept_class = find_concept_class_from_any_preference(sent_detected_concepts, \n",
    "                                                           concept_class_dict, \n",
    "                                                           concept_classes + remaining_classes) \n",
    "    if concept_class:\n",
    "        return concept_class\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['concept_class'] = output['concepts'].apply(lambda sent_detected_concepts: \n",
    "#                                                  find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "#                                                                     concept_classes, remaining_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept classification for CS relation samples\n",
    "\n",
    "data1 = pd.read_excel(\"final_train_data/llm_relations_all_label_1_v2_3.xlsx\")\n",
    "data1['concepts'] = data1['concepts'].apply(eval)\n",
    "data1['concept_class'] = data1['concepts'].apply(lambda sent_detected_concepts: \n",
    "                                                 find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "                                                                    concept_classes, remaining_classes))\n",
    "data1.to_excel(\"final_train_data/llm_relations_all_label_1_v2_3.xlsx\", index=False)\n",
    "\n",
    "data2 = pd.read_excel(\"final_train_data/huge_train_llm_aligned_v2_3_0_1300.xlsx\")\n",
    "data2['concepts'] = data2['concepts'].apply(eval)\n",
    "data2['concept_class'] = data2['concepts'].apply(lambda sent_detected_concepts: \n",
    "                                                 find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "                                                                    concept_classes, remaining_classes))\n",
    "data2.to_excel(\"final_train_data/huge_train_llm_aligned_v2_3_0_1300.xlsx\", index=False)\n",
    "\n",
    "\n",
    "data3 = pd.read_excel(\"final_train_data/huge_train_complex_sents_llm_v2_3.xlsx\")\n",
    "data3['concepts'] = data3['concepts'].apply(eval)\n",
    "data3['concept_class'] = data3['concepts'].apply(lambda sent_detected_concepts: \n",
    "                                                 find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "                                                                    concept_classes, remaining_classes))\n",
    "data3.to_excel(\"final_train_data/huge_train_complex_sents_llm_v2_3.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept classification for other class\n",
    "\n",
    "data1 = pd.read_excel(\"final_train_data/llm_relations_other_from_label_0_v2_3.xlsx\")\n",
    "data1['concepts'] = data1['concepts'].apply(eval)\n",
    "data1['concept_class'] = data1['concepts'].apply(lambda sent_detected_concepts: \n",
    "                                                 find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "                                                                    concept_classes, remaining_classes))\n",
    "data1.to_excel(\"final_train_data/llm_relations_other_from_label_0_v2_3.xlsx\", index=False)\n",
    "\n",
    "data2 = pd.read_excel(\"final_train_data/llm_relations_other_relation_v2_3.xlsx\")\n",
    "data2['concepts'] = data2['concepts'].apply(eval)\n",
    "data2['concept_class'] = data2['concepts'].apply(lambda sent_detected_concepts: \n",
    "                                                 find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "                                                                    concept_classes, remaining_classes))\n",
    "data2.to_excel(\"final_train_data/llm_relations_other_relation_v2_3.xlsx\", index=False)\n",
    "\n",
    "\n",
    "data3 = pd.read_excel(\"final_train_data/huge_other_train_complex_sents.xlsx\")\n",
    "data3['concepts'] = data3['concepts'].apply(eval)\n",
    "data3['concept_class'] = data3['concepts'].apply(lambda sent_detected_concepts: \n",
    "                                                 find_concept_class(sent_detected_concepts, concept_class_dict,\n",
    "                                                                    concept_classes, remaining_classes))\n",
    "data3.to_excel(\"final_train_data/huge_other_train_complex_sents.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "revenue                      927\n",
       "agreement_and_partnership    710\n",
       "licensing_and_ip             578\n",
       "unknown                      415\n",
       "royalties                    244\n",
       "supply_chain                 208\n",
       "investment_related           145\n",
       "financial_statements         120\n",
       "services agreement           116\n",
       "product_related              103\n",
       "legal_and_regulatory          64\n",
       "real_estate                   52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3['concept_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accessionnumber', 'cik', 'reporter_name', 'reported_company',\n",
       "       'sentence_id', 'sentence', 'relation', 'score', 'sents_scores',\n",
       "       'agreration_results', 'winning_relation',\n",
       "       'matched_reported_company_old', 'reported_company_old', 'old_relation',\n",
       "       'explanation', 'relation_completion', 'relations', 'llm_relation_label',\n",
       "       'llm_winning_relation', 'old_llm_align', 'new_llm_align', 'Comment',\n",
       "       'index', 'concepts', 'concept explanation', 'concept_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns\n",
    "\n",
    "# create new df where old_relation is not matching with relation column\n",
    "# filtered_output = output[output['old_relation'] != output['relation']]\n",
    "# filtered_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "licensing_and_ip             92\n",
       "agreement_and_partnership    70\n",
       "unknown                      65\n",
       "royalties                    62\n",
       "supply_chain                 46\n",
       "product_related              35\n",
       "revenue                      33\n",
       "legal_and_regulatory         18\n",
       "financial_statements         10\n",
       "investment_related           10\n",
       "real_estate                   9\n",
       "services agreement            4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['concept_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "licensing_and_ip             76\n",
       "agreement_and_partnership    56\n",
       "royalties                    54\n",
       "unknown                      49\n",
       "supply_chain                 44\n",
       "revenue                      30\n",
       "product_related              27\n",
       "legal_and_regulatory         18\n",
       "financial_statements         10\n",
       "investment_related            8\n",
       "real_estate                   8\n",
       "services agreement            3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_output['concept_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
