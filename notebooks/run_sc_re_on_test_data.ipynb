{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1a1083",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05f8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import math\n",
    "from typing import Dict, Any, Text, Tuple\n",
    "import yaml\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fc8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61d9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac31bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine = \"local\"\n",
    "machine = \"paperspace\"\n",
    "\n",
    "if machine == \"local\":\n",
    "    src_dir= Path.cwd().parent    \n",
    "elif machine == \"paperspace\":\n",
    "    src_dir = Path(\"/notebooks/inferess-relation-extraction/\")\n",
    "\n",
    "sys.path.append(str(src_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62be0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a73bc66d749485389c9d2b633e33069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)L6-v2/resolve/main/tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ed035ec7f547fdaf0ff83b555f48da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)/all-MiniLM-L6-v2/resolve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b488734d28435aaddf13946e7492a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)MiniLM-L6-v2/resolve/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2e4c5b9a5944e0b29c8cb563211a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)-v2/resolve/main/special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e160d6381da941be931e8926f69e5585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ll-MiniLM-L6-v2/resolve/main/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb54b1d64694049bcdcfd619e667bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from src.matcher.core import SimCSE_Matcher\n",
    "entity_matcher = SimCSE_Matcher(\n",
    "        model_name_or_path=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d2236",
   "metadata": {},
   "source": [
    "### Test set from annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339ee9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_relationships_sentences = pd.read_csv(\"test_pipeline_data/labeled-relationships/labeled-relationships-sentences_pos_entity_in_sentence.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233b560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['key', 'company_name', 'related_entity', 'relationship_type',\n",
      "       'sentence'],\n",
      "      dtype='object')\n",
      "(150228, 5)\n",
      "(6775, 5)\n"
     ]
    }
   ],
   "source": [
    "print(labeled_relationships_sentences.columns)\n",
    "\n",
    "print(labeled_relationships_sentences.shape)\n",
    "\n",
    "# find unique count on company_name and related_entity\n",
    "print(labeled_relationships_sentences.drop_duplicates(subset=[\"key\", \"related_entity\"]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug - check overlap in positive and negative samples\n",
    "\n",
    "# # form join_id by joining all keys except sentence\n",
    "# labeled_relationships_sentences[\"join_id\"] = labeled_relationships_sentences.apply(lambda x: \"_\".join([str(x[k]) for k in x.keys() if k != \"sentence\"]), axis=1)\n",
    "# labeled_relationships_sentences_neg[\"join_id\"] = labeled_relationships_sentences_neg.apply(lambda x: \"_\".join([str(x[k]) for k in x.keys() if k != \"sentence\"]), axis=1)\n",
    "\n",
    "# labeled_relationships_sentences[\"acc_join_id\"] = labeled_relationships_sentences.apply(lambda x: \"_\".join([str(x[k]) for k in x.keys() if k not in [\"relationship_type\", \"join_id\", \"sentence\"]]), axis=1)\n",
    "# labeled_relationships_sentences_neg[\"acc_join_id\"] = labeled_relationships_sentences_neg.apply(lambda x: \"_\".join([str(x[k]) for k in x.keys() if k not in [\"relationship_type\", \"join_id\", \"sentence\"]]), axis=1)\n",
    "\n",
    "\n",
    "# join_id_true = set(labeled_relationships_sentences[\"join_id\"].to_list())\n",
    "# join_id_false = set(labeled_relationships_sentences_neg[\"join_id\"].to_list())\n",
    "\n",
    "# acc_join_id_true = set(labeled_relationships_sentences[\"acc_join_id\"].to_list())\n",
    "# acc_join_id_false = set(labeled_relationships_sentences_neg[\"acc_join_id\"].to_list())\n",
    "\n",
    "\n",
    "# # debug \n",
    "# print(len(join_id_false))\n",
    "\n",
    "# print(len(acc_join_id_false))\n",
    "\n",
    "# len(join_id_true.intersection(join_id_false))\n",
    "\n",
    "# len(acc_join_id_false.intersection(acc_join_id_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf90056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f24c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity_in_sentence\n",
      "False    995493\n",
      "True     150228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# write a function to check if entity_company is in the sentence\n",
    "def check_entity_in_sentence(sentence, company_name, entity_company):\n",
    "    ent_comp = entity_company.lower().split(\" \")[0].strip(\".,-:;\")\n",
    "    filer_comp = company_name.lower().split(\" \")[0].strip(\".,-:;\")\n",
    "    sent_lower = sentence.lower() \n",
    "    ent_comp_present = True if re.search(r\"\\b{}\\b\".format(ent_comp), sent_lower) else False\n",
    "    filer_comp_present = True if re.search(r\"\\b{}\\b\".format(filer_comp), sent_lower) else False\n",
    "\n",
    "    return ent_comp_present and filer_comp_present\n",
    "\n",
    "# check if entity_company is in the sentence\n",
    "labeled_relationships_sentences[\"entity_in_sentence\"] = labeled_relationships_sentences.apply(lambda x: check_entity_in_sentence(x.sentence, x.company_name, x.related_entity), axis=1)\n",
    "\n",
    "print(labeled_relationships_sentences[\"entity_in_sentence\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67539e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_relationships_sentences = labeled_relationships_sentences[labeled_relationships_sentences[\"entity_in_sentence\"]==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72705f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33201733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_deduplicate_sentences(entity_matcher, data, threshold=0.99):\n",
    "\n",
    "    # Compute embeddings for each sentence\n",
    "    sentence_list = data['sentence'].to_list()\n",
    "    embeddings = entity_matcher.encode(sentence_list)\n",
    "    embeddings = embeddings.numpy()\n",
    "\n",
    "    groups = []\n",
    "    seen = set()\n",
    "\n",
    "    # Calculate the dot products on GPU\n",
    "    dot_products_cpu = np.dot(embeddings, embeddings.T)\n",
    "\n",
    "    # Create a mask for similarities > threshold\n",
    "    mask = dot_products_cpu > threshold\n",
    "\n",
    "    # Create groups based on mask\n",
    "    groups = []\n",
    "    seen = set()\n",
    "\n",
    "    for i in range(mask.shape[0]):\n",
    "        if i not in seen:\n",
    "            # Find indices where similarity > threshold\n",
    "            similar_indices = np.where(mask[i])[0].tolist()\n",
    "\n",
    "            # Mark these as seen\n",
    "            seen.update(similar_indices)\n",
    "\n",
    "            # Append the group\n",
    "            groups.append(similar_indices)\n",
    "\n",
    "    # Keep one index from each group\n",
    "    indices_to_keep = [group[0] for group in groups]\n",
    "    sentences_to_ignored = [\"\\n\\n\".join([sentence_list[idx] for idx in group[1:]])\n",
    "                            for group in groups ]\n",
    "\n",
    "    return indices_to_keep, sentences_to_ignored\n",
    "\n",
    "\n",
    "def remove_duplicates_at_accession_entity_level(entity_matcher, sentences_df):\n",
    "    # sentences_df has columns 'key', 'company_name', 'related_entity'\n",
    "\n",
    "    # redemove duplicates at the group {accession, reporter_name and reported_company}\n",
    "    #\"key\", \"company_name\", \"related_entity\"\n",
    "    #'accessionnumber', 'reporter_name', 'reported_company'\n",
    "    sentences_df.loc[:, \"deduped\"] = False\n",
    "    #sentences_df.loc[:, \"dup_sents\"] = '[]'\n",
    "    \n",
    "    for _ , group in tqdm(sentences_df.groupby([\"key\", \"company_name\", \"related_entity\"])):\n",
    "        group_index_mapping = dict(zip(range(group.index.shape[0]), group.index))\n",
    "        indices_to_keep, sentences_to_ignored = get_deduplicate_sentences(entity_matcher, group)\n",
    "        indices_to_keep = [group_index_mapping[i] for i in indices_to_keep]\n",
    "        sentences_df.loc[indices_to_keep, \"deduped\"] = True\n",
    "        #sentences_df.loc[indices_to_keep, \"dup_sents\"] = sentences_to_ignored\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d464275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'company_name', 'related_entity', 'relationship_type',\n",
       "       'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_relationships_sentences.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d03eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4781/6775 [02:00<01:10, 28.27it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dbb38725df427ca796e21aad7dbd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4894/6775 [02:07<05:17,  5.93it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff9c4b601fb45b9ba0f17bf2d93cefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 5330/6775 [02:22<00:49, 29.15it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6ea4b7241a4f2b971875d07c8273a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6775/6775 [02:57<00:00, 38.24it/s]\n"
     ]
    }
   ],
   "source": [
    "remove_duplicates_at_accession_entity_level(entity_matcher, labeled_relationships_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8363070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     79042\n",
       "False    71186\n",
       "Name: deduped, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_relationships_sentences[\"deduped\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "170bed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_relationships_sentences = labeled_relationships_sentences[labeled_relationships_sentences[\"deduped\"]==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43708c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (labeled_relationships_sentences\n",
    "#  [['key', 'company_name', 'related_entity', 'relationship_type', 'sentence']].\n",
    "#  to_csv(\"test_pipeline_data/labeled-relationships/labeled-relationships-sentences_pos_entity_in_sentence_dedup.csv\", index=False))\n",
    "\n",
    "\n",
    "(labeled_relationships_sentences\n",
    " [['key', 'company_name', 'related_entity', 'relationship_type', 'sentence']].\n",
    " to_csv(\"test_pipeline_data/labeled-relationships/labeled-relationships-sentences_pos_entity_in_sentence_dedup.csv\", index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d50225",
   "metadata": {},
   "source": [
    "### Read csv data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e71948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79042, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data = pd.read_csv(\"/storage/test_pipeline_data/labeled-relationships/labeled-relationships-sentences_pos_entity_in_sentence_dedup.csv\")\n",
    "\n",
    "# rename columns\n",
    "query_data.rename(columns={\"key\": \"accessionnumber\",\n",
    "                           \"related_entity\": \"reported_company\",                        \n",
    "                           \"company_name\": \"reporter_name\"}, \n",
    "                           inplace=True)\n",
    "\n",
    "query_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c58b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6775, 5)\n"
     ]
    }
   ],
   "source": [
    "print(query_data.drop_duplicates(subset=[\"accessionnumber\", \"reported_company\"]).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99fa8f-a90e-41d8-b770-3b69cf9b7007",
   "metadata": {},
   "source": [
    "### Basic dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46f2e56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d2df1f-0428-4bd2-bf52-7bcd55ff46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/22/2023 03:55:32 PM [INFO]: Found credentials in shared credentials file: ~/.aws/credentials\n",
      "10/22/2023 03:55:32 PM [INFO]: Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch GPU Exists..\n",
      "2023-10-22 15:55:34,465 â€” ðŸŒŒ spaCy â€” INFO â€” Language model used is en_core_web_trf\n",
      "2023-10-22 15:55:34,467 â€” ðŸŒŒ spaCy â€” INFO â€” spaCy Work On GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d264b23c64a14bb4a0c80f98e9522b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)L6-v2/resolve/main/tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58855a28f0f14446a584448de372aa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)/all-MiniLM-L6-v2/resolve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ef42a35fa74e3ea44e5b1a45ca94d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)MiniLM-L6-v2/resolve/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abeea481de6419480c474b2d29b07f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)-v2/resolve/main/special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c455e552abb488caac34424695d79fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ll-MiniLM-L6-v2/resolve/main/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658eeb6bde2b44bba897fa31a019f677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-22 15:55:45,181 â€” ðŸ’« Relations Extractor â€” INFO â€” Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 30005. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load with CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/22/2023 03:55:47 PM [INFO]: Loaded model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-22 15:55:47,919 â€” ðŸ’« Relations Extractor â€” INFO â€” Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import awswrangler as wr\n",
    "from src.utils.s3_utils import put_json_obj\n",
    "from src.utils.data import overwrite_json\n",
    "from src.utils.logs import get_logger\n",
    "from src.relation_extraction.infer import infer_from_trained\n",
    "from src.matcher.core import SimCSE_Matcher\n",
    "from src.relation_extraction.reporter import (agg_relations,\n",
    "                                              process_relations,\n",
    "                                              match_companies)\n",
    "from src.glue.glue_etl import GlueETL\n",
    "\n",
    "icon = \"\\U0001F4AB \"\n",
    "logger = get_logger(f\"{icon} RE JOB\", log_level=\"INFO\")\n",
    "############### Variables ################\n",
    "CURRENT_STEP = \"RE\"\n",
    "FOLLOWING = \"Final\"\n",
    "distribute = False\n",
    "##########################################\n",
    "# Load GlueEtl Worker\n",
    "etl = GlueETL()\n",
    "\n",
    "# Reference it in the inference container at /opt/ml/model/code\n",
    "def model_fn(model_dir: str) -> Tuple[infer_from_trained, SimCSE_Matcher]:\n",
    "    \"\"\"\n",
    "    Loads the trained relation extractor and entity matcher models and returns them\n",
    "    as a tuple.\n",
    "    \"\"\"\n",
    "    relation_extractor = infer_from_trained(detect_entities=True,\n",
    "                             language_model=\"en_core_web_trf\",\n",
    "                             require_gpu=True,\n",
    "                            load_matcher=True,\n",
    "                             entity_matcher=str(src_dir / \"artifacts/matcher_model\"))\n",
    "    # \"pipeline-artifacts/matcher/all-MiniLM-Nli-All-Random-v4\"\n",
    "    entity_matcher = SimCSE_Matcher(\n",
    "        model_name_or_path=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    model_args = {\"model_path\": os.path.join(model_dir, \"re_model\"), \"batch_size\": 32}\n",
    "    relation_extractor.load_model(model_args)\n",
    "    return relation_extractor, entity_matcher\n",
    "\n",
    "\n",
    "def float_format(x: Any) -> float:\n",
    "    \"\"\"\n",
    "    Converts the given argument to a float and returns it.\n",
    "    \"\"\"\n",
    "    return float(x)\n",
    "\n",
    "\n",
    "def input_fn(request_body: str, content_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parses the incoming request data and returns it as a dictionary.\n",
    "    \"\"\"\n",
    "    if content_type == \"application/json\":\n",
    "        request_content = json.loads(request_body)\n",
    "    else:\n",
    "        request_content = {}\n",
    "    return request_content\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    relation_extractor, entity_matcher = model_fn(src_dir/ \"artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075e1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d097738-c118-408a-80f1-691587e5bca2",
   "metadata": {},
   "source": [
    "### Simple Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bfc27-921a-4146-92d9-c6fea9afd363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from itertools import chain\n",
    "def is_sc(relations):\n",
    "    if not relations:\n",
    "        return 0\n",
    "    if isinstance(relations, list):\n",
    "        return int(any([1 if x =='supplier' else 0 for x in\\\n",
    "             list(chain(*[list(r.values()) for r in relations])) ]))\n",
    "    else:\n",
    "        0\n",
    "# Evaluate model performance on the simple data for a sanity check.\n",
    "#simple_data = pd.read_excel(src_dir /\"data/raw/simple_sentences_cs_report.xlsx\")\n",
    "simple_data = pd.read_excel(src_dir / \"notebooks/generated_sentences_cs_report.xlsx\")\n",
    "predictions = relation_extractor.predict_frame(simple_data, sentence_column = 'sentence', mutate=True, reverse=True)        \n",
    "simple_data.loc[predictions.index, 'relations'] = predictions['relations']\n",
    "simple_data.loc[:, 're_prediction'] = simple_data['relations'].apply(is_sc)\n",
    "simple_data['re_prediction'].fillna(0, inplace=True)\n",
    "simple_data.loc[:, 're_correct_prediction'] = simple_data['re_prediction'] == simple_data['true_label']\n",
    "simple_data.query(\"label == re_prediction\").shape[0]/ len(simple_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4038ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data.columns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cc100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60a0b2e2-36fc-47bd-a06c-873617c85065",
   "metadata": {},
   "source": [
    "### SEC data from Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2b34f-51c5-4d32-bb3b-20525e118532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read with CIK\n",
    "query_data = etl.run_query(\"\"\"SELECT * FROM \"legacyevents\".\"filingtexttext_parquet\" where reporter_cik IN ('0000012927',\n",
    "    '0000037996',\n",
    "    '0000104169',\n",
    "    '0000320193',\n",
    "    '0001047122',\n",
    "    '0000078003',\n",
    "    '0000789019',\n",
    "    '0000320193',\n",
    "    '0001467858')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  value counts by accession number and other info for all those unique accession numbers\n",
    "query_data.groupby(\"accessionnumber\").agg({\"reporter_cik\": \"unique\",\n",
    "                                            \"reporter_name\": \"unique\",\n",
    "                                            \"reporter_normalizedname\": \"unique\",\n",
    "                                           \"accessionnumber\": \"count\",\n",
    "                                           })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f251b-c148-4379-8b5d-1311e2a701bf",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1de03793-9ec7-4428-9e54-b65a0579ba5f",
   "metadata": {},
   "source": [
    "### Extract NER Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35e1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79042, 5)\n",
      "(6775, 2)\n"
     ]
    }
   ],
   "source": [
    "query_data = pd.read_csv(\"/storage/test_pipeline_data/labeled-relationships/labeled-relationships-sentences_neg_entity_in_sentence.csv\")\n",
    "print(query_data.columns)\n",
    "\n",
    "# rename columns\n",
    "query_data.rename(columns={\"key\": \"accessionnumber\",\n",
    "                           \"related_entity\": \"reported_company\",                        \n",
    "                           \"company_name\": \"reporter_name\"}, \n",
    "                           inplace=True)\n",
    "\n",
    "print(query_data.shape)\n",
    "\n",
    "print(query_data[[\"accessionnumber\",  \"reported_company\"]].drop_duplicates().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6272e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accessionnumber', 'reporter_name', 'reported_company',\n",
       "       'relationship_type', 'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b1ffcf8-427b-45ad-be30-d50668cfcf72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-01 07:49:34,685 â€” ðŸŒŒ spaCy â€” INFO â€” Start batch job for 4 chunks\n",
      "2023-10-01 07:49:34,687 â€” ðŸŒŒ spaCy â€” INFO â€” process chunk#1 ...\n",
      "2023-10-01 07:51:51,655 â€” ðŸŒŒ spaCy â€” INFO â€” process chunk#2 ...\n",
      "2023-10-01 07:53:45,457 â€” ðŸŒŒ spaCy â€” INFO â€” process chunk#3 ...\n",
      "2023-10-01 07:55:42,600 â€” ðŸŒŒ spaCy â€” INFO â€” process chunk#4 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cac929e15d04320b4e0b15d6eea61b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/389 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sents, spans, group_docs, aliases_docs = relation_extractor.spacy_loader.predictor(query_data['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5c874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d89f55ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79042"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_docs)\n",
    "#sents, spans, group_docs, aliases_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a40609d-5456-4dad-9b2f-516f4216a45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75250, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert JSON strings to Python objects\n",
    "query_data.loc[:, \"sentence\"] = sents\n",
    "query_data.loc[:, \"spans\"] = spans\n",
    "query_data.loc[:, \"org_groups\"] = group_docs\n",
    "query_data.loc[:, \"aliases\"] = aliases_docs\n",
    "query_data.loc[:, 'num_orgs'] = query_data['org_groups']\\\n",
    "          .apply(lambda x : len(set(x.values()))).tolist()\n",
    "query_data = query_data[query_data['num_orgs'] > 1]\n",
    "\n",
    "query_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "query_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75acae48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "41bca815",
   "metadata": {},
   "outputs": [],
   "source": [
    "## debug - read the already ner detected data\n",
    "\n",
    "query_data = pd.read_excel(\"test_pipeline_data/labeled-relationships/sentences_pos_entity_in_sentence_with_ner.xlsx\")\n",
    "\n",
    "# query_data.columns\n",
    "\n",
    "query_data.loc[:, \"spans\"] = query_data.spans.apply(lambda x: eval(x))\n",
    "query_data.loc[:, \"org_groups\"] = query_data.org_groups.apply(lambda x: eval(x))\n",
    "query_data.loc[:, \"filtered_org_groups\"] = query_data.filtered_org_groups.apply(lambda x: eval(x))\n",
    "query_data.loc[:, \"aliases\"] = query_data.aliases.apply(lambda x: eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "deeb5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4fbf074d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adeptus Health Inc': 0, 'Medicare': 1, 'Medicaid': 1, 'Tricare': 2}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.org_groups.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52b410ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only orgs having 'company_name', 'related_entity' companies \n",
    "\n",
    "def get_filtered_orgs(row):\n",
    "    \n",
    "    id2orgs = collections.defaultdict(list)\n",
    "    filtered_org_groups = {}\n",
    "    for k,v in row[\"org_groups\"].items():\n",
    "        id2orgs[v].append(k)\n",
    "\n",
    "    ent_comp = row[\"reported_company\"].lower().split(\" \")[0].strip(\".,-:;\")\n",
    "    filer_comp = row[\"reporter_name\"].lower().split(\" \")[0].strip(\".,-:;\")\n",
    "    filtered_org_id = {'filer': -1, 'ent_comp': -1}\n",
    "    for id, orgs in id2orgs.items():\n",
    "        \n",
    "        is_ent_comp_group =  any([True for x in orgs if re.search(r\"\\b{}\\b\".format(ent_comp), x.lower()) ])\n",
    "        is_filer_comp_group =  any([True for x in orgs if re.search(r\"\\b{}\\b\".format(filer_comp), x.lower())])\n",
    "        \n",
    "        if is_ent_comp_group:\n",
    "            filtered_org_id['ent_comp'] = id\n",
    "        elif is_filer_comp_group:\n",
    "            filtered_org_id['filer'] = id            \n",
    "\n",
    "        if filtered_org_id[\"filer\"] != -1 and filtered_org_id[\"ent_comp\"] != -1:\n",
    "            break\n",
    "    \n",
    "    if filtered_org_id[\"filer\"] != -1 and filtered_org_id[\"ent_comp\"] != -1:\n",
    "        for org in id2orgs[filtered_org_id[\"filer\"]]:\n",
    "            filtered_org_groups[org] = 0\n",
    "    \n",
    "        for org in id2orgs[filtered_org_id[\"ent_comp\"]]:\n",
    "            filtered_org_groups[org] = 1\n",
    "\n",
    "\n",
    "    return filtered_org_groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "316ac6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53313, 10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "170a0021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75250, 9)\n",
      "(65143, 10)\n"
     ]
    }
   ],
   "source": [
    "print(query_data.shape)\n",
    "\n",
    "# create filtered_org_groups column\n",
    "query_data.loc[:, 'filtered_org_groups'] = query_data.apply(get_filtered_orgs, axis=1)\n",
    "\n",
    "# keep only those rows where filtered_org_groups is not empty\n",
    "query_data.loc[:, 'num_orgs'] = query_data['filtered_org_groups']\\\n",
    "          .apply(lambda x : len(set(x.values()))).tolist()\n",
    "\n",
    "query_data = query_data[query_data['num_orgs'] > 1]\n",
    "query_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(query_data.shape)\n",
    "\n",
    "print(query_data.drop_duplicates(subset=[\"accessionnumber\", \"reported_company\"]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04a8d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6431, 10)\n"
     ]
    }
   ],
   "source": [
    "# debug - find the count of unique records by accessionnumber, reporter_name, reported_company\n",
    "query_data[[\"accessionnumber\", \"reported_company\"]].drop_duplicates().shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d58697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    57938\n",
       "3     6717\n",
       "4      415\n",
       "5       63\n",
       "6        7\n",
       "7        3\n",
       "Name: filtered_org_groups, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data['filtered_org_groups'].apply(lambda x : len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5a280-d9d6-4c4f-ad3e-0d2793800641",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Detect supply-chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d546",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb760edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65143, 12)\n",
      "Index(['accessionnumber', 'reporter_name', 'reported_company',\n",
      "       'relationship_type', 'sentence', 'spans', 'org_groups', 'aliases',\n",
      "       'num_orgs', 'filtered_org_groups', 'sc_score', 'sc_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Notice - debug mode - uncomment below only when you want to want to start from here and have the query_data generated from last step\n",
    "\n",
    "query_data = pd.read_excel(\"test_pipeline_data/labeled-relationships/test_pos_query_data_sc.xlsx\")\n",
    "\n",
    "print(query_data.shape)\n",
    "print(query_data.columns)\n",
    "\n",
    "# # apply eval on few columns which has list and dict in the columns\n",
    "query_data.loc[:, \"spans\"] = query_data[\"spans\"].apply(eval)\n",
    "query_data.loc[:, \"org_groups\"] = query_data[\"org_groups\"].apply(eval)\n",
    "query_data.loc[:, \"filtered_org_groups\"] = query_data.filtered_org_groups.apply(lambda x: eval(x))\n",
    "query_data.loc[:, \"aliases\"] = query_data[\"aliases\"].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b863356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6431, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug - find the count of unique records by accessionnumber, reporter_name, reported_company\n",
    "query_data[[\"accessionnumber\", \"reported_company\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee5c7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     48350\n",
       "False    16793\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((query_data[\"sc_score\"] > 0.95) & (query_data[\"sc_label\"] == 1)).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869367a0-09f9-449a-8a6a-af123dfd21b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root==> /notebooks/inferess-relation-extraction\n",
      "2023-10-22 13:32:30,104 â€” SCClassifier â€” INFO â€” loading checkpoint from `sc_model`\n",
      "2023-10-22 13:32:32,590 â€” SCClassifier â€” INFO â€” inference mode...\n"
     ]
    }
   ],
   "source": [
    "from src.sc_classifier.trainer import Trainer\n",
    "from src.sc_classifier.config.core import config\n",
    "config.train_args.load_pretrained = True\n",
    "sc_model = Trainer(config=config,load_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8cedc8-0a2b-4637-84b4-f33e8a5609a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1448/1448 [09:00<00:00,  2.68batch/s]\n",
      "/tmp/ipykernel_533/2596788124.py:2: FutureWarning:\n",
      "\n",
      "In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores, preds = sc_model.predict_seq(query_data['sentence'] , max_length=128)\n",
    "query_data.loc[:, 'sc_score'] = scores.max(1)\n",
    "query_data.loc[:, 'sc_label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bf912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data.to_excel(\"test_pipeline_data/labeled-relationships/test_pos_query_data_sc.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76359cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     48325\n",
       "False    16818\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((query_data['sc_label'] == 1) & (query_data['sc_score'] > 0.95)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b08ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65143, 12)\n",
      "(48350, 12)\n"
     ]
    }
   ],
   "source": [
    "print(query_data.shape)\n",
    "query_data = query_data[(query_data['sc_label'] == 1) & (query_data['sc_score'] > 0.95)]\n",
    "query_data.reset_index(drop=True, inplace=True)\n",
    "print(query_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b722e1-271e-4206-9a59-0c186f87051b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b57669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6161, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug - find the count of unique records by accessionnumber, reporter_name, reported_company\n",
    "query_data[[\"accessionnumber\", \"reported_company\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6339becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_data[(query_data['sc_label'] == 1) & (query_data['sc_score'] > 0.90)][[\"accessionnumber\", \"reported_company\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e945de5-4d5d-46e1-a2ab-754d09d2b4c1",
   "metadata": {},
   "source": [
    "### Extract relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cec9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice - debug mode - uncomment below only when you want to want to start from here and have the query_data generated from last step\n",
    "\n",
    "# query_data = pd.read_excel(\"test_pipeline_data/labeled-relationships/test_pos_query_data_re.xlsx\")\n",
    "# apply eval on few columns which has list and dict in the columns\n",
    "# query_data.loc[:, \"spans\"] = query_data[\"spans\"].apply(eval)\n",
    "# query_data.loc[:, \"org_groups\"] = query_data[\"org_groups\"].apply(eval)\n",
    "# query_data.loc[:, \"filtered_org_groups\"] = query_data[\"filtered_org_groups\"].apply(eval)\n",
    "# query_data.loc[:, \"aliases\"] = query_data[\"aliases\"].apply(eval)\n",
    "\n",
    "#query_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30695e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6dc3349-c6f3-4cd8-8a6c-918e86178886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mutate text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88472/88472 [00:10<00:00, 8723.34it/s]\n",
      "10/22/2023 03:58:03 PM [INFO]: Tokenizing data...\n",
      "tokenization: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88472/88472 [00:31<00:00, 2792.17it/s]\n",
      "tags positioning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88472/88472 [00:01<00:00, 53382.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid rows/total: 0/88472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2765/2765 [09:18<00:00,  4.95it/s]\n",
      "mutate text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88472/88472 [00:10<00:00, 8653.50it/s]\n",
      "10/22/2023 04:08:06 PM [INFO]: Tokenizing data...\n",
      "tokenization: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88472/88472 [00:33<00:00, 2675.64it/s]\n",
      "tags positioning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88472/88472 [00:01<00:00, 51290.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid rows/total: 0/88472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2765/2765 [08:31<00:00,  5.41it/s]\n",
      "/notebooks/inferess-relation-extraction/src/relation_extraction/infer.py:349: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tagged_frame.loc[:, 'scores'] =  labels, score\n"
     ]
    }
   ],
   "source": [
    "# Predict relations\n",
    "predictions= relation_extractor.predict_relations(\n",
    "    sentences=query_data[\"sentence\"].tolist(),\n",
    "    ent=\"ORG\",\n",
    "    spans=query_data[\"spans\"].tolist(),\n",
    "    org_groups=query_data[\"filtered_org_groups\"].tolist(),\n",
    "    aliases=query_data[\"aliases\"].tolist(),\n",
    "    mutate=True, # re_model trained to predict\n",
    "    reverse=True # aggregate average score between both directions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0221070",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data['relations'] = None\n",
    "query_data.loc[predictions.index.values, \"relations\"] = predictions[\"relations\"]\n",
    "query_data.dropna(subset=['relations'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf268434-2114-45d7-a250-c86a1f8ca570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - filter RE predictions based on the score\n",
    "\n",
    "#query_data = query_data[query_data['re_score'] > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0278c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##query_data.to_excel(\"/storage/test_pipeline_data/labeled-relationships/test_ \"<>\" _query_data_re.xlsx\", index=False)\n",
    "\n",
    "query_data.to_excel(\"test_pipeline_data/labeled-relationships/test_pos_query_data_re.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45fa2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accessionnumber', 'reporter_name', 'reported_company',\n",
       "       'relationship_type', 'sentence', 'spans', 'org_groups', 'aliases',\n",
       "       'num_orgs', 'filtered_org_groups', 'sc_score', 'sc_label', 'relations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "970fba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6161, 2)\n",
      "count    48350.000000\n",
      "mean         0.912503\n",
      "std          0.136938\n",
      "min          0.340300\n",
      "25%          0.903700\n",
      "50%          0.980400\n",
      "75%          0.993000\n",
      "max          0.999900\n",
      "Name: re_score, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6043, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debug - find the number of relations that will be dropped after re confidence threshold\n",
    "\n",
    "print(query_data[[\"accessionnumber\", \"reported_company\"]].drop_duplicates().shape)\n",
    "\n",
    "query_data['re_score'] = query_data['relations'].apply(lambda x: x[0]['score'])\n",
    "\n",
    "print(query_data['re_score'].describe())\n",
    "\n",
    "# find count of unique accession numbers and related entities\n",
    "query_data[query_data['re_score'] > 0.75][[\"accessionnumber\", \"reported_company\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766c8a7",
   "metadata": {},
   "source": [
    "### Merge re results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb74e74-8d45-4ee7-a7a4-130b0df21e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple, List, Text, Dict\n",
    "def top_n_size(x, y, z=None):\n",
    "    \"\"\"\n",
    "    Input - \n",
    "    x - count of supplier relation sentences\n",
    "    y - count of customer relation sentences\n",
    "    z - count of other relation sentences\n",
    "\n",
    "    Balaced approach towards all relations\n",
    "    Return the minimum of \"20% of count each relation\" as top_n_relations to consier in final scoring\n",
    "\n",
    "    \"\"\"\n",
    "    if z:\n",
    "        assert (x > 0) and (y > 0) and (z > 0)\n",
    "        n1 = math.ceil(x * 0.2)\n",
    "        n2 = math.ceil(y * 0.2)\n",
    "        n3 = math.ceil(z * 0.2)\n",
    "        return min(n1, min(n2, n3))\n",
    "    else:\n",
    "        assert (x > 0) and  (y > 0)\n",
    "        n1 = math.ceil(x * 0.2)\n",
    "        n2 = math.ceil(y * 0.2)\n",
    "        return min(n1, n2)\n",
    "\n",
    "def top_n_size_new(x, y):\n",
    "    \"\"\"\n",
    "    Input - \n",
    "    x - count of supplier relation sentences\n",
    "    y - count of customer relation sentences\n",
    "\n",
    "    - Ignore the relation count of other relations, find the top_n_size based on \n",
    "    only supplier and customer relations count. \n",
    "    - This approach slightely favors relation occuring more times\n",
    "   \n",
    "    \"\"\"\n",
    "    assert (x > 0) and (y > 0) \n",
    "    \n",
    "    # If difference of just 1 relation count, two relations will fight for winning relation\n",
    "    if abs(x - y) == 1:\n",
    "        \n",
    "        return min(x, y)\n",
    "    else:\n",
    "        # if more difference in relation counts, favor to relation with more count\n",
    "        n1 = math.ceil(x * 0.5)\n",
    "        n2 = math.ceil(y * 0.5)        \n",
    "        return max(n1, n2)\n",
    "\n",
    "\n",
    "def log_sum_top_n(scores, top_n_size):\n",
    "    \"\"\"\n",
    "    Logarithmic sum of top_n scores\n",
    "    function name - log_sum_top_n\n",
    "    \"\"\"\n",
    "    total_score = sum(scores)\n",
    "    avg_score = total_score / len(scores)\n",
    "    sorted_classifications = sorted(scores, reverse=True)\n",
    "    top_n = sorted_classifications[:top_n_size]\n",
    "    top_n_conf = sum(top_n)\n",
    "    return avg_score * (1 + math.log(top_n_conf))\n",
    "    \n",
    "    \n",
    "\n",
    "def agg_relation_score(company_relation_score: Dict, top_n_approach: str):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    top_n_approach: \"old\" or \"new\"\n",
    "        \"old\" - top_n_size function\n",
    "        \"new\" - top_n_size_new function\n",
    "    \n",
    "    Returns:\n",
    "    Aggregates the scores for each relation type (supplier, customer, other) and \n",
    "    returns a dictionary with the aggregated scores.\n",
    "    \"\"\"\n",
    "\n",
    "    supplier_scores = company_relation_score.get(\"supplier_scores\", [])\n",
    "    customer_scores = company_relation_score.get(\"customer_scores\", [])\n",
    "    other_scores = company_relation_score.get(\"other_scores\", [])\n",
    " \n",
    "    label_scores = {\"supplier\": 0, \"customer\": 0, \"other\": 0}\n",
    "\n",
    "    # no scores for any relation \n",
    "    if not supplier_scores and not customer_scores and not other_scores:\n",
    "        pass\n",
    "    \n",
    "    # only one relation has scores\n",
    "    elif supplier_scores and not customer_scores and not other_scores:\n",
    "        label_scores[\"supplier\"] = log_sum_top_n(supplier_scores, len(supplier_scores))\n",
    "    \n",
    "    elif customer_scores and not supplier_scores and not other_scores:        \n",
    "        label_scores[\"customer\"] = log_sum_top_n(customer_scores, len(customer_scores))\n",
    "\n",
    "    elif other_scores and not customer_scores and not supplier_scores:\n",
    "        label_scores[\"other\"] = log_sum_top_n(other_scores, len(other_scores)) \n",
    "    \n",
    "    # two or more relations have scores\n",
    "    else:\n",
    "        if customer_scores and supplier_scores and not other_scores:\n",
    "            if top_n_approach == \"old\":\n",
    "                n = top_n_size(len(customer_scores), len(supplier_scores))\n",
    "            elif top_n_approach == \"new\":\n",
    "                n = top_n_size_new(len(customer_scores), len(supplier_scores))\n",
    "        elif customer_scores and other_scores and not supplier_scores:\n",
    "            if top_n_approach == \"old\":\n",
    "                n = top_n_size(len(customer_scores), len(other_scores))\n",
    "            elif top_n_approach == \"new\":\n",
    "                n = top_n_size_new(len(customer_scores), len(other_scores))\n",
    "\n",
    "        elif supplier_scores and other_scores and not customer_scores:\n",
    "            if top_n_approach == \"old\":\n",
    "                n = top_n_size(len(supplier_scores), len(other_scores))\n",
    "            elif top_n_approach == \"new\":\n",
    "                n = top_n_size_new(len(supplier_scores), len(other_scores))\n",
    "        elif customer_scores and supplier_scores and other_scores:\n",
    "            if top_n_approach == \"old\":\n",
    "                n = top_n_size(len(customer_scores), len(supplier_scores), len(other_scores))\n",
    "            elif top_n_approach == \"new\":\n",
    "                n = top_n_size_new(len(customer_scores), len(supplier_scores))\n",
    "\n",
    "        if customer_scores:\n",
    "            label_scores[\"customer\"] = log_sum_top_n(customer_scores, n)\n",
    "        if supplier_scores:\n",
    "            label_scores[\"supplier\"] = log_sum_top_n(supplier_scores, n)\n",
    "        if other_scores:\n",
    "            label_scores[\"other\"] = log_sum_top_n(other_scores, n)\n",
    "\n",
    "    return label_scores\n",
    "    \n",
    "def get_winning_relation(company_relation_score: Dict, top_n_approach: str  ):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    ------\n",
    "    Dict with list of scores for each relation type. \n",
    "    {\"customer_scores\": [..],  \"supplier_scores\": [..], \"other_scores\": [..]}\n",
    "    \n",
    "    top_n_approach: \"old\" or \"new\"\n",
    "    \"old\" - top_n_size function\n",
    "    \"new\" - top_n_size_new function\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    Dict with relation type and scores for each relation type.\n",
    "    If there are more than one relation type with the same score, then winning relation is \"Supplier\".\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # get the scores for each relation type: Dict[relation_key, aggregated_score_for_relation]\n",
    "    relation_scores = agg_relation_score(company_relation_score, top_n_approach)\n",
    "\n",
    "    # find the max score and get the relation type of max score\n",
    "    max_score = max(relation_scores.values())\n",
    "    max_score_relations = [k for k, v in relation_scores.items() if v == max_score]\n",
    "\n",
    "    # if there are more than one relation type with max score, then return \"Suuplier\"\n",
    "    if len(max_score_relations) > 1:\n",
    "        winning_relation = \"other\"\n",
    "    else:\n",
    "        winning_relation = max_score_relations[0]\n",
    "    \n",
    "    relation_scores[\"winning_relation\"] = winning_relation\n",
    "\n",
    "    return relation_scores\n",
    "\n",
    "\n",
    "def get_winning_relation_simplified(company_relation_score: Dict, top_n_approach: str  ):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    ------\n",
    "    Dict with list of scores for each relation type. \n",
    "    {\"customer_scores\": [..],  \"supplier_scores\": [..], \"other_scores\": [..]}\n",
    "    \n",
    "    top_n_approach: \"old\" or \"new\"\n",
    "    \"old\" - top_n_size function\n",
    "    \"new\" - top_n_size_new function\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    Dict with relation type and scores for each relation type.\n",
    "    If there are more than one relation type with the same score, then winning relation is \"Supplier\".\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # get the scores for each relation type: Dict[relation_key, aggregated_score_for_relation]\n",
    "    supplier_scores = company_relation_score.get(\"supplier_scores\", [])\n",
    "    customer_scores = company_relation_score.get(\"customer_scores\", [])\n",
    "    other_scores = company_relation_score.get(\"other_scores\", [])\n",
    " \n",
    "    relation_scores = {\"supplier\": sum(supplier_scores),\n",
    "                     \"customer\": sum(customer_scores),\n",
    "                       \"other\": sum(other_scores)}\n",
    "\n",
    "    # if \n",
    "\n",
    "    if relation_scores[\"supplier\"] > relation_scores[\"customer\"]:\n",
    "        winning_relation = \"supplier\"\n",
    "    elif relation_scores[\"customer\"] > relation_scores[\"supplier\"]:\n",
    "        winning_relation = \"customer\"\n",
    "    else:\n",
    "        winning_relation = \"other\"\n",
    "    \n",
    "    relation_scores[\"winning_relation\"] = winning_relation\n",
    "\n",
    "    return relation_scores\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a64292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48350, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2602bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import string\n",
    "import re\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def process_relations(\n",
    "    all_relations: pd.DataFrame,\n",
    "    top_n_approach=\"new\",\n",
    "    re_score_threshold=0.95,\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Process relations from all_relations dataframe and perform clustering based on organization names.\n",
    "\n",
    "    @params\n",
    "    -------\n",
    "    - all_relations (pd.DataFrame): DataFrame containing all relations data.\n",
    "    - matcher: Matcher object for name matching.\n",
    "    - _ingest (bool): Flag indicating whether the data should be ingested.\n",
    "    - match_thresh (float): Threshold for matching similarity.\n",
    "    - top_n_approach (str): Approach for selecting top relations.\n",
    "\n",
    "    @returns:\n",
    "    --------\n",
    "    List[Dict[str, str]]: Processed relations data.\n",
    "    \"\"\"\n",
    "\n",
    "    all_records = []\n",
    "    counter_for_company_not_found = 0\n",
    "    counter_for_reported_company = 0\n",
    "    counter_for_relation_not_found = 0\n",
    "\n",
    "    # Group relations by accessionnumber and process each file\n",
    "    for _, group in all_relations.groupby([\"accessionnumber\",  \"reported_company\"]):\n",
    "        \n",
    "        companies_relations = defaultdict(dict)\n",
    "\n",
    "        # Increment counter for reported company\n",
    "        counter_for_reported_company += 1   # debug - remove later\n",
    "        \n",
    "        # Process each relation in the group\n",
    "        for _, raw in group.iterrows():\n",
    "                              \n",
    "            for relation in raw[\"relations\"]:\n",
    "\n",
    "                reporter_name = raw[\"reporter_name\"]\n",
    "                reported_company = raw[\"reported_company\"]\n",
    "                reporter_first_word = reporter_name.split(\" \")[0].strip(\".,-:;\").lower()\n",
    "                reported_first_word = reported_company.split(\" \")[0].strip(\".,-:;\").lower()\n",
    "\n",
    "                # safe check\n",
    "                if not relation or not relation.get(\"score\"):\n",
    "                    counter_for_relation_not_found += 1 # debug - remove later\n",
    "                    continue\n",
    "\n",
    "                score = relation.get(\"score\")\n",
    "                \n",
    "                entity_companies = [key for key in relation.keys() if key != \"score\"]\n",
    "                company1 = entity_companies[0]\n",
    "                company2 = entity_companies[1]\n",
    "                company1_lower = company1.lower()\n",
    "                company2_lower = company2.lower()\n",
    "\n",
    "                \n",
    "                # TODO - find the correct relation\n",
    "                if reporter_first_word in company1_lower or reported_first_word in company2_lower:                    \n",
    "                    reported_company_relation = relation[company2]\n",
    "                elif reporter_first_word in company2_lower or reported_first_word in company1_lower:\n",
    "                    reported_company_relation = relation[company1]\n",
    "                \n",
    "                else:\n",
    "                    print(f\" {reporter_name} -- {reported_company} --   {company1}  -- {company2}\")                    \n",
    "                    counter_for_company_not_found += 1  # debug - remove later\n",
    "                    continue\n",
    "\n",
    "                # if score is more than trheshold, then add the relation to the list                  \n",
    "                if score >= re_score_threshold:\n",
    "                    if not companies_relations[reported_company].get('sentences'):\n",
    "                        companies_relations[reported_company]['sentences'] = []\n",
    "                        companies_relations[reported_company]['scores'] = defaultdict(list)\n",
    "                    \n",
    "                    # add the score to scores dict\n",
    "                    companies_relations[reported_company]['scores']\\\n",
    "                    [\"{}_scores\".format(reported_company_relation)].append(score)\n",
    "                    # add sentence info\n",
    "                    companies_relations[reported_company]['sentences'].append(\n",
    "                        {\n",
    "                            \"sentence\": raw[\"sentence\"],\n",
    "                            \"relation\": reported_company_relation,\n",
    "                            \"score\": score\n",
    "                        }\n",
    "                    )\n",
    "            \n",
    "        # Aggregate relations by company and append to file_report\n",
    "        intial_vals = group.iloc[0]\n",
    "        \n",
    "        for co in list(companies_relations.keys()):\n",
    "            # Assign reporter name and reported company, relationship type\n",
    "            row_per_detected_company = {} \n",
    "\n",
    "            row_per_detected_company[\"accessionnumber\"] = intial_vals[\"accessionnumber\"]\n",
    "            row_per_detected_company[\"reporter_name\"] = intial_vals[\"reporter_name\"]\n",
    "            row_per_detected_company[\"reported_company\"] = intial_vals[\"reported_company\"]\n",
    "            row_per_detected_company[\"relationship_type\"] = intial_vals[\"relationship_type\"]\n",
    "            row_per_detected_company[\"company_name\"] = co\n",
    "            row_per_detected_company[\"sentences\"] = companies_relations[co][\"sentences\"]\n",
    "            \n",
    "            # Get the winning results and add to relations row\n",
    "\n",
    "            winning_results = get_winning_relation_simplified(companies_relations[co]['scores'],\n",
    "                                                              top_n_approach=top_n_approach)\n",
    "            \n",
    "            row_per_detected_company[\"sents_scores\"] = {k:[round(vv,2) for vv in v] for k,v in \n",
    "                                                        companies_relations[co][\"scores\"].items()}             \n",
    "            row_per_detected_company['aggregation_results'] = {k: round(v,2) for k,v in winning_results.items() \n",
    "                                                                 if k in ['supplier', 'customer', 'other']}\n",
    "            row_per_detected_company['winning_relation'] = winning_results[\"winning_relation\"]           \n",
    "            \n",
    "            # collect into list\n",
    "            all_records.append(row_per_detected_company)\n",
    "    \n",
    "    print(f\"counter_for_company_not_found: {counter_for_company_not_found}\")\n",
    "    print(f\"counter_for_reported_company: {counter_for_reported_company}\")    \n",
    "    print(f\"counter_for_relation_not_found: {counter_for_relation_not_found}\")\n",
    "    \n",
    "    return all_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e16d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accessionnumber', 'reporter_name', 'reported_company',\n",
       "       'relationship_type', 'sentence', 'spans', 'org_groups', 'aliases',\n",
       "       'num_orgs', 'filtered_org_groups', 'sc_score', 'sc_label', 'relations',\n",
       "       're_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5483002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1d61665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter_for_company_not_found: 0\n",
      "counter_for_reported_company: 6161\n",
      "counter_for_relation_not_found: 0\n"
     ]
    }
   ],
   "source": [
    "relations_report = process_relations(query_data,  \n",
    "                                     top_n_approach=\"new\",\n",
    "                                     re_score_threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d83377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe5ad939",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_report_df = pd.DataFrame(relations_report)\n",
    "\n",
    "relations_report_df[\"old_new_match\"] = relations_report_df.apply(lambda x: x['relationship_type'] == x['winning_relation'], axis=1)\n",
    "\n",
    "# for negative data, old relation is other\n",
    "#relations_report_df[\"old_new_match\"] = relations_report_df.apply(lambda x: \"other\" == x['winning_relation'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c01d34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the xlsx file for the relations_report by expanding relations dict\n",
    "relations_report_sentences_df = []\n",
    "\n",
    "# iterate over relations_report list\n",
    "\n",
    "for all_relations_data_wrt_filer in relations_report:\n",
    "    row = {}\n",
    "    row['accessionnumber'] = all_relations_data_wrt_filer['accessionnumber']\n",
    "    row['reporter_name'] = all_relations_data_wrt_filer['reporter_name']\n",
    "    row['reported_company'] = all_relations_data_wrt_filer['reported_company']\n",
    "    row['company_name'] = all_relations_data_wrt_filer['company_name']\n",
    "    row['relationship_type'] = all_relations_data_wrt_filer['relationship_type']\n",
    "    row['sents_scores'] = all_relations_data_wrt_filer['sents_scores']\n",
    "    row['aggregation_results'] = all_relations_data_wrt_filer['aggregation_results']\n",
    "    row['winning_relation'] = all_relations_data_wrt_filer['winning_relation']    \n",
    "    row[\"old_new_match\"] = (row[\"relationship_type\"] == row[\"winning_relation\"])\n",
    "    \n",
    "    # for negative data\n",
    "    #row[\"old_new_match\"] = (\"other\" == row[\"winning_relation\"])\n",
    "\n",
    "    for sentence_data in all_relations_data_wrt_filer['sentences']:\n",
    "       \n",
    "        v1 = row.copy()\n",
    "        v1['sentence'] = sentence_data['sentence']\n",
    "        #v1['sentence_id'] = sentence_data['sentence_id']\n",
    "        v1['sent_relation'] = sentence_data['relation']\n",
    "        v1['sent_score'] = round(sentence_data['score'], 2)\n",
    "\n",
    "        relations_report_sentences_df.append(v1.copy())\n",
    "        \n",
    "    # Add few empty rows for better readability in the excel \n",
    "    relations_report_sentences_df.append({})\n",
    "    relations_report_sentences_df.append({})\n",
    "\n",
    "\n",
    "# convert the list of dict to dataframe\n",
    "\n",
    "relations_report_sentences_df = pd.DataFrame(relations_report_sentences_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7579978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accessionnumber', 'reporter_name', 'reported_company',\n",
      "       'relationship_type', 'company_name', 'sentences', 'sents_scores',\n",
      "       'aggregation_results', 'winning_relation', 'old_new_match'],\n",
      "      dtype='object')\n",
      "Index(['accessionnumber', 'reporter_name', 'reported_company', 'company_name',\n",
      "       'relationship_type', 'sents_scores', 'aggregation_results',\n",
      "       'winning_relation', 'old_new_match', 'sentence', 'sent_relation',\n",
      "       'sent_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(relations_report_df.columns)\n",
    "\n",
    "print(relations_report_sentences_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "437cbe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     37208\n",
       "False     4611\n",
       "Name: old_new_match, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_report_sentences_df.old_new_match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d62cb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "\n",
    "# pos\n",
    "## relations_report_df.to_excel(\"test_pipeline_data/labeled-relationships/test_pos_relations_report.xlsx\", index=False)\n",
    "## relations_report_sentences_df.to_excel(\"test_pipeline_data/labeled-relationships/test_pos_relations_report_sentences.xlsx\", index=False)\n",
    "\n",
    "# neg\n",
    "## relations_report_df.to_excel(\"test_pipeline_data/labeled-relationships/test_neg_relations_report.xlsx\", index=False)\n",
    "## relations_report_sentences_df.to_excel(\"/storage/test_pipeline_data/labeled-relationships/test_neg_relations_report_sentences.xlsx\", index=False)\n",
    "\n",
    "relations_report_df.to_excel(\"test_pipeline_data/labeled-relationships/test_pos_relations_report.xlsx\", index=False)\n",
    "relations_report_sentences_df.to_excel(\"test_pipeline_data/labeled-relationships/test_pos_relations_report_sentences.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "352c50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6161, 14)\n",
      "(6043, 10)\n"
     ]
    }
   ],
   "source": [
    "print(query_data.drop_duplicates(subset=['accessionnumber', 'reported_company']).shape)\n",
    "\n",
    "print(relations_report_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82621b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb31c75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5397\n",
       "False     646\n",
       "Name: old_new_match, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_report_df[\"old_new_match\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8862b318-ffc6-46b8-a764-25b9a2434ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer    3795\n",
       "supplier    2248\n",
       "Name: relationship_type, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_report_df['relationship_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc6053f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supplier    525\n",
       "customer    121\n",
       "Name: relationship_type, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_report_df[ ~ relations_report_df['old_new_match']]['relationship_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac88b8c5-dad7-4488-a850-c125b800791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States Postal Service                         11\n",
       "FedEx                                                11\n",
       "UPS                                                   8\n",
       "Zodiac Pool Systems Inc.                              6\n",
       "Microsoft                                             6\n",
       "                                                     ..\n",
       "China University of Geosciences School of Jewelry     1\n",
       "Gedeon Richter                                        1\n",
       "Icon Genetics AG                                      1\n",
       "Dairy Farmers of America                              1\n",
       "GlobalFoundries                                       1\n",
       "Name: reported_company, Length: 576, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_report_df[ ~ relations_report_df['old_new_match']]['reported_company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a211436a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5218, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_report_df.drop_duplicates(subset=['reporter_name', 'reported_company']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822fd03",
   "metadata": {},
   "source": [
    "Concept disribution in wrong predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1853ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_sents_pos = \"test_pipeline_data/labeled-relationships/test_pos_relations_report_sentences_w_concepts.xlsx\"\n",
    "# report_sents_pos =  pd.read_excel(report_sents_pos)\n",
    "\n",
    "# report_sents_neg = \"test_pipeline_data/labeled-relationships/test_neg_relations_report_sentences_w_concepts.xlsx\"\n",
    "# report_sents_neg =  pd.read_excel(report_sents_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30f94a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "revenue                      22.0\n",
       "supply_chain                 22.0\n",
       "agreement_and_partnership    13.0\n",
       "licensing_and_ip             12.0\n",
       "unknown                       9.0\n",
       "product_related               5.0\n",
       "investment_related            4.0\n",
       "services agreement            3.0\n",
       "real_estate                   3.0\n",
       "royalties                     2.0\n",
       "legal_and_regulatory          2.0\n",
       "financial_statements          1.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concept distribution in all labelled sentences\n",
    "\n",
    "concat_report_sents = pd.concat([report_sents_pos, report_sents_neg])\n",
    "\n",
    "(concat_report_sents.concept_class.value_counts(normalize=True, dropna=False).round(2) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f09d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_sents_pos = report_sents_pos[(report_sents_pos.relationship_type != report_sents_pos.sent_relation)]\n",
    "report_sents_neg = report_sents_neg[(\"other\" != report_sents_neg.sent_relation)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d266d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "supply_chain                 20.0\n",
       "licensing_and_ip             20.0\n",
       "agreement_and_partnership    17.0\n",
       "unknown                      10.0\n",
       "revenue                       8.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos - sentences where relation is incorrect\n",
    "(report_sents_pos.concept_class.value_counts(normalize=True, dropna=False).round(2) * 100 )[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d61063f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "agreement_and_partnership    24.0\n",
       "revenue                      13.0\n",
       "unknown                      13.0\n",
       "supply_chain                 12.0\n",
       "licensing_and_ip             11.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neg - sentences where sentence prediction is incorrect\n",
    "(report_sents_neg.concept_class.value_counts(normalize=True, dropna=False).round(2) * 100 )[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f1ec887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "agreement_and_partnership    20.0\n",
       "supply_chain                 16.0\n",
       "licensing_and_ip             16.0\n",
       "unknown                      11.0\n",
       "revenue                      11.0\n",
       "product_related               6.0\n",
       "investment_related            5.0\n",
       "services agreement            4.0\n",
       "legal_and_regulatory          3.0\n",
       "real_estate                   3.0\n",
       "financial_statements          2.0\n",
       "royalties                     2.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos + neg - all sentences where sentence prediction is incorrect\n",
    "\n",
    "concat_report_all_sents = pd.concat([report_sents_pos, report_sents_neg])\n",
    "\n",
    "(concat_report_all_sents.concept_class.value_counts(normalize=True, dropna=False).round(2) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883b800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db773878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pos - all sentences where relation and sentence predictionis incorrect\n",
    "# report_sents_pos = report_sents_pos[(report_sents_pos[\"old_new_match\"] == False)] \n",
    "# (report_sents_pos.concept_class.value_counts(normalize=True, dropna=False).round(2) * 100 )[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0fbd83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # neg - all sentences where relation and sentence predictionis incorrect\n",
    "\n",
    "# report_sents_neg = report_sents_neg[(report_sents_neg[\"old_new_match\"] == False)] \n",
    "# (report_sents_neg.concept_class.value_counts(normalize=True, dropna=False).round(2) * 100 )[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d56dc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0528071150639244"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bf09c9d",
   "metadata": {},
   "source": [
    "### Performance report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddc12b",
   "metadata": {},
   "source": [
    "**Report on positive relations**\n",
    "\n",
    "\n",
    "- Initial Total Relations\t6775\t(100%)\n",
    "- After NER Matching\t6431\t(94%)\n",
    "- After SC Filter\t6215\t(91%)\n",
    "- After RE Score Filter\t5692\t(84%)\n",
    "- Relations Summary\t-\n",
    "  - Dropped in Pipeline\t1211\t(16%)\n",
    "  - Matching\t4976\t(73%)\n",
    "  - Not Matching\t716\t(11%)\n",
    "\n",
    "\n",
    "**Report on negative relations**\n",
    "\n",
    "- Initial Total Relations\t2316\t(100%)\n",
    "- After NER Matching\t1799\t(77%)\n",
    "- After SC Filter\t1316\t(56%)\n",
    "- After RE Score Filter\t996\t(43%)\n",
    "- Relations Summary\t-\n",
    "  - Dropped in Pipeline\t1320\t(57%)\n",
    "  - Matching\t104\t(5%)\n",
    "  - Not Matching\t892\t(38%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9bbea",
   "metadata": {},
   "source": [
    "\n",
    "**Concept distibution**\n",
    "\n",
    "-- All labelled sentences  \n",
    "\n",
    "  - revenue                      22.0\n",
    "  - supply_chain                 22.0\n",
    "  - agreement_and_partnership    13.0\n",
    "  - licensing_and_ip             12.0\n",
    "  - unknown                       9.0\n",
    "\n",
    "  \n",
    "-- Sentence wrong prediction \n",
    " \n",
    "  - agreement_and_partnership    20.0\n",
    "  - supply_chain                 16.0\n",
    "  - licensing_and_ip             16.0\n",
    "  - unknown                      11.0\n",
    "  - revenue                      11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee23ab",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. Labelled data \n",
    "   1. It has a relation to many sentences mapping. Most of the sentences don't have required companies. Also many sentences have near duplicates in them.\n",
    "2. Both positive and negative test peformance \n",
    "   1. Pipeline performance is ~ 77%\n",
    "   2. Just model accuracy performance is ~ 85% \n",
    "3. Mistakes \n",
    "   1. Model mispredicts customer relation (another company to filer) more often (85%). \n",
    "      1. Looks like model has memorized filer as supplier from imbalance in training data \n",
    "   2. Model has high mispredictions on less frequently occuring concepts. \n",
    "      1. Model needs to see more training data on these concepts to get better \n",
    "4. Improvements \n",
    "   1. Create balanced training data on following things - \n",
    "      1. relation (1 or 0)\n",
    "      2. direction of relation\n",
    "      3. concepts class\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ed999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c43c82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392162960659306"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6775 - ( 5314 + 457)\n",
    "\n",
    "5397 / 6431"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbe3e8",
   "metadata": {},
   "source": [
    "\n",
    "** After agreement and lincense fix - Report on positive relations**\n",
    "\n",
    "\n",
    "- Initial Total Relations\t6775\t(100%)\n",
    "- After NER Matching\t6431\t(94%)\n",
    "- After SC Filter\t6215 -> 6181 -> 6051 -\t(92%) -> (91%) -> (89%)\n",
    "- After RE Score Filter\t5692 -> 5888 -> 5771 \t(84%) -> (87%) -> (85%)\n",
    "- Relations Summary\t-\n",
    "  - Dropped in Pipeline\t1083 -> 887\t(16%) -> 1004 (15%)\n",
    "  - Matching\t4976 -> 5217\t-> 5314 (73%) -> (77%) -> (79%)\n",
    "  - Not Matching\t716 -> 671-> 457 (11%) -> (10%)  -> (7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb7a19",
   "metadata": {},
   "source": [
    "\n",
    "** After adding weekly lablled data re_score_threshold=0.75 **\n",
    "\n",
    "\n",
    "- Initial Total Relations\t6775\t(100%)\n",
    "- After NER Matching\t6431\t(94%)\n",
    "- After SC Filter\t6215 -> 6181 -> 6051 -> 6161\t(92%) -> (91%) -> (89%)\n",
    "- After RE Score Filter\t5692 -> 5888 -> 5771 -> 6043\t(84%) -> (87%) -> (85%)\n",
    "- Relations Summary\t-\n",
    "  - Dropped in Pipeline\t1083 -> 887\t(16%) -> 1004 (15%) -> 732 (10%)  \n",
    "  - Matching\t4976 -> 5217\t-> 5314 -> 5397 (73%) -> (77%) -> (78%) -> (79%)\n",
    "  - Not Matching\t716 -> 671-> 457 -> 646 (11%) -> (10%)  -> (7%) -> (9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d195df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec6547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a34d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
