{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas openai torch scikit-learn dvc dvc-s3\n",
    "#!pip install openpyxl retry python-dotenv\n",
    "\n",
    "#!dvc pull artifacts/matcher_model.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shyamshinde/codebase/inferess-relation-extraction/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import time\n",
    "from typing import Tuple, List, Text, Dict\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from copy import copy\n",
    "\n",
    "from retry import retry\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "current_path = Path.cwd()\n",
    "src_dir = current_path.parent.parent\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "# import annotation methods\n",
    "from src.labels_generator import (relation_search, resort_relation)\n",
    "\n",
    "# Load matcher\n",
    "from src.matcher.core import SimCSE_Matcher\n",
    "matcher = SimCSE_Matcher(str(src_dir/ 'artifacts/matcher_model'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct sme_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'sentence', 'Label', 'org_groups', 'inf_relations', 'entity_1',\n",
      "       'entity_2', 'sme_relations', 'earlier_llm_relations', 'concepts',\n",
      "       'concept explanation', 'concept_class', 'Comment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read excel file with two tabs -\n",
    "\n",
    "pos_data = pd.read_excel(\"labelled_data_for_prompt/agreement.xlsx\", sheet_name=\"pos\")\n",
    "neg_data = pd.read_excel(\"labelled_data_for_prompt/agreement.xlsx\", sheet_name=\"neg\")\n",
    "\n",
    "print(pos_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sme_relation(entity_1, entity_2, inf_relations ):\n",
    "    \"Generate relation from entity 2 to 1\"\n",
    "\n",
    "    if inf_relations == \"customer\":\n",
    "        return [entity_1, \"supplier\" , entity_2]\n",
    "    elif inf_relations == \"supplier\":\n",
    "        return [entity_2, \"supplier\" , entity_1]\n",
    "    elif inf_relations == \"other\":\n",
    "        return [entity_2, \"other\" , entity_1]\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_sme_relation\n",
    "tqdm.pandas(desc=\"correct_sme_relation\")\n",
    "pos_data['sme_relations'] =\\\n",
    "pos_data[['entity_1', 'entity_2', 'inf_relations']]\\\n",
    ".progress_apply(lambda x:\n",
    "correct_sme_relation(\n",
    "entity_1=x.iloc[0],\n",
    "entity_2=x.iloc[1],\n",
    "inf_relations=x.iloc[2]),axis=1).to_list()\n",
    "\n",
    "tqdm.pandas(desc=\"correct_sme_relation\")\n",
    "neg_data['sme_relations'] =\\\n",
    "neg_data[['entity_1', 'entity_2', 'inf_relations']]\\\n",
    ".progress_apply(lambda x:\n",
    "correct_sme_relation(\n",
    "entity_1=x.iloc[0],\n",
    "entity_2=x.iloc[1],\n",
    "inf_relations=x.iloc[2]),axis=1).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the both dataframes to single excel file\n",
    "\n",
    "# with pd.ExcelWriter('labelled_data_for_prompt/agreement.xlsx') as writer:\n",
    "#     pos_data.to_excel(writer, sheet_name='pos', index=False)\n",
    "#     neg_data.to_excel(writer, sheet_name='neg', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llm relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces = {\"sentence\": \"{sentence}\"}\n",
    "# # Replace the keys with values for unified relation direction\n",
    "# relations_map = {\"customer\": \"supplier\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=3, delay=1)\n",
    "def get_completion_2(prompt:Text,\n",
    "                        temperature:float=0,\n",
    "                        model=\"gpt-3.5-turbo\")->str:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = None\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model,\n",
    "        messages=messages,\n",
    "        temperature= temperature,    #this is the degree of randomness of the model's output\n",
    "        request_timeout = 90\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "global sent_relations_out_star\n",
    "sent_relations_out_star = []\n",
    "\n",
    "def classify_relation(data: pd.DataFrame,\n",
    "                      prompt_1: Text)-> pd.DataFrame:\n",
    "    \n",
    "    batch_size = 10\n",
    "    sentences_in_batch = []\n",
    "    global sent_concepts_out_star \n",
    "    sent_concepts_out_star = []\n",
    "\n",
    "    output = []\n",
    "    # Iterate over the frame rows\n",
    "    for i, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Generating concepts\"):\n",
    "        \n",
    "        row = row.to_dict()\n",
    "        \n",
    "        sentences_in_batch.append(f\"{row['index']}    {row['sentence']}\")\n",
    "        # continue till batch fills\n",
    "        if (len(sentences_in_batch) == batch_size) or (i == data.index[-1]):\n",
    "            sentences_txt = \"\\n\".join(sentences_in_batch)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "        report_prompt_1 = copy(prompt_1)\n",
    "        report_prompt_1 = report_prompt_1.replace(\"{sentences}\", sentences_txt)\n",
    "\n",
    "        retry_on_parse_err = False        \n",
    "        attempt_count = 0\n",
    "        while attempt_count == 0 or retry_on_parse_err:\n",
    "            try:\n",
    "                prompt_1_completion = get_completion_2(prompt=report_prompt_1)\n",
    "                sent_concept_list = deserialize_json_list(prompt_1_completion)\n",
    "            except:\n",
    "                # don't retry of already retried\n",
    "                if retry_on_parse_err == True:                      \n",
    "                    retry_on_parse_err = False\n",
    "                    sent_concept_list = []\n",
    "                    print(\"Not retrying after 2nd error\")\n",
    "                else:\n",
    "                    print(\"Retrying after 1st error\")\n",
    "                    retry_on_parse_err = True\n",
    "            \n",
    "            attempt_count += 1\n",
    "        \n",
    "        if sent_concept_list:\n",
    "            sent_concepts_out_star += sent_concept_list\n",
    "\n",
    "        # Reset \n",
    "        sentences_in_batch = []         \n",
    "        \n",
    "    return sent_concepts_out_star\n",
    "\n",
    "\n",
    "def deserialize_json_list(ser_relations):    \n",
    "    # the string representation of the list of dictionaries\n",
    "    string_list_of_dicts = ser_relations\n",
    "    # regular expression to match a dictionary\n",
    "    dict_regex = r\"\\{[^{}]+\\}\"\n",
    "    # find all dictionaries in the string\n",
    "    dict_strings = re.findall(dict_regex, string_list_of_dicts)\n",
    "    # deserialize each dictionary into a Python object\n",
    "    list_of_dicts = []\n",
    "    for dict_string in dict_strings:\n",
    "        try:\n",
    "            list_of_dicts.append(json.loads(re.sub(r\"(?<!\\w)'|'(?!\\w)\", '\"', dict_string)))\n",
    "        except:\n",
    "            try:\n",
    "                list_of_dicts.append(json.loads(re.sub(r\"(?<!\\w)'|'(?!\\w)\", '\"', dict_string.replace('\"', '\\\\\"'))))\n",
    "            except:\n",
    "                continue\n",
    "    return list_of_dicts\n",
    "\n",
    "\n",
    "def find_relation_wrapper(data, prompt):\n",
    "    \n",
    "    global sent_concepts_out_star\n",
    "    sent_concepts_out_star = []\n",
    "\n",
    "    # run prompts to find relations\n",
    "    sent_concepts_out = classify_relation(data, prompt)\n",
    "    \n",
    "    sent_concepts_dict = {}\n",
    "\n",
    "    for sent_concepts in sent_concepts_out:\n",
    "        sent_concepts_dict[sent_concepts[\"index\"]] = sent_concepts\n",
    "\n",
    "    output = []  \n",
    "    for i, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        row = row.to_dict()\n",
    "        index_str = str(row[\"index\"])\n",
    "        if index_str in sent_concepts_dict:\n",
    "            row[\"cs_other\"] = sent_concepts_dict.get(index_str, {}).get(\"relation\")\n",
    "        else:\n",
    "            row[\"cs_other\"] = None\n",
    "        \n",
    "        output.append(row)\n",
    "    \n",
    "    output = pd.DataFrame(output)\n",
    "    # set index as data index\n",
    "    output.index = data.index\n",
    "  \n",
    "    return output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data = pd.read_excel(\"../final_train_data/shared_with_all/llm_relations_all_label_1_v2_3.xlsx\")\n",
    "#data = pd.read_excel(\"../final_train_data/shared_with_all/huge_train_complex_sents_llm_v2_3.xlsx\")\n",
    "\n",
    "data = pd.read_excel(\"../final_train_data/shared_with_all/huge_train_llm_aligned_v2_3_0_1300.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_class\n",
       "revenue                      420\n",
       "agreement_and_partnership     91\n",
       "supply_chain                  61\n",
       "unknown                       40\n",
       "investment_related            37\n",
       "product_related               24\n",
       "services agreement            21\n",
       "licensing_and_ip              17\n",
       "real_estate                    8\n",
       "legal_and_regulatory           8\n",
       "royalties                      3\n",
       "financial_statements           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.concept_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 15)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating concepts: 100%|██████████| 112/112 [02:51<00:00,  1.53s/it]\n",
      "100%|██████████| 112/112 [00:00<00:00, 7184.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read agreement_prompt \n",
    "with open(\"./cs_prompts/agreement.txt\", \"r\") as f:\n",
    "    agreement_prompt = f.read()\n",
    "    \n",
    "agreement_data = data[(data[\"concept_class\"] == \"agreement_and_partnership\") | (data[\"concept_class\"] == \"services agreement\")]\n",
    "\n",
    "agreement_data_out = find_relation_wrapper(agreement_data, agreement_prompt)\n",
    "\n",
    "data.loc[:, \"agreement_relation\"] = None\n",
    "data.loc[agreement_data_out.index, \"agreement_relation\"] = agreement_data_out[\"cs_other\"].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating concepts:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating concepts: 100%|██████████| 17/17 [00:25<00:00,  1.51s/it]\n",
      "100%|██████████| 17/17 [00:00<00:00, 9943.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read license_prompt \n",
    "with open(\"./cs_prompts/license.txt\", \"r\") as f:\n",
    "    license_prompt = f.read()\n",
    "    \n",
    "license_data = data[(data[\"concept_class\"] == \"licensing_and_ip\")]\n",
    "\n",
    "license_data_out = find_relation_wrapper(license_data, license_prompt)\n",
    "\n",
    "data.loc[:, \"license_relation\"] = None\n",
    "data.loc[license_data_out.index, \"license_relation\"] = license_data_out[\"cs_other\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating concepts:   0%|          | 0/171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating concepts: 100%|██████████| 171/171 [04:22<00:00,  1.54s/it]\n",
      "100%|██████████| 171/171 [00:00<00:00, 26263.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#supply_chain.txt\n",
    "# Read license_prompt \n",
    "with open(\"./cs_prompts/supply_chain.txt\", \"r\") as f:\n",
    "    supply_chain_prompt = f.read()\n",
    "    \n",
    "supply_chain_data = data[(data[\"concept_class\"] == \"product_related\") | (data[\"concept_class\"] == \"supply_chain\")]\n",
    "\n",
    "supply_chain_data_out = find_relation_wrapper(supply_chain_data, supply_chain_prompt)\n",
    "\n",
    "data.loc[:, \"supply_chain_relation\"] = None\n",
    "data.loc[supply_chain_data_out.index, \"supply_chain_relation\"] = supply_chain_data_out[\"cs_other\"].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To run again with modified prompts or different model \n",
    "#supply_chain_data = supply_chain_data_out[(supply_chain_data_out[\"cs_other\"] == \"other\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 18)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supply_chain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_relation\n",
       "customer_supplier    237\n",
       "other                178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.agreement_relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "license_relation\n",
       "customer_supplier    13\n",
       "other                 4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.license_relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supply_chain_relation\n",
       "customer_supplier    152\n",
       "other                 18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.supply_chain_relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data.to_excel(\"../final_train_data/shared_with_all/llm_relations_all_label_1_v2_3.xlsx\", index=False)\n",
    "\n",
    "##data.to_excel(\"../final_train_data/shared_with_all/huge_train_complex_sents_llm_v2_3.xlsx\", index=False)\n",
    "\n",
    "##data.to_excel(\"../final_train_data/shared_with_all/huge_train_llm_aligned_v2_3_0_1300.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read excel file with two tabs -\n",
    "\n",
    "# pos_data = pd.read_excel(\"labelled_data_for_prompt/agreement.xlsx\", sheet_name=\"pos\")\n",
    "# neg_data = pd.read_excel(\"labelled_data_for_prompt/agreement.xlsx\", sheet_name=\"neg\")\n",
    "\n",
    "# print(pos_data.columns)\n",
    "\n",
    "# neg_output = generate_relations_wrapper(neg_data, PROMPT_V1 , replaces, relations_map)\n",
    "\n",
    "# pos_output = generate_relations_wrapper(pos_data, PROMPT_V1 , replaces, relations_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
