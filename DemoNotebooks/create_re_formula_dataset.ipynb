{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine = \"local\"\n",
    "machine = \"paperspace\"\n",
    "\n",
    "if machine == \"local\":\n",
    "    src_dir= Path.cwd().parent    \n",
    "elif machine == \"paperspace\":\n",
    "    src_dir = Path(\"/notebooks/inferess-relation-extraction/\")\n",
    "\n",
    "sys.path.append(str(src_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load_dotenv()\n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KE\")\n",
    "\n",
    "\n",
    "# import annotation methods\n",
    "from src.labels_generator import (generate_relations,relation_search,resort_relation, get_completion,\n",
    "                                  deserialize_relations,\n",
    "                                  generate_relations_with_explanation,\n",
    "                                  relations_tupled,\n",
    "                                 create_sorted_relation)\n",
    "\n",
    "# Load matcher\n",
    "from src.matcher.core import SimCSE_Matcher\n",
    "matcher = SimCSE_Matcher(str(src_dir/ 'artifacts/matcher_model'))\n",
    "\n",
    "main_relations = [\"supplier\", \"customer\"]\n",
    "replaces = {\"sentence\": \"{sentence}\"}\n",
    "# Replace the keys with values for unified relation direction\n",
    "relations_map = {\"customer\": \"supplier\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters for train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel(str(\"/storage/test_pipeline_data/pipeline_train_data/llm_relations_all_label_1_v2_3.xlsx\"))\n",
    "\n",
    "# data2 = pd.read_excel(str(\"/storage/test_pipeline_data/pipeline_train_data/huge_train_llm_aligned_v2_3_0_1300.xlsx\"))\n",
    "# data3 = pd.read_excel(str(\"/storage/test_pipeline_data/pipeline_train_data/huge_train_complex_sents_llm_v2_3.xlsx\"))\n",
    "# data1 = data1[(data1[\"agreement_relation\"] != \"other\") & (data1[\"license_relation\"] != \"other\")]\n",
    "# data2 = data2[(data2[\"agreement_relation\"] != \"other\") & (data2[\"license_relation\"] != \"other\")]\n",
    "# data3 = data3[(data3[\"agreement_relation\"] != \"other\") & (data3[\"license_relation\"] != \"other\")]\n",
    "# data1.to_excel( str(src_dir / \"data/raw/llm_relations_all_label_1_v2_3.xlsx\"), index=False)\n",
    "# data2.to_excel( str(src_dir / \"data/raw/huge_train_llm_aligned_v2_3_0_1300.xlsx\"), index=False)\n",
    "# data3.to_excel( str(src_dir / \"data/raw/huge_train_complex_sents_llm_v2_3.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'sentence', 'Label', 'org_groups', 'inf_relations', 'entity_1',\n",
       "       'entity_2', 'sme_relations', 'explanation', 'relation_completion',\n",
       "       'relations', 'align', 'concepts', 'concept explanation',\n",
       "       'concept_class', 'agreement_relation', 'license_relation',\n",
       "       'supply_chain_relation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sme_relations</th>\n",
       "      <th>relations</th>\n",
       "      <th>inf_relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['IMMUNOGEN INC', 'supplier', 'Roche']</td>\n",
       "      <td>[['IMMUNOGEN Inc', 'supplier', 'Roche']]</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Zhejiang Yingte Pharmaceutical Co. Ltd', 'su...</td>\n",
       "      <td>[['HuaDong Pharmaceutical Co, Ltd', 'supplier'...</td>\n",
       "      <td>supplier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['WPX', 'supplier', 'NGL Energy Partners']</td>\n",
       "      <td>[['WPX', 'supplier', 'NGL Energy Partners']]</td>\n",
       "      <td>supplier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Xilinx Inc ’s', 'supplier', 'Avnet Inc']</td>\n",
       "      <td>[['Xilinx Inc', 'supplier', 'Avnet Inc']]</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['VIAVI SOLUTIONS INC.', 'supplier', 'SICPA']</td>\n",
       "      <td>[['VIAVI SOLUTIONS Inc', 'supplier', 'SICPA']]</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sme_relations  \\\n",
       "0             ['IMMUNOGEN INC', 'supplier', 'Roche']   \n",
       "1  ['Zhejiang Yingte Pharmaceutical Co. Ltd', 'su...   \n",
       "2         ['WPX', 'supplier', 'NGL Energy Partners']   \n",
       "3         ['Xilinx Inc ’s', 'supplier', 'Avnet Inc']   \n",
       "4      ['VIAVI SOLUTIONS INC.', 'supplier', 'SICPA']   \n",
       "\n",
       "                                           relations inf_relations  \n",
       "0           [['IMMUNOGEN Inc', 'supplier', 'Roche']]      customer  \n",
       "1  [['HuaDong Pharmaceutical Co, Ltd', 'supplier'...      supplier  \n",
       "2       [['WPX', 'supplier', 'NGL Energy Partners']]      supplier  \n",
       "3          [['Xilinx Inc', 'supplier', 'Avnet Inc']]      customer  \n",
       "4     [['VIAVI SOLUTIONS Inc', 'supplier', 'SICPA']]      customer  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[[\"sme_relations\", \"relations\", \"inf_relations\" ]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = ['accession_number', 'index', 'sentence', 'Label', 'org_groups', 'inf_relations', \n",
    "                    'entity_1', 'entity_2', 'sme_relations',  'relations', \n",
    "                    'concept_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weakly_labeled_data_pos = pd.read_excel(\"./test_pipeline_data/huge_set_deduped_data/huge_train_dedup_sc_cc_re.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'index', 'accessionNumber', 'filer', 'firstEntity',\n",
       "       'relationship', 'secondEntity', 'sentence', 'sme_relations',\n",
       "       'duplicate_sentences', 'sent_size', 'clause_size', 'deduped',\n",
       "       'sc_score', 'sc_label', 'cc_class', 'cc_class_2', 'cc_class_score',\n",
       "       'cc_class_2_score', 'spans', 'org_groups', 'aliases', 'num_orgs',\n",
       "       'filtered_org_groups', 'num_orgs_filter', 're_relations', 're_score',\n",
       "       're_rel_label', 're_pred_match', 'data_status', 'matching_sent_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weakly_labeled_data_pos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sme_relations</th>\n",
       "      <th>relationship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['GLOBALFOUNDRIES Inc', 'supplier', 'AMD']</td>\n",
       "      <td>supplier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sme_relations relationship\n",
       "0  ['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...     customer\n",
       "1  ['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...     customer\n",
       "2  ['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...     customer\n",
       "3  ['ADVANCED MICRO DEVICES INC', 'supplier', 'MI...     customer\n",
       "4         ['GLOBALFOUNDRIES Inc', 'supplier', 'AMD']     supplier"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weakly_labeled_data_pos[[\"sme_relations\", \"relationship\" ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3039, 31)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc model was not confident on these sentences, but re models scored them high with correct relation, \n",
    "# sentence is matching at least 1 training row in existing training data\n",
    "\n",
    "# create a copy of weakly_labeled_data_pos with following conditions\n",
    "\n",
    "\n",
    "weakly_labeled_data_pos_1 = weakly_labeled_data_pos[(weakly_labeled_data_pos[\"sc_label\"] == 1) &\n",
    "                                                    (weakly_labeled_data_pos[\"sc_score\"] < 0.95 ) &\n",
    "                                                    (weakly_labeled_data_pos[\"re_rel_label\"].isin([\"supplier\", \"customer\"])) &\n",
    "                                                    (weakly_labeled_data_pos[\"re_score\"] > 0.95) &\n",
    "                                                    (weakly_labeled_data_pos[\"re_pred_match\"] == True) &                                                     \n",
    "                                                    (weakly_labeled_data_pos[\"matching_sent_count\"] > 0)].copy()\n",
    "\n",
    "                                                    \n",
    "weakly_labeled_data_pos_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply eval on column sme_relations\n",
    "weakly_labeled_data_pos_1.loc[:, \"sme_relations\"] = weakly_labeled_data_pos_1[\"sme_relations\"].apply(eval)\n",
    "\n",
    "\n",
    "# rename columns\n",
    "weakly_labeled_data_pos_1.rename(columns={\"accessionNumber\": \"accession_number\",\n",
    "                                         \"relationship\": \"inf_relations\", \n",
    "                                          \"firstEntity\": \"entity_1\",\n",
    "                                          \"secondEntity\": \"entity_2\"},\n",
    "                                 inplace=True)\n",
    "## Dervie columns   \n",
    "# Label\n",
    "# relations\n",
    "# concept_class\n",
    "weakly_labeled_data_pos_1.loc[:, \"Label\"] = 0\n",
    "weakly_labeled_data_pos_1.loc[:, \"relations\"] = [[sme_relation] for sme_relation in weakly_labeled_data_pos_1[\"sme_relations\"].to_list()]\n",
    "weakly_labeled_data_pos_1.loc[:, \"concept_class\"] = weakly_labeled_data_pos_1[\"cc_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labeled_data_pos_1[required_columns].to_excel( str(src_dir / \"data/raw/huge_train_pipe_labelled_pos_more_to_sc.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labeled_data_neg = pd.read_excel(\"./test_pipeline_data/huge_set_deduped_data/huge_neg_train_dedup_sc_cc_re.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Acc no', 'filer', 'secondEntity', 'sentence', 'Prediction', 'Score',\n",
       "       'relationship', 'index', 'sme_relations', 'sent_size', 'clause_size',\n",
       "       'deduped', 'duplicate_sentences', 'spans', 'org_groups', 'aliases',\n",
       "       'num_orgs', 'filtered_org_groups', 'num_orgs_filter', 'sc_score',\n",
       "       'sc_label', 'cc_class', 'cc_class_2', 'cc_class_score',\n",
       "       'cc_class_2_score', 're_relations', 're_score', 're_rel_label',\n",
       "       're_pred_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weakly_labeled_data_neg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sme_relations</th>\n",
       "      <th>relationship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['EMA Financial', 'other', '12 Retech Corp']</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['EMA Financial', 'other', '12 Retech Corp']</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['SBI Investments', 'other', '12 Retech Corp']</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['SBI Investments', 'other', '12 Retech Corp']</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['SBI Investments', 'other', '12 Retech Corp']</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sme_relations relationship\n",
       "0    ['EMA Financial', 'other', '12 Retech Corp']        other\n",
       "1    ['EMA Financial', 'other', '12 Retech Corp']        other\n",
       "2  ['SBI Investments', 'other', '12 Retech Corp']        other\n",
       "3  ['SBI Investments', 'other', '12 Retech Corp']        other\n",
       "4  ['SBI Investments', 'other', '12 Retech Corp']        other"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weakly_labeled_data_neg[[\"sme_relations\", \"relationship\" ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1137, 29)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc label is 1, but re_model corrected it to `other`, we removed re_score filter to get more data \n",
    "weakly_labeled_data_neg_1 = weakly_labeled_data_neg[ (weakly_labeled_data_neg[\"sc_label\"] == 1) &\n",
    "                                                    (weakly_labeled_data_neg[\"re_rel_label\"].isin([\"other\"])) &\n",
    "                                                    #(weakly_labeled_data_neg[\"re_score\"] > 0.95) &\n",
    "                                                    (weakly_labeled_data_neg[\"re_pred_match\"] == True)                                                      \n",
    "                                                     #(weakly_labeled_data_neg[\"matching_sent_count\"] > 0) \n",
    "                                                     ].copy()\n",
    "\n",
    "weakly_labeled_data_neg_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply eval on column sme_relations\n",
    "weakly_labeled_data_neg_1.loc[:, \"sme_relations\"] = weakly_labeled_data_neg_1[\"sme_relations\"].apply(eval)\n",
    "\n",
    "# rename columns\n",
    "weakly_labeled_data_neg_1.rename(columns={\"Acc no\": \"accession_number\",\n",
    "                                         \"relationship\": \"inf_relations\", \n",
    "                                          \"filer\": \"entity_1\",\n",
    "                                          \"secondEntity\": \"entity_2\"},\n",
    "                                 inplace=True)\n",
    "## Dervie columns   \n",
    "# Label\n",
    "# relations\n",
    "# concept_class\n",
    "weakly_labeled_data_neg_1.loc[:, \"Label\"] = 0\n",
    "weakly_labeled_data_neg_1.loc[:, \"relations\"] = [[sme_relation] for sme_relation in weakly_labeled_data_neg_1[\"sme_relations\"].to_list()]\n",
    "weakly_labeled_data_neg_1.loc[:, \"concept_class\"] = weakly_labeled_data_neg_1[\"cc_class\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accession_number', 'entity_1', 'entity_2', 'sentence', 'Prediction',\n",
       "       'Score', 'inf_relations', 'index', 'sme_relations', 'sent_size',\n",
       "       'clause_size', 'deduped', 'duplicate_sentences', 'spans', 'org_groups',\n",
       "       'aliases', 'num_orgs', 'filtered_org_groups', 'num_orgs_filter',\n",
       "       'sc_score', 'sc_label', 'cc_class', 'cc_class_2', 'cc_class_score',\n",
       "       'cc_class_2_score', 're_relations', 're_score', 're_rel_label',\n",
       "       're_pred_match', 'Label', 'relations', 'concept_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weakly_labeled_data_neg_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labeled_data_neg_1[required_columns].to_excel( str(src_dir / \"data/raw/huge_train_pipe_labelled_neg_more_to_sc.xlsx\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform LLM Data into RE Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load NER Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-25 07:48:49,728 — 🌌 spaCy — INFO — Language model used is en_core_web_trf\n",
      "2023-10-25 07:48:49,729 — 🌌 spaCy — INFO — spaCy Work On GPU\n"
     ]
    }
   ],
   "source": [
    "from src.language_model.spacy_loader import SpacyLoader\n",
    "spacy_loader = SpacyLoader(\"en_core_web_trf\",\n",
    "                           entity_matcher= str(src_dir / \"artifacts/matcher_model/\"),\n",
    "                          load_matcher=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read project configuration\n",
    "import yaml\n",
    "from src.utils.data import dict2dot\n",
    "\n",
    "\n",
    "with open(src_dir/ 'params.yaml' ,'r') as o:\n",
    "    config = dict2dot(yaml.safe_load(o))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_relations(relation, default=[]):\n",
    "    try:\n",
    "        re = eval(relation)\n",
    "    except:\n",
    "        re = default\n",
    "    return re\n",
    "\n",
    "def eval_relation_data(output, relations_map):\n",
    "    # Resort the sme_relations to unify the relations directions\n",
    "    if not isinstance(output['sme_relations'].iloc[0], list):\n",
    "        tqdm.pandas(desc=\"Eval sme_relations\")\n",
    "        output['sme_relations'] = output['sme_relations'].progress_apply(eval)\n",
    "        \n",
    "        \n",
    "    if 'relations' in output.columns:\n",
    "        if not isinstance(output['relations'].iloc[0], list):\n",
    "            tqdm.pandas(desc=\"Eval relations\")\n",
    "            output['relations'] = output['relations'].progress_apply(eval_relations)\n",
    "    else:\n",
    "        output['relations'] = None\n",
    "    if not isinstance(output['org_groups'].iloc[0], dict):\n",
    "        tqdm.pandas(desc=\"Eval org_groups\")\n",
    "        output['org_groups'] = output['org_groups'].progress_apply(eval_relations, default={})  \n",
    "    tqdm.pandas(desc=\"Resort sme relations\")\n",
    "    output['sme_relations'] = output['sme_relations'].progress_apply(lambda x:\\\n",
    "                              resort_relation((x[0], x[1], x[2]),\n",
    "                                            relations_map))\n",
    "def process_labeled_data(data,\n",
    "                         text_col:str,\n",
    "                         relation_tuple:str,\n",
    "                        relations_map:dict): \n",
    "    # Create org_groups if not exist\n",
    "    if not all([x in data.columns for x in ['spans', 'org_groups']]):\n",
    "        from src.language_model.spacy_loader import SpacyLoader\n",
    "        spacy_loader = SpacyLoader(\"en_core_web_trf\",\n",
    "                                   entity_matcher=str(src_dir/ 'artifacts/matcher_model'),\n",
    "                                  load_matcher=True)\n",
    "        sents, spans, org_groups, aliases = spacy_loader.predictor(data[text_col])\n",
    "        data[text_col]= sents\n",
    "        data.loc[:, text_col] = sents\n",
    "        data.loc[:, \"spans\"] = spans\n",
    "        data.loc[:, \"org_groups\"] = org_groups\n",
    "    # deserialize data\n",
    "    eval_relation_data(data, relations_map)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from typing import Tuple, List, Text, Dict\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "from typing import Text \n",
    "from itertools import chain\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from operator import is_not\n",
    "from functools import partial\n",
    "from src.labels_generator.utils import check_relation_tuples\n",
    "\n",
    "\n",
    "def get_other_relations(org_groups, max_others:int):\n",
    "    \"\"\"\n",
    "    Returns a list of other relations between companies based on the dictionary of company groups passed as input.\n",
    "    The maximum number of other relations is determined by the max_others parameter.\n",
    "\n",
    "    @params\n",
    "    -------\n",
    "    org_groups (dict): A dictionary with company names as keys and groups as values.\n",
    "    max_others (int): The maximum number of other relations to return.\n",
    "\n",
    "    @returns\n",
    "    --------\n",
    "    list: A list of other relations between companies.\n",
    "    \"\"\"\n",
    "    # Collect all unique company names from the org_groups dictionary\n",
    "    orgs = list(org_groups.keys())\n",
    "    orgs = {k:None for k in set(orgs)}\n",
    "\n",
    "    # Create a dictionary to map each unique company name to an ID\n",
    "    orgs_ids = {k:i for i,k in enumerate(set(orgs))}\n",
    "    ids2org = {i:k for i,k in enumerate(set(orgs_ids))}\n",
    "\n",
    "    # Create a list of all possible pair-wise combinations of the values in 'ids2org', and randomly choose max_others of those combinations\n",
    "    available_relations = []\n",
    "    comp_keys = list(ids2org.keys())\n",
    "    for i in range(len(comp_keys)):\n",
    "        for j in range(i+1, len(comp_keys)):\n",
    "            relation_t = tuple(sorted([comp_keys[i], comp_keys[j]]))\n",
    "            available_relations.append(relation_t)\n",
    "\n",
    "    other_ids = set(available_relations)\n",
    "\n",
    "    other_relations = []\n",
    "    if len(other_ids) > max_others:\n",
    "        other_ids = random.sample(list(other_ids), max_others)\n",
    "\n",
    "    # Map the IDs back to the company names and create a list of other relations\n",
    "    for pair in other_ids:\n",
    "        c1 = ids2org[pair[0]]\n",
    "        c2 = ids2org[pair[1]]\n",
    "        other_relations.append((c1,'other', c2))\n",
    "\n",
    "    return other_relations\n",
    "\n",
    "def extract_relations_from_llm(datapoint,\n",
    "                                matcher,\n",
    "                                text_col:str=\"sentence\",\n",
    "                                relations_key:str='relations',\n",
    "                                threshold:float=0.9,\n",
    "                               max_others=3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a dataset for relation extraction training.\n",
    "    @params\n",
    "    -------\n",
    "    - datapoint: A dictionary containing the following keys:\n",
    "        - org_groups: A dictionary of company names associated with an integer identifier.\n",
    "        - relations: A list of tuples representing the relationship between companies.\n",
    "    - matcher: An instance of the `StringMatcher` class.\n",
    "    - text_col: The key in the datapoint dictionary where the text to match can be found.\n",
    "    - relations_key: The key in the datapoint dictionary where the relations can be found.\n",
    "    - threshold: The similarity threshold for matching company names.\n",
    "\n",
    "    @returns\n",
    "    --------\n",
    "    - llms_relations: A list of tuples representing the relationships between companies that were successfully matched.\n",
    "    - other_relations: A list of tuples representing the relationships between companies that were not matched.\n",
    "\n",
    "    @raises\n",
    "    -------\n",
    "    - ValueError: If the relations list in the datapoint is invalid.\n",
    "    \"\"\"\n",
    "    r_others = True\n",
    "    # establish org_groups\n",
    "    group2id = datapoint['org_groups']\n",
    "    id2group = defaultdict(list)\n",
    "    for k,v in group2id.items():\n",
    "        id2group[v].append(k)\n",
    "    \n",
    "    # define llms relations\n",
    "    relations = datapoint[relations_key]\n",
    "    \n",
    "    # build index for org_groups\n",
    "    if len(group2id) > 0:\n",
    "        matcher.build_index(list(group2id.keys()))\n",
    "    \n",
    "    # Assert the relations on the right format\n",
    "    if not check_relation_tuples:\n",
    "        raise ValueError(\"Invlid relations list on the datapoint, must be List[Tuple[Text, Text, Text]]\")\n",
    "    # Collect all companies mentioned in the relations and create a dictionary with each unique company as a key\n",
    "    llms_companies = []\n",
    "    if isinstance(relations, list):\n",
    "        for relation in relations:\n",
    "            llms_companies += [relation[0] , relation[2]]\n",
    "            \n",
    "            \n",
    "    # match the llm_companies to assign id according to group2id\n",
    "    llms_co_matches = matcher.search(llms_companies, threshold=threshold, top_k=2)\\\n",
    "                      if len(llms_companies) > 0 else []\n",
    "    llms_ids = {}\n",
    "    for i,co_match in enumerate(llms_co_matches):\n",
    "        if len(co_match) > 0:\n",
    "            llms_ids[llms_companies[i]] = group2id[co_match[0][0]]\n",
    "        elif llms_companies[i] in datapoint[text_col]:\n",
    "            group2id[llms_companies[i]] = len(group2id)+1\n",
    "            id2group[len(group2id)+1] = [llms_companies[i]]\n",
    "            llms_ids[llms_companies[i]] = len(group2id)+1\n",
    "    \n",
    "    # llms_ids = {llms_companies[i]: group2id.get(x[0][0], None) \\\n",
    "    #             if len(x) > 0 else None for i,x in enumerate(llms_co_matches)}\n",
    "    \n",
    "    \n",
    "    llms_names = {k:id2group[v][0] if v is not None else None for k,v in llms_ids.items() }\n",
    "    # in case the lmm companies not all aligned with NER org_groups, don't involve other\n",
    "    if None in llms_ids.values():\n",
    "        r_others = False\n",
    "\n",
    "    ids_set = list(set(filter(partial(is_not, None), llms_ids.values())))\n",
    "        \n",
    "    availabel_relations = []\n",
    "    for i in range(len(ids_set)):\n",
    "        for j in range(i+1, len(ids_set)):\n",
    "            relation_t = tuple(sorted([ids_set[i], ids_set[j]]))\n",
    "            availabel_relations.append(relation_t)\n",
    "    exist_relations = []\n",
    "    llms_relations = []\n",
    "    if isinstance(relations, list):\n",
    "        for relation in relations:\n",
    "            c1, c1_name = relation[0], llms_names.get(relation[0])\n",
    "            c2, c2_name = relation[2], llms_names.get(relation[2])\n",
    "            relation = relation[1]\n",
    "            if None in  [c1, c2 , c1_name, c2_name]:\n",
    "                continue\n",
    "\n",
    "            llms_relations.append((c1_name, relation, c2_name))\n",
    "\n",
    "            c1_id = llms_ids.get(c1)\n",
    "            c2_id = llms_ids.get(c2)    \n",
    "            exist_relations.append(tuple(sorted([c1_id, c2_id])))\n",
    "    \n",
    "    other_ids = set(availabel_relations) ^ set(exist_relations)\n",
    "    # if len(other_ids)>max_others:\n",
    "    #     other_ids = random.sample(other_ids, max_others)\n",
    "    other_relations = []\n",
    "    if r_others:\n",
    "        for pair in list(other_ids): \n",
    "            c1 = id2group[pair[0]][0]\n",
    "            c2 = id2group[pair[1]][0]\n",
    "            other_relations.append((c1,'other', c2))\n",
    "        \n",
    "    if len(llms_relations) == 0 and len(other_relations) == 0:\n",
    "        other_relations = get_other_relations(group2id, max_others)\n",
    "        \n",
    "    return llms_relations, other_relations\n",
    "\n",
    "\n",
    "def create_re_dataset(\n",
    "                      output,\n",
    "                      matcher,\n",
    "                      text_col:str=\"sentence\",\n",
    "                      relations_key:str='relations',\n",
    "                      threshold:float=0.9,\n",
    "                      max_others:int=3,\n",
    "                      basic_columns:list=[],\n",
    "                      ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a relation extraction dataset.\n",
    "\n",
    "    @params\n",
    "    -------\n",
    "    - output: A pandas dataframe containing the following keys:\n",
    "        * sentence: A string representing a sentence containing relevant text.\n",
    "        * relations: A list of tuples representing the relationship between companies.\n",
    "    - matcher: An instance of the `StringMatcher` class.\n",
    "    - text_col: The key in the output dataframe where the text to match can be found.\n",
    "    - relations_key: The key in the output dataframe where the relations can be found.\n",
    "    - threshold: The similarity threshold for matching company names.\n",
    "\n",
    "    @returns\n",
    "    --------\n",
    "    - dataset: A pandas dataframe containing the following columns:\n",
    "    - idx: A unique identifier for the datapoint.\n",
    "    - sentence: A string representing the sentence containing relevant text.\n",
    "    - entity_2: A string representing the second entity in the relation.\n",
    "    - relation: A string representing the relation between the two entities.\n",
    "    - entity_1: A string representing the first entity in the relation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply the `extract_relations_from_llm` function to each datapoint in the output dataframe\n",
    "    results = output.apply(lambda x: extract_relations_from_llm(datapoint=x,\n",
    "                            matcher=matcher,\n",
    "                            text_col=text_col,\n",
    "                            relations_key=relations_key,\n",
    "                            threshold=threshold), axis=1)\n",
    "\n",
    "    # Create new columns in the output dataframe to store the results of the `extract_relations_from_llm` function\n",
    "    output['llm_relations']  = results.apply(lambda x : x[0])\n",
    "    output['other_relations']  = results.apply(lambda x : x[1])\n",
    "    relation_columns = ['llm_relations', 'other_relations']\n",
    "    # Create a list of all possible pair-wise combinations of the values in 'ids2org', and randomly choose 5 of those combinations\n",
    "    columns = relation_columns + [text_col, relations_key] + basic_columns\n",
    "    re_dataset = []\n",
    "    for i, row in output[columns].iterrows():\n",
    "        row = row.to_dict()\n",
    "        for r_column in relation_columns:\n",
    "            # Iterate over relations and ingest row for each relation\n",
    "            for relation_tuple in row[r_column]:\n",
    "                row['entity_2'] = relation_tuple[0]\n",
    "                row['relation'] = relation_tuple[1]\n",
    "                row['entity_1'] = relation_tuple[2]\n",
    "                re_dataset.append(dict(row))\n",
    "\n",
    "    # Return a pandas dataframe containing the relation extraction dataset\n",
    "    dataset = pd.DataFrame(re_dataset)[[ text_col,\n",
    "                                        'entity_2',\n",
    "                                        'relation',\n",
    "                                        'entity_1'] + basic_columns]\n",
    "    return dataset\n",
    "# method to add Label based on the relations columns\n",
    "def sc_label_from_relations(relation_tuples, main_relations):\n",
    "    if not relation_tuples:\n",
    "        return 0\n",
    "    if len(relation_tuples) == 0:\n",
    "        return 0\n",
    "    for relation_tuple in relation_tuples:\n",
    "        if len(relation_tuple) != 3:\n",
    "            continue\n",
    "        elif  relation_tuple[1] in main_relations:\n",
    "            return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define and read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# define configuration file of the files\n",
    "#dataset_name = \"llm_aligned_0_1_huge_complex\"\n",
    "\n",
    "dataset_name = \"llm_aligned_0_1_huge_complex\"\n",
    "\n",
    "with open(src_dir/ 'data/config/{}.yaml'.format(dataset_name)) as o:\n",
    "    data_files = yaml.safe_load(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_0': {'dir': '/notebooks/inferess-relation-extraction/data/raw/verified_train_files/llm_relations_other_from_label_0_v2_3.xlsx'},\n",
       " 'all_1': {'dir': '/notebooks/inferess-relation-extraction/data/raw/verified_train_files/llm_relations_all_label_1_v2_3.xlsx'},\n",
       " 'all_other': {'dir': '/notebooks/inferess-relation-extraction/data/raw/verified_train_files/llm_relations_other_relation_v2_3.xlsx'},\n",
       " 'huge_1': {'dir': '/notebooks/inferess-relation-extraction/data/raw/verified_train_files/huge_train_llm_aligned_v2_3_0_1300.xlsx'},\n",
       " 'huge_1_complex': {'dir': '/notebooks/inferess-relation-extraction/data/raw/verified_train_files/huge_train_complex_sents_llm_v2_3.xlsx'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assert all the keys contain directory\n",
    "assert all([x.get('dir') for x in data_files.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Prepare data to be in `RE_FORM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_0 \n",
      "--------------\n",
      "2023-10-25 07:46:39,316 — 🌌 spaCy — INFO — Language model used is en_core_web_trf\n",
      "2023-10-25 07:46:39,317 — 🌌 spaCy — INFO — spaCy Work On GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval sme_relations: 100%|██████████| 877/877 [00:00<00:00, 111860.01it/s]\n",
      "Eval relations: 100%|██████████| 877/877 [00:00<00:00, 89809.19it/s]\n",
      "Resort sme relations: 100%|██████████| 877/877 [00:00<00:00, 499647.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_1 \n",
      "--------------\n",
      "2023-10-25 07:47:01,600 — 🌌 spaCy — INFO — Language model used is en_core_web_trf\n",
      "2023-10-25 07:47:01,601 — 🌌 spaCy — INFO — spaCy Work On GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval sme_relations: 100%|██████████| 1767/1767 [00:00<00:00, 120825.82it/s]\n",
      "Eval relations: 100%|██████████| 1767/1767 [00:00<00:00, 73791.62it/s]\n",
      "Resort sme relations: 100%|██████████| 1767/1767 [00:00<00:00, 330700.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_other \n",
      "--------------\n",
      "2023-10-25 07:47:13,609 — 🌌 spaCy — INFO — Language model used is en_core_web_trf\n",
      "2023-10-25 07:47:13,610 — 🌌 spaCy — INFO — spaCy Work On GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval sme_relations: 100%|██████████| 111/111 [00:00<00:00, 78883.05it/s]\n",
      "Eval relations: 100%|██████████| 111/111 [00:00<00:00, 217656.73it/s]\n",
      "Resort sme relations: 100%|██████████| 111/111 [00:00<00:00, 280631.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huge_1 \n",
      "--------------\n",
      "2023-10-25 07:47:17,562 — 🌌 spaCy — INFO — Language model used is en_core_web_trf\n",
      "2023-10-25 07:47:17,563 — 🌌 spaCy — INFO — spaCy Work On GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval sme_relations: 100%|██████████| 688/688 [00:00<00:00, 115816.39it/s]\n",
      "Eval relations: 100%|██████████| 688/688 [00:00<00:00, 73933.06it/s]\n",
      "Resort sme relations: 100%|██████████| 688/688 [00:00<00:00, 492773.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huge_1_complex \n",
      "--------------\n",
      "2023-10-25 07:47:24,253 — 🌌 spaCy — INFO — Language model used is en_core_web_trf\n",
      "2023-10-25 07:47:24,254 — 🌌 spaCy — INFO — spaCy Work On GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval sme_relations: 100%|██████████| 1550/1550 [00:00<00:00, 106995.79it/s]\n",
      "Eval relations: 100%|██████████| 1550/1550 [00:00<00:00, 78174.78it/s]\n",
      "Resort sme relations: 100%|██████████| 1550/1550 [00:00<00:00, 493784.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# read file and store each into it's coresponding key_value\n",
    "for key in list(data_files.keys()):\n",
    "    print(key,'\\n--------------')\n",
    "    data_files[key]['data'] = pd.read_excel(data_files[key]['dir'])\n",
    "    process_labeled_data(data_files[key]['data'], \"sentence\", \"relations\", relations_map)\n",
    "    data_files[key]['data']['idx'] = [\"{}_{}\".format(key, i)\\\n",
    "                                      for i in range(data_files[key]['data'].shape[0])]\n",
    "    data_files[key]['data']['Label'] = data_files[key]['data']['relations']\\\n",
    "                                        .apply(lambda x : sc_label_from_relations(x, main_relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_0', 'all_1', 'all_other', 'huge_1', 'huge_1_complex'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in all_0: Index(['index', 'sentence', 'Label', 'org_groups', 'inf_relations', 'entity_1',\n",
      "       'entity_2', 'sme_relations', 'explanation', 'relation_completion',\n",
      "       'relations', 'align', 'rd_conflict', 'concepts', 'concept explanation',\n",
      "       'concept_class', 'spans', 'idx'],\n",
      "      dtype='object')\n",
      "------------------------------------------------------------\n",
      "Columns in all_1: Index(['index', 'sentence', 'Label', 'org_groups', 'inf_relations', 'entity_1',\n",
      "       'entity_2', 'sme_relations', 'explanation', 'relation_completion',\n",
      "       'relations', 'align', 'concepts', 'concept explanation',\n",
      "       'concept_class', 'agreement_relation', 'license_relation',\n",
      "       'supply_chain_relation', 'spans', 'idx'],\n",
      "      dtype='object')\n",
      "------------------------------------------------------------\n",
      "Columns in all_other: Index(['index', 'sentence', 'Label', 'org_groups', 'inf_relations', 'entity_1',\n",
      "       'entity_2', 'sme_relations', 'explanation', 'relation_completion',\n",
      "       'relations', 'align', 'concepts', 'concept explanation',\n",
      "       'concept_class', 'spans', 'idx'],\n",
      "      dtype='object')\n",
      "------------------------------------------------------------\n",
      "Columns in huge_1: Index(['index', 'accessionNumber', 'filer', 'firstEntity', 'relationship',\n",
      "       'secondEntity', 'sentence', 'sme_relations', 'explanation',\n",
      "       'relation_completion', 'relations', 'align', 'concepts',\n",
      "       'concept explanation', 'concept_class', 'agreement_relation',\n",
      "       'license_relation', 'spans', 'org_groups', 'idx', 'Label'],\n",
      "      dtype='object')\n",
      "------------------------------------------------------------\n",
      "Columns in huge_1_complex: Index(['index', 'accessionNumber', 'filer', 'firstEntity', 'relationship',\n",
      "       'secondEntity', 'sentence', 'sme_relations', 'sent_size', 'clause_size',\n",
      "       'concepts', 'concept explanation', 'explanation', 'relation_completion',\n",
      "       'relations', 'align', 'rd_conflict', 'concept_class',\n",
      "       'supply_chain_relation', 'agreement_relation', 'license_relation',\n",
      "       'spans', 'org_groups', 'idx', 'Label'],\n",
      "      dtype='object')\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in list(data_files.keys()):\n",
    "    print(\"Columns in {}: {}\".format(key,data_files[key]['data'].columns))    \n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create `RE_FORM` dataset for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Label', 'concept_class', 'idx', 'org_groups', 'spans']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.base.basic_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/25/2023 07:48:58 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
      "10/25/2023 07:48:58 - INFO - faiss.loader -   Successfully loaded faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_0 \n",
      "--------------\n",
      "all_1 \n",
      "--------------\n",
      "all_other \n",
      "--------------\n",
      "huge_1 \n",
      "--------------\n",
      "huge_1_complex \n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# read file and store each into it's coresponding key_value\n",
    "for key in list(data_files.keys()):\n",
    "    print(key,'\\n--------------' )\n",
    "    dataset = create_re_dataset(output=data_files[key]['data'],\n",
    "                           matcher=spacy_loader.entity_matcher,\n",
    "                           text_col=\"sentence\",\n",
    "                           relations_key=\"relations\",\n",
    "                           threshold=0.9,\n",
    "                           max_others=1,\n",
    "                           basic_columns=config.base.basic_columns)\n",
    "    data_files[key]['dataset'] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset= pd.concat([data_files[k]['dataset'] for k in data_files.keys()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other              6824\n",
       "supplier           6619\n",
       "financial_trade    1225\n",
       "nothing             145\n",
       "Name: relation, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset.relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_2</th>\n",
       "      <th>relation</th>\n",
       "      <th>entity_1</th>\n",
       "      <th>Label</th>\n",
       "      <th>concept_class</th>\n",
       "      <th>idx</th>\n",
       "      <th>org_groups</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For the fiscal year ended March 31, 2017, two ...</td>\n",
       "      <td>HuaDong Pharmaceutical Co, Ltd</td>\n",
       "      <td>supplier</td>\n",
       "      <td>CHINA JO JO DRUGSTORES Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>all_1_0</td>\n",
       "      <td>{'Zhejiang Yingte Pharmaceutical Co Ltd': 0, '...</td>\n",
       "      <td>[{'text': 'the fiscal year ended March 31, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For the fiscal year ended March 31, 2017, two ...</td>\n",
       "      <td>Zhejiang Yingte Pharmaceutical Co Ltd</td>\n",
       "      <td>supplier</td>\n",
       "      <td>CHINA JO JO DRUGSTORES Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>all_1_0</td>\n",
       "      <td>{'Zhejiang Yingte Pharmaceutical Co Ltd': 0, '...</td>\n",
       "      <td>[{'text': 'the fiscal year ended March 31, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since NGL Energy Partners December 2013 acquis...</td>\n",
       "      <td>WPX</td>\n",
       "      <td>supplier</td>\n",
       "      <td>NGL Energy Partners</td>\n",
       "      <td>1</td>\n",
       "      <td>investment_related</td>\n",
       "      <td>all_1_1</td>\n",
       "      <td>{'NGL Energy Partners': 0, 'Gavilon Energy': 1...</td>\n",
       "      <td>[{'text': 'NGL Energy Partners', 'label': 'ORG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avnet Inc, one of Xilinx Inc ’s distributors, ...</td>\n",
       "      <td>Xilinx Inc ’s</td>\n",
       "      <td>supplier</td>\n",
       "      <td>Avnet Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>supply_chain</td>\n",
       "      <td>all_1_2</td>\n",
       "      <td>{'Xilinx Inc ’s': 0, 'Xilinx Inc’s': 0, 'Avnet...</td>\n",
       "      <td>[{'text': 'Avnet Inc', 'label': 'ORG', 'start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Under a license and supply agreement, VIAVI SO...</td>\n",
       "      <td>VIAVI SOLUTIONS Inc</td>\n",
       "      <td>supplier</td>\n",
       "      <td>SICPA</td>\n",
       "      <td>1</td>\n",
       "      <td>licensing_and_ip</td>\n",
       "      <td>all_1_3</td>\n",
       "      <td>{'VIAVI SOLUTIONS Inc': 0, 'SICPA': 2}</td>\n",
       "      <td>[{'text': 'VIAVI SOLUTIONS Inc', 'label': 'ORG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>QUALCOMM INC/DE reports that QTL accounts rece...</td>\n",
       "      <td>QUALCOMM INC/DE</td>\n",
       "      <td>supplier</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>huge_1_complex_1547</td>\n",
       "      <td>{'QUALCOMM INC/DE': 0, 'Huawei': 1, 'vivo': 2,...</td>\n",
       "      <td>[{'text': 'QUALCOMM INC/DE', 'label': 'ORG', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>QUALCOMM INC/DE reports that QTL accounts rece...</td>\n",
       "      <td>QUALCOMM INC/DE</td>\n",
       "      <td>supplier</td>\n",
       "      <td>Oppo</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>huge_1_complex_1547</td>\n",
       "      <td>{'QUALCOMM INC/DE': 0, 'Huawei': 1, 'vivo': 2,...</td>\n",
       "      <td>[{'text': 'QUALCOMM INC/DE', 'label': 'ORG', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>QUALCOMM INC/DE reports that QTL accounts rece...</td>\n",
       "      <td>QUALCOMM INC/DE</td>\n",
       "      <td>supplier</td>\n",
       "      <td>vivo</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>huge_1_complex_1547</td>\n",
       "      <td>{'QUALCOMM INC/DE': 0, 'Huawei': 1, 'vivo': 2,...</td>\n",
       "      <td>[{'text': 'QUALCOMM INC/DE', 'label': 'ORG', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>Certain of QUALCOMM Inc largest integrated cir...</td>\n",
       "      <td>QUALCOMM Inc</td>\n",
       "      <td>supplier</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>huge_1_complex_1548</td>\n",
       "      <td>{'QUALCOMM Inc': 0, 'Samsung': 1}</td>\n",
       "      <td>[{'text': 'QUALCOMM Inc', 'label': 'ORG', 'sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>However, TSMC also fabricates wafers for other...</td>\n",
       "      <td>TSMC</td>\n",
       "      <td>supplier</td>\n",
       "      <td>Broadcom Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>huge_1_complex_1549</td>\n",
       "      <td>{'Broadcom Inc': 0, 'TSMC': 1}</td>\n",
       "      <td>[{'text': 'TSMC', 'label': 'ORG', 'start': 9, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6619 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     For the fiscal year ended March 31, 2017, two ...   \n",
       "1     For the fiscal year ended March 31, 2017, two ...   \n",
       "3     Since NGL Energy Partners December 2013 acquis...   \n",
       "4     Avnet Inc, one of Xilinx Inc ’s distributors, ...   \n",
       "5     Under a license and supply agreement, VIAVI SO...   \n",
       "...                                                 ...   \n",
       "4031  QUALCOMM INC/DE reports that QTL accounts rece...   \n",
       "4032  QUALCOMM INC/DE reports that QTL accounts rece...   \n",
       "4033  QUALCOMM INC/DE reports that QTL accounts rece...   \n",
       "4037  Certain of QUALCOMM Inc largest integrated cir...   \n",
       "4038  However, TSMC also fabricates wafers for other...   \n",
       "\n",
       "                                   entity_2  relation  \\\n",
       "0            HuaDong Pharmaceutical Co, Ltd  supplier   \n",
       "1     Zhejiang Yingte Pharmaceutical Co Ltd  supplier   \n",
       "3                                       WPX  supplier   \n",
       "4                             Xilinx Inc ’s  supplier   \n",
       "5                       VIAVI SOLUTIONS Inc  supplier   \n",
       "...                                     ...       ...   \n",
       "4031                        QUALCOMM INC/DE  supplier   \n",
       "4032                        QUALCOMM INC/DE  supplier   \n",
       "4033                        QUALCOMM INC/DE  supplier   \n",
       "4037                           QUALCOMM Inc  supplier   \n",
       "4038                                   TSMC  supplier   \n",
       "\n",
       "                        entity_1  Label       concept_class  \\\n",
       "0     CHINA JO JO DRUGSTORES Inc      1             revenue   \n",
       "1     CHINA JO JO DRUGSTORES Inc      1             revenue   \n",
       "3            NGL Energy Partners      1  investment_related   \n",
       "4                      Avnet Inc      1        supply_chain   \n",
       "5                          SICPA      1    licensing_and_ip   \n",
       "...                          ...    ...                 ...   \n",
       "4031                      Huawei      1             revenue   \n",
       "4032                        Oppo      1             revenue   \n",
       "4033                        vivo      1             revenue   \n",
       "4037                     Samsung      1             unknown   \n",
       "4038                Broadcom Inc      1             unknown   \n",
       "\n",
       "                      idx                                         org_groups  \\\n",
       "0                 all_1_0  {'Zhejiang Yingte Pharmaceutical Co Ltd': 0, '...   \n",
       "1                 all_1_0  {'Zhejiang Yingte Pharmaceutical Co Ltd': 0, '...   \n",
       "3                 all_1_1  {'NGL Energy Partners': 0, 'Gavilon Energy': 1...   \n",
       "4                 all_1_2  {'Xilinx Inc ’s': 0, 'Xilinx Inc’s': 0, 'Avnet...   \n",
       "5                 all_1_3             {'VIAVI SOLUTIONS Inc': 0, 'SICPA': 2}   \n",
       "...                   ...                                                ...   \n",
       "4031  huge_1_complex_1547  {'QUALCOMM INC/DE': 0, 'Huawei': 1, 'vivo': 2,...   \n",
       "4032  huge_1_complex_1547  {'QUALCOMM INC/DE': 0, 'Huawei': 1, 'vivo': 2,...   \n",
       "4033  huge_1_complex_1547  {'QUALCOMM INC/DE': 0, 'Huawei': 1, 'vivo': 2,...   \n",
       "4037  huge_1_complex_1548                  {'QUALCOMM Inc': 0, 'Samsung': 1}   \n",
       "4038  huge_1_complex_1549                     {'Broadcom Inc': 0, 'TSMC': 1}   \n",
       "\n",
       "                                                  spans  \n",
       "0     [{'text': 'the fiscal year ended March 31, 201...  \n",
       "1     [{'text': 'the fiscal year ended March 31, 201...  \n",
       "3     [{'text': 'NGL Energy Partners', 'label': 'ORG...  \n",
       "4     [{'text': 'Avnet Inc', 'label': 'ORG', 'start'...  \n",
       "5     [{'text': 'VIAVI SOLUTIONS Inc', 'label': 'ORG...  \n",
       "...                                                 ...  \n",
       "4031  [{'text': 'QUALCOMM INC/DE', 'label': 'ORG', '...  \n",
       "4032  [{'text': 'QUALCOMM INC/DE', 'label': 'ORG', '...  \n",
       "4033  [{'text': 'QUALCOMM INC/DE', 'label': 'ORG', '...  \n",
       "4037  [{'text': 'QUALCOMM Inc', 'label': 'ORG', 'sta...  \n",
       "4038  [{'text': 'TSMC', 'label': 'ORG', 'start': 9, ...  \n",
       "\n",
       "[6619 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4871,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset['idx'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset for concept classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_class_remapping = {'agreement': ['supply_purchase_agreement',\n",
    "               'services agreement',\n",
    "               'agreement_and_partnership'],\n",
    "'licensing_and_ip': ['royalties',\n",
    "                     'licensing_and_ip',\n",
    "                     'legal_and_regulatory'],\n",
    "'supply_chain': ['supply_chain', 'product_related'],\n",
    "'revenue': ['revenue', 'royalties'],\n",
    "'real_estate': ['real_estate'],\n",
    "'financial_statements': ['investment_related', 'financial_statements'],\n",
    "'other': ['unknown'] \n",
    "}\n",
    "\n",
    "# reverse the mapping\n",
    "reverse_concept_class_remapping = {}\n",
    "for k,v in concept_class_remapping.items():\n",
    "    for x in v:\n",
    "        reverse_concept_class_remapping[x] = k  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap the concept class\n",
    "all_dataset[\"concept_class_remapped\"] = all_dataset[\"concept_class\"].apply(lambda x: reverse_concept_class_remapping.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't include other class\n",
    "all_dataset = all_dataset[all_dataset[\"concept_class_remapped\"] != \"other\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "revenue                 6532\n",
       "supply_chain            2590\n",
       "agreement               1863\n",
       "licensing_and_ip        1201\n",
       "financial_statements    1152\n",
       "real_estate              256\n",
       "Name: concept_class_remapped, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset[\"concept_class_remapped\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Check dataset health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.preprocess import word_search, Intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "founded1 = all_dataset.apply(lambda x : word_search(x['entity_1'], x['sentence']), axis =1 )\n",
    "founded2 = all_dataset.apply(lambda x : word_search(x['entity_2'], x['sentence']), axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_2</th>\n",
       "      <th>relation</th>\n",
       "      <th>entity_1</th>\n",
       "      <th>Label</th>\n",
       "      <th>concept_class</th>\n",
       "      <th>idx</th>\n",
       "      <th>org_groups</th>\n",
       "      <th>spans</th>\n",
       "      <th>concept_class_remapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, entity_2, relation, entity_1, Label, concept_class, idx, org_groups, spans, concept_class_remapped]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "all_dataset[founded2.apply(len) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(founded1.apply(len) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(founded2.apply(len) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(founded1.apply(len) == 0).sum()==0,(founded2.apply(len) == 0).sum()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other              6204\n",
       "supplier           6171\n",
       "financial_trade    1075\n",
       "nothing             144\n",
       "Name: relation, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load previous dataset\n",
    "# previous_dataset = pd.read_json(str(src_dir / \"data/raw/llm_aligned_0_1_huge_complex.json\"))\n",
    "\n",
    "# previous_dataset = previous_dataset[['sentence', 'entity_2', 'relation', 'entity_1', 'Label', \n",
    "#                                      'concept_class', 'idx', 'org_groups', 'spans']]\n",
    "\n",
    "\n",
    "# # concat the previous dataset with the new one\n",
    "# combined_all_dataset = pd.concat([all_dataset, previous_dataset], axis=0)\n",
    "\n",
    "\n",
    "# combined_all_dataset.reset_index(drop=True).to_json(src_dir / 'data/raw/llm_aligned_0_1_huge_complex.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.reset_index(drop=True).to_json(src_dir / 'data/raw/llm_aligned_0_1_huge_complex.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
