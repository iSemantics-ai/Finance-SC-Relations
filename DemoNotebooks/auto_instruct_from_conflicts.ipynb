{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Basic Dependencies_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KE\")\n",
    "\n",
    "current_path = Path.cwd()\n",
    "src_dir = current_path.parent\n",
    "sys.path.append(str(src_dir))\n",
    "# import annotation methods\n",
    "from src.labels_generator.instructor_util import (generate_relations,relation_search,resort_relation, get_completion,\n",
    "                                  deserialize_json_dict2,\n",
    "                                  generate_relations_with_explanation,\n",
    "                                  relations_tupled_2,\n",
    "                                 create_sorted_relation)\n",
    "\n",
    "# Load matcher\n",
    "from src.matcher.core import SimCSE_Matcher\n",
    "matcher = SimCSE_Matcher(str(src_dir/ 'artifacts/matcher_model'))\n",
    "\n",
    "\n",
    "replaces = {\"sentence\": \"{sentence}\"}\n",
    "# Replace the keys with values for unified relation direction\n",
    "relations_map = {\"customer\": \"supplier\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **_`LLM Annotator`_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm_annotator.py\n",
    "import os\n",
    "import openai\n",
    "from glob import glob\n",
    "from typing import List, Tuple, Union\n",
    "from typing import Dict, Text\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "from colorama import Fore\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys \n",
    "src_dir = Path.cwd().parent\n",
    "sys.path.append(str(src_dir)) \n",
    "from src.matcher.core import SimCSE_Matcher\n",
    "from src.utils import get_logger, dotdict\n",
    "\n",
    "\n",
    "\n",
    "dataset_columns = ['sentence', 'org_groups']\n",
    "valid_models =[\"gpt-3.5-turbo\"]\n",
    "\n",
    "main_relations = ['supplier', 'customer']\n",
    "inverse = {\"customer\":\"supplier\", \"supplier\":\"customer\", \"other\":\"other\"}\n",
    "explanation_tags = [\"{sentence}\", \"{instructions}\"]\n",
    "labeling_tags = [\"{explanation}\"]\n",
    "confirm_tags = [\"{company1}\", \"{company2}\", \"{relation}\" , \"{explanation}\"]\n",
    "\n",
    "class LLMAnnotator(object):\n",
    "    \"\"\"This module contains code that generates prompt templates for Language Model\n",
    "        APIs, such as OpenAI's GPT-3. The prompts are designed to help generate labeled\n",
    "        datasets for training Relation Extraction models.\n",
    "\n",
    "        The template consists of three prompts:\n",
    "\n",
    "        1. Explanation prompt: This prompt is used to explain certain aspects of a given\n",
    "        sentence. It is designed to help the user identify the entities and relations\n",
    "        in the sentence.\n",
    "\n",
    "        2. Label generation prompt: This prompt is responsible for generating a JSON\n",
    "        object that contains the label for the given sentence. The label includes the\n",
    "        type of relation between the entities and any additional information that may\n",
    "        be relevant.\n",
    "\n",
    "        3. Confirmation prompt: This prompt is used to curate the final label generated\n",
    "        by the previous prompt. It allows the user to review and modify the label as\n",
    "        needed.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, version, matcher_device='cpu'):\n",
    "        self.logger = get_logger('\\U0001F300 LLMAnnotator', log_level=\"INFO\")\n",
    "        versions_dirs = set(filter(None, [v if not '.dvc' in v else None for v in glob(str(src_dir / 'data/llms_datasets/templates/v*'))]))\n",
    "        print(\"versions_dirs\", versions_dirs, str(src_dir / 'data/llms_datasets/templates/v*'))\n",
    "        \n",
    "        self._versions = list(sorted([float(v.split('/')[-1][1:]) for v in versions_dirs]))\n",
    "        # Validate the version\n",
    "        if version not in self._versions:\n",
    "            raise (f\"Invalid template, The available _versions are {self._versions}\")\n",
    "        self.version = version\n",
    "        self.logger.info(\"Loading template card...\")\n",
    "        # Reading template card\n",
    "        with open(src_dir / f\"data/llms_datasets/templates/v{str(version)}/card.yaml\") as ob:\n",
    "            self.card = dotdict(yaml.safe_load(ob))\n",
    "        # identify instruction for annotation\n",
    "        self._sme_definitions = src_dir / f\"data/llms_datasets/templates/v{str(version)}/sme_definitions.yaml\"\n",
    "        self._llm_definitions = src_dir / f\"data/llms_datasets/templates/v{str(version)}/llm_definitions.yaml\"\n",
    "        # \n",
    "        self.outdir = src_dir / f\"data/llms_datasets/templates/v{str(version)}/output\"\n",
    "        self.outdir.mkdir(parents=True, exist_ok=True)\n",
    "        # read sme instrctions\n",
    "        with open(self._sme_definitions,\"r\") as ob:\n",
    "            self.sme_definitions =  yaml.safe_load(ob)\n",
    "        # read llm instrctions\n",
    "        with open(self._llm_definitions,\"r\") as ob:\n",
    "            self.llm_definitions =  yaml.safe_load(ob)\n",
    "        # Use only approved examples\n",
    "        self.valid_instructions = list(self.sme_definitions.keys())\n",
    "        # Add only approved definitions from llm \n",
    "        self.valid_instructions += list(filter(None, [k if v['approved'] == True \\\n",
    "                                else None for k,v in self.llm_definitions.items()]))\n",
    "            \n",
    "        # Define conflict directory\n",
    "        self._conflict_path = src_dir /f\"data/llms_datasets/templates/v{self.version}/reports/conflict_sme_llm_trainset.json\"\n",
    "        # Load entity matcher\n",
    "        self.matcher  = SimCSE_Matcher('princeton-nlp/sup-simcse-roberta-base', device=matcher_device)\n",
    "        if self.valid_instructions is not None:\n",
    "            self.matcher.build_index(self.valid_instructions)\n",
    "        else:\n",
    "            self.logger.info(\"no instructions provided for annoation\")\n",
    "        # initiate the labelled data\n",
    "        self._ground_truth  = None\n",
    "\n",
    "    @property\n",
    "    def unlabeled(self):\n",
    "        suffix = (src_dir / self.card['dataset']).suffix\n",
    "        if  suffix == '.json':\n",
    "            pd.read_json(src_dir / self.card['dataset'])\n",
    "        elif suffix == '.xlsx':\n",
    "            return pd.read_excel(src_dir / self.card['dataset'], index_col=\"index\" )\n",
    "\n",
    "    @property\n",
    "    def conflicts(self):\n",
    "        if os.path.isfile(self._conflict_path):\n",
    "            return pd.read_json(self._conflict_path)\n",
    "        else:\n",
    "            self.logger.info(\"No conflicts had been detected the conflict file might be not exist or target dataset not labeled!!!\")\n",
    "\n",
    "\n",
    "    \n",
    "    def insert_llm_definition(self, items:dict):\n",
    "        for definition, values in items.items():\n",
    "            if self.llm_definitions.get(definition, None) is not None:\n",
    "                continue\n",
    "            self.llm_definitions[definition] = values\n",
    "        with open(self._llm_definitions, 'w') as ob:\n",
    "            yaml.safe_dump(self.llm_definitions, ob)\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_completion(self, prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = None\n",
    "        while not response:\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=self.card['model'],\n",
    "                    messages=messages,\n",
    "                    temperature=self.card['temperature'] # this is the degree of randomness of the model's output\n",
    "                )\n",
    "            except:\n",
    "                time.sleep(0.2)\n",
    "            \n",
    "        return response.choices[0].message[\"content\"]\n",
    "    \n",
    "    def update_template(self):\n",
    "        new_template = self.card.copy()\n",
    "        \n",
    "        for item in new_template.keys():\n",
    "            text = f\"Insert {Fore.BLUE}`{item}`{Fore.RESET}\\nPrevious one:\\n{Fore.LIGHTCYAN_EX}{new_template[item]}\\n\"\n",
    "            print(text)\n",
    "            input_item = input()\n",
    "            print(f\"{'*'*50}\\n\")\n",
    "            if input_item:\n",
    "                new_template[item] = input_item\n",
    "        if self.card == new_template:\n",
    "            print(\"No changes founded\")\n",
    "        else:\n",
    "            # TODO: validate the new template\n",
    "            # If Vaild \n",
    "            # pprint the new template and ask  for confirmation\n",
    "            #print(\"The new template\\n\", Fore.CYAN, json.dumps(new_template, indent=4),'\\n', \"*\"*50)\n",
    "            print(\"#### New Template ####\\n######################\\n\")\n",
    "            for k,v in new_template.items():\n",
    "                print(f'{k}\\n--------------\\n{Fore.GREEN}{v}{Fore.RESET}\\n{\"*\"*50}\\n')\n",
    "            confirm  = input(\"Confirm the changes?(y|n)\")\n",
    "            if confirm == 'y':\n",
    "                new_version = round(max(self._versions)+0.1, 2)\n",
    "                # Validate the data\n",
    "                if self.card['dataset'] != new_template['dataset']:\n",
    "                    # Read file\n",
    "                    new_data = pd.read_json(new_template['dataset'])\n",
    "                    # Check required columns\n",
    "                    if not all([x in new_data.columns for x in dataset_columns]):\n",
    "                        raise(f\"Invalid dataset must contains {dataset_columns}\")\n",
    "\n",
    "                # Validate templates \n",
    "                if new_template['model'] not in valid_models:\n",
    "                    raise Exception(f\"invalid open-ai model, Valid Models: {valid_models}\")\n",
    "                    \n",
    "                if self.card['explanation_prompt'] != new_template[\"explanation_prompt\"]:\n",
    "                    if not all([x in new_template[\"explanation_prompt\"] for x in explanation_tags]):\n",
    "                        raise Exception(f\"Invalid prompt for explanation, must include [{explanation_tags}]\")\n",
    "                        \n",
    "                if self.card['labeling_prompt'] != new_template[\"labeling_prompt\"]:\n",
    "                    if not all([x in new_template[\"labeling_prompt\"] for x in labeling_tags]):\n",
    "                        raise Exception(f\"Invalid prompt for labeling, must include [{labeling_tags}]\")\n",
    "                        \n",
    "                if self.card['confirmation_prompt'] != new_template[\"confirmation_prompt\"]:\n",
    "                    if not all([x in new_template[\"confirmation_prompt\"] for x in confirm_tags]):\n",
    "                        raise Exception(f\"Invalid prompt for confirmation, must include [{confirm_tags}]\")\n",
    "                \n",
    "                # Create the directory and the card of the template\n",
    "                version_dir = str(src_dir / f\"data/llms_datasets/templates/v{new_version}\") \n",
    "                os.mkdir(version_dir)\n",
    "                os.mkdir(version_dir+'/data')\n",
    "                with open (version_dir+'/card.yaml', 'w')as obj:\n",
    "                    yaml.safe_dump(new_template, obj)\n",
    "                \n",
    "                print(f\"Create new template with version {new_version}\")\n",
    "    \n",
    "    def overwrite_card(self):\n",
    "        \"\"\"\n",
    "        Write the current state of the `card` dictionary to the `card.yaml` file.\n",
    "        \"\"\"\n",
    "        with open(src_dir / f\"data/llms_datasets/templates/v{str(self.version)}/card.yaml\", 'w') as ob:\n",
    "            yaml.safe_dump(self.card, ob)\n",
    "\n",
    "    def update_instructions(self, command: Text, instruction: Text, overwrite: bool = True) -> bool:\n",
    "        \"\"\"\n",
    "        Update the `instructions` set in the `card` dictionary using the provided `command` and `instruction`.\n",
    "\n",
    "        Args:\n",
    "            command (Text): The name of the method to call on the `instructions` set.\n",
    "            instruction (Text): The argument to the method specified in `command`.\n",
    "            overwrite (bool, optional): Whether to overwrite the `card.yaml` file. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether the update was successful.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.instructions.__getattribute__(command)(instruction)\n",
    "            if overwrite:\n",
    "                self.overwrite_card()\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_terms(sentence:Text, mask:Dict, mask_word:Text, demask=False):\n",
    "        if demask:\n",
    "            for v,k in dict(sorted(mask.items(),\n",
    "                                    key=lambda item:item[1],\n",
    "                                    reverse=True)).items():\n",
    "                sentence = sentence.replace(f\"{mask_word}{k}\",v)\n",
    "        else:\n",
    "            for k,v in dict(sorted(mask.items(),\n",
    "                                    key=lambda item:item[1],\n",
    "                                    reverse=True)).items():\n",
    "                sentence = sentence.replace(k,f\"{mask_word}{v}\")\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_to_str(rules_dict):\n",
    "        str_out = ''\n",
    "        for key, values in rules_dict.items():\n",
    "            str_out += \"- {}:\\n\".format(key)\n",
    "            str_out += '\\t- ' + '\\n\\t- '.join(values) + '\\n'\n",
    "        return str_out\n",
    "        \n",
    "    def generate_explanation_prompt(self,\n",
    "                                    sentence,\n",
    "                                    org_groups=None,\n",
    "                                    use_llm_definitions=True,\n",
    "                                    candidate_definition=False,\n",
    "                                    custom_definitions=None):\n",
    "        \"\"\"\n",
    "        Generate an explanation prompt based on the given inputs.\n",
    "\n",
    "        @params:\n",
    "        -------\n",
    "        - sentence (str): The sentence to generate the prompt for.\n",
    "        - org_groups (list): Optional. List of organizational groups to mask in the sentence.\n",
    "        - use_llm_definitions (bool): Optional. Flag to indicate whether to include LLM definitions in the prompt.\n",
    "        - candidate_definition (bool): Optional. Flag to indicate whether to include candidate definitions in the prompt.\n",
    "\n",
    "        @returns:\n",
    "        ---------\n",
    "        - str: The generated explanation prompt.\n",
    "\n",
    "        \"\"\"\n",
    "        prompt = self.card['explanation_prompt']\n",
    "        # If org_groups are given mask the `Orgs` on the query\n",
    "        if org_groups:\n",
    "            sentence = LLMAnnotator.mask_terms(sentence=sentence,\n",
    "                                               mask=org_groups,\n",
    "                                               mask_word=\"Company\")\n",
    "        # create_explanation_prompt\n",
    "        explanation_prompt = str(self.card.explanation_prompt)\n",
    "        # Create definitions\n",
    "        definitions = ''\n",
    "        output_rules = ''\n",
    "        cand_definitions = None\n",
    "        # Select slice of definitions based on semantic similarity between query and all the definitions\n",
    "        \n",
    "        if custom_definitions:\n",
    "            for definition in custom_definitions:\n",
    "                definitions += '- {}\\n'.format(definition)  \n",
    "        \n",
    "        elif candidate_definition:\n",
    "            cand_definitions = {x[0]:x[1] for x in self.matcher.search(sentence, threshold=0.1, top_k=10)} \n",
    "            \n",
    "            for definition in cand_definitions.keys():\n",
    "                definitions += '- {}\\n'.format(definition)\n",
    "\n",
    "        else:\n",
    "            for definition in self.sme_definitions.keys():\n",
    "                definitions += '- {}\\n'.format(definition)\n",
    "\n",
    "        for output_rule in self.card.explanation_output_rules:\n",
    "            if isinstance(output_rule, dict):\n",
    "                output_rules += dict_to_str(output_rule)\n",
    "            else:\n",
    "                output_rules += \"- {}\\n\".format(output_rule)\n",
    "\n",
    "        explanation_prompt = explanation_prompt.replace('{sentence}', sentence)\n",
    "        explanation_prompt = explanation_prompt.replace('{definitions}', definitions)\n",
    "        explanation_prompt = explanation_prompt.replace('{explanation_output_rules}', output_rules)\n",
    "\n",
    "        return explanation_prompt\n",
    "\n",
    "\n",
    "    def generate_relation_prompt(self, explanation):\n",
    "        prompt = self.card['labeling_prompt']\n",
    "        prompt = prompt.replace('{explanation}',  explanation)\n",
    "        return prompt\n",
    "\n",
    "    def generate_confirmation(self, company1, company2, relation, explanation):\n",
    "        prompt = self.card['confirmation_prompt']\n",
    "        prompt = prompt.replace('{company1}',  company1)\n",
    "        prompt = prompt.replace('{company2}',  company2)\n",
    "        prompt = prompt.replace('{explanation}',  explanation)\n",
    "        prompt = prompt.replace('{relation}',  relation)\n",
    "        return prompt\n",
    "        \n",
    "    def annotate(self, datapoint):\n",
    "        \"\"\"\n",
    "        Annotates a datapoint with explanations, relations, and confirmations if they do not already exist.\n",
    "\n",
    "        Args:\n",
    "            datapoint (dict): A dictionary representing a datapoint.\n",
    "\n",
    "        Returns:\n",
    "            dict: The annotated datapoint.\n",
    "        \"\"\"\n",
    "        if not datapoint.get('explanation'): \n",
    "            # If the datapoint does not have an explanation, generate an explanation prompt and get the completion.\n",
    "            datapoint['explanation_prompt'] = self.generate_explanation_prompt(sentence=datapoint['sentence'],\n",
    "                                                                               org_groups=datapoint.get('org_groups'))\n",
    "            \n",
    "            explanation = self.get_completion(datapoint['explanation_prompt'])\n",
    "            datapoint['explanation'] = LLMAnnotator.mask_terms(sentence = explanation,\n",
    "                            mask=datapoint.get('org_groups'),\n",
    "                            mask_word=\"Company\", \n",
    "                            demask=True)\n",
    "            \n",
    "            \n",
    "        if not datapoint.get('ser_relations'):\n",
    "            # If the datapoint does not have a relation, generate a relation prompt and get the completion.\n",
    "            datapoint['relation_prompt'] = self.generate_relation_prompt(datapoint['explanation'])\n",
    "            datapoint['ser_relations'] = self.get_completion(datapoint['relation_prompt'])\n",
    "            try:\n",
    "                datapoint['relations'] = deserialize_relations(datapoint['ser_relations'])\n",
    "                llms_relations, other_relations = establish_company_relations(datapoint, self.matcher)\n",
    "                datapoint['llms_relations'] = llms_relations\n",
    "                datapoint['other_relations'] = other_relations\n",
    "\n",
    "            except:\n",
    "                datapoint['relations'] = 'undefined'\n",
    "                datapoint['llms_relations'] = 'undefined'\n",
    "                datapoint['other_relations'] = 'undefined'\n",
    "\n",
    "        if not datapoint.get('confirmation') and self.card.get('confirm'):\n",
    "            # If the datapoint does not have a confirmation, generate a confirmation prompt and get the completion.\n",
    "            if datapoint['relations'] == 'undefined':\n",
    "                datapoint['confirmation_prompt'] = 'undefined'\n",
    "                datapoint['confirmation'] = 'undefined'\n",
    "            else:\n",
    "                datapoint['confirmation_prompt'] = self.generate_confirmation(datapoint['company1'],\n",
    "                                                        datapoint['company2'],\n",
    "                                                        datapoint['relations'],\n",
    "                                                        datapoint['explanation'])\n",
    "                datapoint['confirmation'] = self.get_completion(datapoint['confirmation_prompt'])\n",
    "        return datapoint\n",
    "    \n",
    "    def generate_labels(self, batch:Tuple[int,int]):\n",
    "        batch_name = f'batch_{batch[0]}_{batch[1]}.json'\n",
    "        file_name = src_dir / f'data/llms_datasets/templates/v{str(self.version)}/data/{batch_name}'\n",
    "        if os.path.exists(file_name):\n",
    "            self.logger.info(\"This batch is already exist\")\n",
    "            data = pd.read_json(file_name)\n",
    "            data = pd.concat([data ,\n",
    "                              self.unlabeled_data[len(data)+batch[0]:batch[1]]], axis = 0)                \n",
    "        else:   \n",
    "            data = self.unlabeled_data[batch[0]:batch[1]]\n",
    "        annotations = []\n",
    "        count  = 0\n",
    "        for i, datapoint in tqdm(data.iterrows(), total= data.shape[0]):\n",
    "            datapoint = datapoint.to_dict()\n",
    "            datapoint['index'] = i\n",
    "            if self.card.get('tagged'):\n",
    "                annotations.append(self.annotate(datapoint))                 \n",
    "            else: \n",
    "                # Annotate all possible pairs\n",
    "                datapoint_pairs= LLMAnnotator.get_random_company_pairs(datapoint['org_groups'],\n",
    "                                                                      self.card.get(\"max_rel\", 7))\n",
    "                for pair in datapoint_pairs:\n",
    "                    db_pair = datapoint.copy()\n",
    "                    db_pair['company1'] = pair[0]\n",
    "                    db_pair['company2'] = pair[1]\n",
    "                    # self.logger.info(f\"For {pair}, we have datapoint: \\n{datapoint}\")\n",
    "                    annotations.append(self.annotate(db_pair))\n",
    "            count += 1\n",
    "                \n",
    "            if (count%10) == 0:\n",
    "                pd.DataFrame(annotations).to_json(file_name)\n",
    "        pd.DataFrame(annotations).to_json(file_name)\n",
    "        return pd.DataFrame(annotations)\n",
    "\n",
    "    def is_conflict(self, row: Dict, threshold: float = 0.85) -> Tuple[bool, Tuple[str, str, str]]:\n",
    "        \"\"\"\n",
    "        Check if there is a conflict between two entities based on their expected relation and their actual relations.\n",
    "\n",
    "        Args:\n",
    "        - row (Dict): A dictionary containing the information about the entities and their relations.\n",
    "        - threshold (float): A float value between 0 and 1 that determines the minimum similarity score for the relations to be considered aligned.\n",
    "\n",
    "        Returns:\n",
    "        - A tuple containing a boolean value indicating whether the relations are aligned or not, and a tuple of the two entities and their expected relation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize the value of align to False until we prove otherwise.\n",
    "        align = False\n",
    "        \n",
    "        # Define the two entities to search for.\n",
    "        c1 = row.get('entity_1')\n",
    "        c2 = row.get('entity_2')\n",
    "        \n",
    "        # Determine the expected relation between c2 and c1.\n",
    "        expected_relation = row.get('inf_relations')\n",
    "        \n",
    "        # Get the organization groups and the SME relation.\n",
    "        org_groups  = row.get('org_groups')\n",
    "        sme_relation = (c2, expected_relation, c1)\n",
    "        \n",
    "        # Initialize defaultdict to carry org_ids as keys with values carrying all companies and their aliases.\n",
    "        id2c = defaultdict(lambda: [])\n",
    "            \n",
    "        # Group the companies by their organization ID.\n",
    "        for k,v in org_groups.items():\n",
    "            id2c[v].append(k)\n",
    "        \n",
    "        # Set the expected relation to \"other\" if the label is 0.\n",
    "        if row.get('Label') == 0:\n",
    "            expected_relation = \"other\"\n",
    "        \n",
    "        # Set the SME relation based on the main relations.\n",
    "        elif main_relations[0] == expected_relation:\n",
    "            sme_relation = (c2,main_relations[0], c1)\n",
    "        elif main_relations[1] == expected_relation:\n",
    "            sme_relation = (c1,main_relations[0], c2)\n",
    "            \n",
    "        # Initialize defaultdict to carry supplier names as keys with values carrying customer names.\n",
    "        llm_relations= defaultdict(lambda : [])\n",
    "        \n",
    "        # Get all the supplier-customer relations.\n",
    "        if isinstance(row['llms_relations'], list):\n",
    "            for llm_relation in row['llms_relations']:\n",
    "                if llm_relation[1] == 'supplier':\n",
    "                    supplier = llm_relation[0]\n",
    "                    supplier_id = org_groups.get(supplier)\n",
    "                    supplier_names = id2c[supplier_id] if supplier_id else [supplier]\n",
    "                    \n",
    "                    customer = llm_relation[2]\n",
    "                    customer_id = org_groups.get(customer)\n",
    "                    customer_names = id2c[customer_id] if customer_id else [customer]\n",
    "                    \n",
    "                    for supplier_name in supplier_names:\n",
    "                        llm_relations[supplier_name] += customer_names\n",
    "        \n",
    "        # Get the supplier names.\n",
    "        llm_suppliers = list(llm_relations.keys())\n",
    "        \n",
    "        # Check if the relation had been detected\n",
    "        expected_supplier = sme_relation[0]\n",
    "        expected_customer = sme_relation[2]\n",
    "        \n",
    "        # If the expected relation is \"other\".\n",
    "        if expected_relation == \"other\":\n",
    "            # If there is no relation between the reporter and other companies.\n",
    "            if len(llm_relations) == 0:\n",
    "                align = True\n",
    "            # If there are relations between the reporter and other companies.\n",
    "            else:\n",
    "                # Check if the supplier is found in the llm_relations.\n",
    "                align = not self.matcher.similarity(expected_supplier,list(llm_relations.keys())).max() > threshold\n",
    "        \n",
    "        # If the expected relation is not \"other\".\n",
    "        else:\n",
    "            # If there are relations between the reporter and other companies.\n",
    "            if len(llm_relations) > 0:\n",
    "                # Get the similarity scores between the expected supplier and the llm_suppliers.\n",
    "                sim_scores = self.matcher.similarity(expected_supplier, llm_suppliers)\n",
    "                max_score = sim_scores.max()\n",
    "                max_idx  = sim_scores.argmax()\n",
    "                \n",
    "                # If the maximum similarity score is greater than the threshold or the expected supplier is found in the llm_suppliers.\n",
    "                if max_score > threshold  or any([expected_supplier in x for x in llm_suppliers  ]):\n",
    "                    # Check if the expected customer is found in the llm_relations.\n",
    "                    align = self.matcher.similarity(expected_customer,llm_relations[llm_suppliers[max_idx]] ).max() > threshold \\\n",
    "                            or any([[expected_customer.lower() in x.lower() for x in y] for y in llm_relations[llm_suppliers[max_idx]]  ])\n",
    "        \n",
    "        # Return the align and sme_relation values.\n",
    "        return align, sme_relation\n",
    "    \n",
    "    def detect_conflicts(self, threshold:float=0.85,save:bool = True)->pd.DataFrame:\n",
    "        '''Search conflicts within llms annotator compared with ground truth labels\n",
    "        '''\n",
    "        # Read generated labels\n",
    "        llm_labels = pd.read_json(f\"data/llms_datasets/templates/v{self.version}/labels/labels.json\")\n",
    "        llm_labels = llm_labels.query(\"inf_relations.notnull()\")\n",
    "\n",
    "        # Determine the basic two lists: sme_relations (expert annotations) and align_bool (True if llms align with ground truth).\n",
    "        sme_relations = []\n",
    "        align_bool = []\n",
    "        for i, row in tqdm(llm_labels.iterrows(), total=llm_labels.shape[0]):\n",
    "            align, sme_relation = self.is_conflict(row.to_dict(), threshold=threshold)\n",
    "            align_bool.append(align)\n",
    "            sme_relations.append(sme_relation)\n",
    "\n",
    "        llm_labels['sme_relations'] = sme_relations\n",
    "        llm_labels['align'] = align_bool\n",
    "\n",
    "        true_ratio = llm_labels.query(\"align == True\").shape[0] / llm_labels.shape[0]\n",
    "        self.logger.info(\"Alignment percentage: {:.2f}%\".format(true_ratio*100))\n",
    "        conflicts = llm_labels.query(\"align == False\")\n",
    "\n",
    "        if save:\n",
    "            if not os.path.exists(f\"data/llms_datasets/templates/v{self.version}/reports\"):\n",
    "                os.mkdir(f\"data/llms_datasets/templates/v{self.version}/reports\")\n",
    "            conflicts.to_json(self._conflict_path, index=True)\n",
    "        return conflicts\n",
    "\n",
    "    @staticmethod\n",
    "    def get_companies_and_relation(relation: dict) -> tuple:\n",
    "        \"\"\"\n",
    "        Extracts the companies and relation from a dictionary.\n",
    "\n",
    "        Parameters:\n",
    "        relation (dict): A dictionary containing the relation between two companies.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the first company, the relation, and the second company in the relation.\n",
    "\n",
    "        Example:\n",
    "        >>> relation = {'company_1': 'Health Net Inc.', 'relation': 'supplier', 'company_2': 'LA Care'}\n",
    "        >>> get_companies_and_relation(relation)\n",
    "        ('Health Net Inc.', 'supplier', 'LA Care')\n",
    "        \"\"\"\n",
    "        keys = np.array(list(relation.keys()))\n",
    "\n",
    "        # Get the index of the 'relation' key in the dictionary\n",
    "        relation_idx = np.where(keys == 'relation')[0][0]\n",
    "\n",
    "        # Get the first and second company names based on the 'relation' key index\n",
    "        company_1 = relation[keys[relation_idx-1] if relation_idx > 0 else keys[1]]\n",
    "        company_2 = relation[keys[relation_idx+1] if relation_idx<len(keys) else keys[0]]\n",
    "\n",
    "        return company_1, relation['relation'], company_2\n",
    "    @staticmethod\n",
    "    def get_random_company_pairs(org_groups, max_relation=5):\n",
    "        \"\"\"\n",
    "        Returns a list of randomly-selected pairs of companies from a dictionary of company groups.\n",
    "\n",
    "        Parameters:\n",
    "            org_groups (dict): A dictionary mapping company keys to group values.\n",
    "            max_relation (int): The maximum number of pairs to return.\n",
    "\n",
    "        Returns:\n",
    "            A list of randomly-selected pairs of companies.\n",
    "        \"\"\"\n",
    "        # Create a dictionary called 'ids2org' that maps each value in 'org_groups' to a list of keys that have that value\n",
    "        ids2org = defaultdict(lambda : [])\n",
    "        for key ,val in org_groups.items():\n",
    "            ids2org[val].append(key)\n",
    "\n",
    "        # Create a list of all possible pair-wise combinations of the values in 'ids2org', and randomly choose 5 of those combinations\n",
    "        availabel_relations = []\n",
    "        comp_keys = list(ids2org.keys())\n",
    "        for i in range(len(comp_keys)):\n",
    "            for j in range(i+1, len(comp_keys)):\n",
    "                relation_t = comp_keys[i], comp_keys[j]\n",
    "                availabel_relations.append(relation_t)\n",
    "\n",
    "        # For each of the 5 chosen combinations, randomly choose one key from each group of 'org_groups'\n",
    "        #  that corresponds to the two values in the combination\n",
    "        n_relations = max_relation if len(availabel_relations) > max_relation else len(availabel_relations)\n",
    "        random_pairs = random.sample(availabel_relations, n_relations)\n",
    "        company_pairs = []\n",
    "        for pair in random_pairs:\n",
    "            company1 = random.choice(ids2org[pair[0]])\n",
    "            company2 = random.choice(ids2org[pair[1]])\n",
    "            company_pairs.append((company1, company2))\n",
    "        return company_pairs\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def establish_company_relations(datapoint, matcher):\n",
    "    \"\"\"\n",
    "    Assigns relationships between companies based on certain criteria.\n",
    "\n",
    "    Args:\n",
    "        datapoint (dict): A dictionary containing the sentence to be processed.\n",
    "        matcher (object): An instance of the fuzzywuzzy string matching class.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the LLMS relations and other relations.\n",
    "\n",
    "    \"\"\"\n",
    "    global main_relations\n",
    "    global inverse\n",
    "    org_groups = datapoint['org_groups']\n",
    "    relations = datapoint['relations']\n",
    "    matcher_built = False\n",
    "    # Collect all companies mentioned in the relations and create a dictionary with each unique company as a key\n",
    "    llms_companies = []\n",
    "    for relation in relations:\n",
    "        llms_companies += [relation.get('company_1'), relation.get('company_2')]\n",
    "    llms_companies = {k:None for k in set(llms_companies)}\n",
    "    llms_ids = {k:i for i,k in enumerate(set(llms_companies))}\n",
    "    ids_llms = {i:k for i,k in enumerate(set(llms_companies))}\n",
    "    # Check if each company in the dictionary is mentioned in the sentence, and if not, try to match it with a known organization\n",
    "    for company in list(llms_companies.keys()):\n",
    "        if company in datapoint['sentence']:\n",
    "            llms_companies[company] = company\n",
    "        else:\n",
    "            if matcher_built is False: \n",
    "                matcher.build_index(list(org_groups.keys()))\n",
    "                matcher_built = True\n",
    "            \n",
    "            matches = matcher.search(company, threshold=0.95, top_k = 3)\n",
    "            if len(matches) > 0:\n",
    "                llms_companies[company] = matches[0][0]\n",
    "            else:\n",
    "                llms_companies.pop(company)\n",
    "                ids_llms.pop(llms_ids.pop(company))\n",
    "\n",
    "    # Create a dictionary called 'ids2org' that maps each value in 'org_groups' to a list of keys that have that value\n",
    "    ids2org = defaultdict(lambda : [])\n",
    "    for key ,val in llms_ids.items():\n",
    "        ids2org[val].append(key)\n",
    "\n",
    "    # Create a list of all possible pair-wise combinations of the values in 'ids2org', and randomly choose 5 of those combinations\n",
    "    availabel_relations = []\n",
    "    comp_keys = list(ids2org.keys())\n",
    "    for i in range(len(comp_keys)):\n",
    "        for j in range(i+1, len(comp_keys)):\n",
    "            relation_t = tuple(sorted([comp_keys[i], comp_keys[j]]))\n",
    "            availabel_relations.append(relation_t)\n",
    "    exist_relations = []\n",
    "    llms_relations = []\n",
    "    for relation in relations:\n",
    "        c1 = relation.get('company_1')\n",
    "        c2 = relation.get('company_2')\n",
    "        if not all([c1 in llms_companies.keys() , c2 in llms_companies.keys()]):\n",
    "            continue\n",
    "        relation = relation.get('relation')\n",
    "        if main_relations[0] == relation:\n",
    "            llms_relations.append((c1,main_relations[0], c2))\n",
    "        elif main_relations[1] == relation:\n",
    "            llms_relations.append((c2,main_relations[0], c1))\n",
    "        else:\n",
    "            llms_relations.append((c1, relation, c2))\n",
    "        \n",
    "        if not all([c1,c2,relation]):\n",
    "            continue \n",
    "        c1_id = llms_ids.get(c1)\n",
    "        c2_id = llms_ids.get(c2)    \n",
    "        exist_relations.append(tuple(sorted([c1_id, c2_id])))\n",
    "        \n",
    "    other_ids = set(availabel_relations) ^ set(exist_relations)\n",
    "    other_relations = []\n",
    "    for pair in other_ids: \n",
    "        c1 = llms_companies[ids_llms[pair[0]]]\n",
    "        c2 = llms_companies[ids_llms[pair[1]]]    \n",
    "        other_relations.append((c1,'other', c2))\n",
    "    return llms_relations, other_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_`LLM Instructor`_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "from typing import List, Tuple, Text \n",
    "from src.utils import get_logger\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "from src.labels_generator.llm_annotator import establish_company_relations, main_relations\n",
    "src_dir = Path.cwd().parent\n",
    "sys.path.append(str(src_dir))\n",
    "from src.labels_generator.instructor_util import deserialize_json_dict2, relations_tupled_2\n",
    "# from src.labels_generator import LLMAnnotator\n",
    "from src.labels_generator.utils import relation_search\n",
    "\n",
    "class LLMInstructor(LLMAnnotator):\n",
    "    def __init__(self, version,\n",
    "                matcher_device='cpu',\n",
    "                deserialize_func = deserialize_json_dict2,\n",
    "                tuple_func= relations_tupled_2\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Initializes an LLMInstructor object.\n",
    "        Tasks expected from that module:\n",
    "        - Find conflicts and generate definition to resolve conflicted points\n",
    "        - Provide list of rules attached with attr\n",
    "\n",
    "        Args:\n",
    "        - version (str): the version of the LLM model to use\n",
    "        - matcher_device (str): the device to use for the matcher model (default: 'cpu')\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        super().__init__(version, matcher_device)\n",
    "        self.logger = get_logger('\\U0001F300 LLMInstructor', log_level=\"INFO\")\n",
    "        self.name = 'llm-instructor'\n",
    "        self.deserialize_func = deserialize_func\n",
    "        self.tuple_func = tuple_func\n",
    "        self._ground_truth = None\n",
    "        self.default_relation_columns = ['entity_2', 'inf_relations', 'entity_1','Label']\n",
    "\n",
    "    @property\n",
    "    def ground_truth(self):\n",
    "        if isinstance(self._ground_truth, pd.DataFrame):\n",
    "            return self._ground_truth\n",
    "        else: \n",
    "            self.logger.warn(\"No facts loaded, please use `load_facts` to read labelled data\")\n",
    "            \n",
    "        \n",
    "    def load_facts(self,\n",
    "                   path: Path,\n",
    "                   feature_column:str,\n",
    "                   relation_columns: List[str],\n",
    "                   **kwargs):\n",
    "        \"\"\"\n",
    "        Load labelled data from a specified path, considering different file formats.\n",
    "\n",
    "        #params:\n",
    "        --------\n",
    "        - path (Path): The path to the data file.\n",
    "        - relation_columns (List[str]): List of column names containing relation data.\n",
    "        - **kwargs: Additional keyword arguments for data reading (e.g., for pandas read_json or read_excel).\n",
    "\n",
    "        @raises:\n",
    "        --------\n",
    "        - ValueError: If the 'path' argument is not an instance of 'Path'.\n",
    "        - FileExistsError: If the file format is not supported (not .json or .xlsx).\n",
    "        \"\"\"\n",
    "        self.feature = feature_column\n",
    "        \n",
    "        if not isinstance(path, Path):\n",
    "            raise ValueError(\"Invalid path type, must be Path from pathlib\")\n",
    "\n",
    "        suffix = path.suffix\n",
    "        self.facts_source = path\n",
    "        if suffix == '.json':\n",
    "            self._ground_truth = pd.read_json(path, **kwargs)\n",
    "        elif suffix == '.xlsx':\n",
    "            self._ground_truth = pd.read_excel(path, **kwargs)\n",
    "        else:\n",
    "            raise FileExistsError(\"Invalid path, must be .json or .xlsx\")\n",
    "\n",
    "        if \"sme_relations\" in self._ground_truth.columns:\n",
    "            # Process sme_relations to unify relation directions\n",
    "            if not isinstance(self._ground_truth['sme_relations'].iloc[0], list):\n",
    "                tqdm.pandas(desc=\"Evaluate sme_relations\")\n",
    "                self._ground_truth['sme_relations'] = self._ground_truth['sme_relations'].progress_apply(eval)\n",
    "            tqdm.pandas(desc=\"Resort sme relations\")\n",
    "            self._ground_truth['sme_relations'] = self._ground_truth['sme_relations'].progress_apply(lambda x:\n",
    "                resort_relation((x[0], x[1], x[2]), self.card.relations_map))\n",
    "\n",
    "        else:\n",
    "            tqdm.pandas(desc=\"Create sme_relations column\")\n",
    "            relation_columns = relation_columns or self.default_relation_columns\n",
    "            self._ground_truth['sme_relations'] = self._ground_truth[relation_columns].progress_apply(lambda x:\n",
    "                create_sorted_relation(x[0], x[1], x[2], x[3], relations_map=self.card.relations_map),\n",
    "                axis=1)\n",
    "        \n",
    "    def generate_rule_prompt(self, sentence: str,\n",
    "                             fact: Tuple[str],\n",
    "                             source_idx: int,\n",
    "                             compelition=True) -> str:\n",
    "        \"\"\"\n",
    "        Generates a rule prompt by replacing placeholders in a card's rule_prompt template.\n",
    "\n",
    "        @params:\n",
    "        --------\n",
    "        - sentence (str): The main sentence to be inserted into the rule_prompt.\n",
    "        - facts (Tuple[str]): A tuple of facts to be incorporated into the rule_prompt.\n",
    "        - source_idx (int): Index of the source for the rule_prompt.\n",
    "\n",
    "        @returns:\n",
    "        ---------\n",
    "        - str: The generated rule prompt with placeholders replaced.\n",
    "\n",
    "        @raises:\n",
    "        --------\n",
    "        - ValueError: If the card does not contain a rule_prompt.\n",
    "\n",
    "        \"\"\"\n",
    "        # Retrieve the rule_prompt template from the card\n",
    "        rule_prompt = str(self.card.get('rule_prompt'))\n",
    "\n",
    "        # Check if rule_prompt exists in the card\n",
    "        if not rule_prompt:\n",
    "            raise ValueError(\"Card must contain rule_prompt\")\n",
    "\n",
    "        # Replace placeholders in the rule_prompt template\n",
    "        rule_prompt = rule_prompt.replace(\"{sentence}\", sentence)\n",
    "        facts_str = ''\n",
    "        facts_str += '{} {} {}'.format(fact[0], self.card[f\"{fact[1]}_expression\"], fact[2])\n",
    "        if fact[1] in main_relations:\n",
    "            facts_str += '{} {} {}'.format(fact[2], self.card[f\"{inverse[fact[1]]}_expression\"], fact[0])\n",
    "        \n",
    "        # Add facts and intro phrases of each relation\n",
    "        rule_prompt = rule_prompt.replace(\"{facts}\", facts_str)\n",
    "        rule_prompt = rule_prompt.replace(\"{intro}\", self.card[f\"{fact[1]}_intro\"])\n",
    "        if compelition:\n",
    "            llm_definitions = self.get_completion(prompt=rule_prompt)\n",
    "            return llm_definitions\n",
    "        return rule_prompt\n",
    "    \n",
    "    \n",
    "    def annotate_point(self,\n",
    "                       row,\n",
    "                       candidate_definition=True,\n",
    "                       custom_definitions=None):\n",
    "        row[\"exp_prompt\"] = self.generate_explanation_prompt(row[self.feature],\n",
    "                                                             candidate_definition=candidate_definition,\n",
    "                                                             custom_definitions=custom_definitions)\n",
    "        # Generate relations and parse it\n",
    "        explanation = self.get_completion(prompt=row[\"exp_prompt\"])\n",
    "        row['explanation'] = explanation\n",
    "        #row['rel_prompt'] = self.generate_relation_prompt(explanation)\n",
    "        #relation_completion = get_completion(prompt=row['rel_prompt'])\n",
    "        #row['relation_completion'] = relation_completion\n",
    "\n",
    "        # try:\n",
    "        row['explanation'] = eval(row['explanation']) #or explanation\n",
    "        row['relations'] = self.tuple_func(row['explanation'])\n",
    "        row['defintions'] = [x['span with definition']['definition'] for x in row['explanation']]\n",
    "        row['relation_phrase']  = [x['relation phrase'] for x in row['explanation']]\n",
    "        \n",
    "        matched_defintions = self.matcher.search(row['defintions'], threshold=0.9, top_k=1)\n",
    "        semantic_score = 0\n",
    "        if len(matched_defintions[0]) > 0 : \n",
    "            row['matched_definitions'] = [x[0][0] for x in matched_defintions ]\\\n",
    "                                         if len(matched_defintions)> 0  else None\n",
    "            semantic_score = annotator.matcher.similarity(row[\"matched_definitions\"], row[self.feature])\n",
    "        # Test if annotation aligns\n",
    "        align = False\n",
    "        if isinstance(row['relations'], list):\n",
    "            align = relation_search(row['sme_relations'], row['relations'], annotator.matcher)\n",
    "\n",
    "        row[\"source_file\"] = str(annotator.facts_source)\n",
    "        row[\"semantic_score\"] = round(float(semantic_score.max()), 3)\n",
    "        row[\"align\"] = align\n",
    "            \n",
    "        return row\n",
    "        \n",
    "    def extract_rules(self, row):\n",
    "        \"\"\"\n",
    "        Extract rules based on the given row.\n",
    "\n",
    "        @params:\n",
    "        --------\n",
    "        - row (dict): The row containing the necessary information.\n",
    "\n",
    "        @returns:\n",
    "        ---------\n",
    "        - dict: The generated definitions and their corresponding information.\n",
    "\n",
    "        \"\"\"\n",
    "        _generated_definitions = {}\n",
    "        # Generate definitions to solve certain pattern\n",
    "        out = self.generate_rule_prompt(sentence=row[self.feature],\n",
    "                                        fact=row['sme_relations'],\n",
    "                                        source_idx=row['idx'],\n",
    "                                        compelition=True)\n",
    "        # Deserialize the output\n",
    "        llm_definitions = deserialize_json_dict2(out)\n",
    "        llm_definitions = list(llm_definitions.values())\n",
    "        # Calculate the semantic similarity between the definition and the report\n",
    "        semantic_scores = self.matcher.similarity(llm_definitions, row[self.feature])\n",
    "        # Return only sentences semantically similar with threshold > 0.5\n",
    "        indices = np.where(semantic_scores > 0.4)[0]\n",
    "        # Annotate the report with the generated definition for validation\n",
    "        valid_definitions = {llm_definitions[i]: semantic_scores[i] for i in indices}\n",
    "        if len(valid_definitions) == 0:\n",
    "            return {}\n",
    "        for definition, semantic_score in valid_definitions.items():\n",
    "            # Ingest the definition into the definitions dataset\n",
    "            annotation = self.annotate_point(dict(row), custom_definitions=[definition])\n",
    "            # Identify if definition solved the pattern\n",
    "            if isinstance(annotation['relations'], list):\n",
    "                align = relation_search(annotation['sme_relations'], annotation['relations'], self.matcher)\n",
    "            else:\n",
    "                align = False\n",
    "            _generated_definitions[definition] = {\n",
    "                                                  \"sentence\": annotation[self.feature],\n",
    "                                                  \"source_file\": str(self.facts_source),\n",
    "                                                  \"source_idx\": annotation['idx'],\n",
    "                                                  \"source_align\": align,\n",
    "                                                  \"source_semantic_score\": round(float(semantic_score[0]), 3),\n",
    "                                                  \"approved\": False,\n",
    "                                                  \"rejected\": False,\n",
    "                                                  \"type\": \"LLM\"}\n",
    "\n",
    "            self.logger.info(\"sentence: {}\\ndefinition: {}\\nrelation_phrase: {}\\nalign: {}\"\n",
    "                             .format(annotation[self.feature],\n",
    "                                     definition,\n",
    "                                     annotation['relation_phrase'],\n",
    "                                     align))\n",
    "        return _generated_definitions\n",
    "\n",
    "    def discover_rules(self, b_start=None, b_end=None):\n",
    "        \"\"\"\n",
    "        Extract rules based on the provided data batch.\n",
    "\n",
    "        @params:\n",
    "        --------\n",
    "        - b_start (int): Optional. Start index of the data batch.\n",
    "        - b_end (int): Optional. End index of the data batch.\n",
    "\n",
    "        @returns:\n",
    "        ---------\n",
    "        None\n",
    "        \"\"\"\n",
    "        b_start = b_start or 0\n",
    "        b_end = b_end or len(annotator.ground_truth)\n",
    "        data_batch = annotator._ground_truth[b_start:b_end]\n",
    "        _definitions_records = []\n",
    "        _generated_definitions = []\n",
    "\n",
    "        for i, row in tqdm(data_batch.iterrows(),\n",
    "                           total=len(data_batch),\n",
    "                           desc=\"Searching rules\"):\n",
    "            row = row.to_dict()\n",
    "            row['idx'] = i\n",
    "\n",
    "            # Annotate with LLM\n",
    "            row = annotator.annotate_point(row, candidate_definition=True)\n",
    "\n",
    "            # Test if annotation aligns\n",
    "            align = False\n",
    "            if isinstance(row['relations'], list):\n",
    "                align = relation_search(row['sme_relations'], row['relations'], annotator.matcher)\n",
    "\n",
    "            semantic_score = 0\n",
    "            if len(row.get(\"matched_definitions\", [])) > 0:\n",
    "                semantic_score = annotator.matcher.similarity(row[\"matched_definitions\"], row[self.feature])\n",
    "\n",
    "            row[\"source_file\"] = str(annotator.facts_source)\n",
    "            row[\"semantic_score\"] = round(float(semantic_score.max()), 3)\n",
    "            row[\"align\"] = align\n",
    "            _definitions_records.append(row)\n",
    "\n",
    "            if align is False:\n",
    "                print(\"resolve definition for following sentence\\n: {}\".format(row[self.feature]))\n",
    "                _llm_definitions = annotator.extract_rules(row)\n",
    "                _generated_definitions.append(_llm_definitions)\n",
    "                # annotator.insert_instruction(_llm_definitions)\n",
    "        pd.DataFrame(_definitions_records).to_excel(self.outdir/f'b{b_start}_b{b_end}_{self.facts_source.name}')\n",
    "        for _definition in _generated_definitions:\n",
    "            annotator.insert_llm_definition(_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# _Using LLMInstructor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions_dirs {'/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v1.5', '/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v1.7', '/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v1.8', '/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v2.0', '/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v1.9', '/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v1.6', '/notebooks/inferess-relation-extraction/data/llms_datasets/templates/v2.4'} /notebooks/inferess-relation-extraction/data/llms_datasets/templates/v*\n",
      "2023-11-21 13:06:35,922 — 🌀 LLMAnnotator — INFO — Loading template card...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate sme_relations: 100%|██████████| 2910/2910 [00:00<00:00, 102014.52it/s]\n",
      "Resort sme relations: 100%|██████████| 2910/2910 [00:00<00:00, 451701.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['annotate',\n",
       " 'annotate_point',\n",
       " 'detect_conflicts',\n",
       " 'dict_to_str',\n",
       " 'discover_rules',\n",
       " 'extract_rules',\n",
       " 'generate_confirmation',\n",
       " 'generate_explanation_prompt',\n",
       " 'generate_labels',\n",
       " 'generate_relation_prompt',\n",
       " 'generate_rule_prompt',\n",
       " 'get_companies_and_relation',\n",
       " 'get_completion',\n",
       " 'get_random_company_pairs',\n",
       " 'insert_llm_definition',\n",
       " 'is_conflict',\n",
       " 'load_facts',\n",
       " 'mask_terms',\n",
       " 'overwrite_card',\n",
       " 'update_instructions',\n",
       " 'update_template']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real the data\n",
    "version = 2.4\n",
    "annotator = LLMInstructor(version=version)\n",
    "methods = [method for method in dir(LLMInstructor) if callable(getattr(LLMInstructor, method)) and not method.startswith(\"__\")]\n",
    "\n",
    "#Load Facts\n",
    "annotator.load_facts(src_dir / \"data/tasks/finetune_llm_on_label_1/source_data.xlsx\",\n",
    "                     feature_column=\"sentence\",\n",
    "                     index_col='index',\n",
    "                     relation_columns=[\"entity_2\", \"inf_relations\", \"entity_1\", \"Label\"])\n",
    "methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract rules from annotated table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce6e623eb447feb0abca23a88b5249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Searching rules:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolve definition for following sentence\n",
      ": Since NGL Energy Partners December 2013 acquisition of Gavilon Energy, NGL Energy Partners have purchased crude oil and natural gas from and sold crude oil and natural gas to WPX.\n",
      "2023-10-07 23:14:19,948 — 🌀 LLMInstructor — INFO — sentence: Since NGL Energy Partners December 2013 acquisition of Gavilon Energy, NGL Energy Partners have purchased crude oil and natural gas from and sold crude oil and natural gas to WPX.\n",
      "definition: Supplier companies may be referred to as entities from which another company purchases goods or services.\n",
      "relation_phrase: ['NGL Energy Partners is a customer of WPX.']\n",
      "align: True\n",
      "resolve definition for following sentence\n",
      ": On August 7, 2007, Sypris Solutions Inc entered into a comprehensive settlement agreement with Dana to resolve all outstanding disputes between the parties, terminate previously approved arbitration payments and replace three existing supply agreements with a single, revised contract running through 2014.\n",
      "2023-10-07 23:14:28,366 — 🌀 LLMInstructor — INFO — sentence: On August 7, 2007, Sypris Solutions Inc entered into a comprehensive settlement agreement with Dana to resolve all outstanding disputes between the parties, terminate previously approved arbitration payments and replace three existing supply agreements with a single, revised contract running through 2014.\n",
      "definition: There is no relation between companies when they enter into a comprehensive settlement agreement to resolve disputes.\n",
      "relation_phrase: ['Sypris Solutions Inc is nothing to Dana']\n",
      "align: True\n",
      "2023-10-07 23:14:31,151 — 🌀 LLMInstructor — INFO — sentence: On August 7, 2007, Sypris Solutions Inc entered into a comprehensive settlement agreement with Dana to resolve all outstanding disputes between the parties, terminate previously approved arbitration payments and replace three existing supply agreements with a single, revised contract running through 2014.\n",
      "definition: There is no relation between companies when they terminate previous agreements and replace them with a new contract.\n",
      "relation_phrase: ['Sypris Solutions Inc is nothing to Dana']\n",
      "align: True\n",
      "resolve definition for following sentence\n",
      ": Avnet Inc, one of Xilinx Inc ’s distributors, distributes Xilinx Inc’s products worldwide.\n",
      "2023-10-07 23:14:37,428 — 🌀 LLMInstructor — INFO — sentence: Avnet Inc, one of Xilinx Inc ’s distributors, distributes Xilinx Inc’s products worldwide.\n",
      "definition: Supplier companies may be referred to as distributors who distribute products worldwide for their customers.\n",
      "relation_phrase: ['Avnet Inc is a supplier of Xilinx Inc']\n",
      "align: False\n",
      "2023-10-07 23:14:40,424 — 🌀 LLMInstructor — INFO — sentence: Avnet Inc, one of Xilinx Inc ’s distributors, distributes Xilinx Inc’s products worldwide.\n",
      "definition: Customer companies may be referred to as distributors who source and distribute products from their suppliers.\n",
      "relation_phrase: ['Avnet Inc is a customer of Xilinx Inc.']\n",
      "align: True\n"
     ]
    }
   ],
   "source": [
    "# discover rules by focusing on conflicts between human annotator and LLM annotation\n",
    "annotator.discover_rules(b_start=0, b_end=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate annotation with candidate definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = annotator.ground_truth.sample(1).iloc[0]\n",
    "row['idx'] = row.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = annotator.annotate_point(dict(row), candidate_definition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: ['AEROJET ROCKETDYNE HOLDINGS, INC.', 'supplier', 'NASA'] \n",
      "------------\n",
      "\n",
      "predicted: [] \n",
      "------------\n",
      "\n",
      "[{'explanation': 'AEROJET ROCKETDYNE HOLDINGS INC reports that Principal '\n",
      "                 'customers include the DoD, NASA, Boeing, Lockheed Martin, '\n",
      "                 'Orbital Sciences Corporation, Raytheon Company, and ULA.',\n",
      "  'financial_trade': [],\n",
      "  'link between span and defintion': 'The span mentions the names of companies '\n",
      "                                     'that are the principal customers of '\n",
      "                                     'AEROJET ROCKETDYNE HOLDINGS INC. These '\n",
      "                                     'companies are referred to as customers '\n",
      "                                     'because they are a source of revenue for '\n",
      "                                     'AEROJET ROCKETDYNE HOLDINGS INC.',\n",
      "  'nothing': [],\n",
      "  'relation phrase': 'AEROJET ROCKETDYNE HOLDINGS INC is a supplier of DoD, '\n",
      "                     'NASA, Boeing, Lockheed Martin, Orbital Sciences '\n",
      "                     'Corporation, Raytheon Company, and ULA',\n",
      "  'span with definition': {'definition': 'Customer companies may be referred '\n",
      "                                         'to as a source of revenue or clients '\n",
      "                                         'or customers for supplier companies',\n",
      "                           'span': 'Principal customers include the DoD, NASA, '\n",
      "                                   'Boeing, Lockheed Martin, Orbital Sciences '\n",
      "                                   'Corporation, Raytheon Company, and ULA'},\n",
      "  'supplier_and_customer': []}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(\"expected: {}\".format(row['sme_relations']), \"\\n------------\\n\")\n",
    "print(\"predicted: {}\".format(row['relations']), \"\\n------------\\n\")\n",
    "pprint(row['explanation'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate definitions out of row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-07 23:32:08,339 — 🌀 LLMInstructor — INFO — sentence: AEROJET ROCKETDYNE HOLDINGS INC reports that Principal customers include the DoD, NASA, Boeing, Lockheed Martin, Orbital Sciences Corporation, Raytheon Company, and ULA.\n",
      "definition: Supplier companies may be referred to as entities that provide goods or services to their customers.\n",
      "relation_phrase: ['AEROJET ROCKETDYNE HOLDINGS INC is a supplier of DoD, NASA, Boeing, Lockheed Martin, Orbital Sciences Corporation, Raytheon Company, and ULA.']\n",
      "align: True\n",
      "2023-10-07 23:32:13,352 — 🌀 LLMInstructor — INFO — sentence: AEROJET ROCKETDYNE HOLDINGS INC reports that Principal customers include the DoD, NASA, Boeing, Lockheed Martin, Orbital Sciences Corporation, Raytheon Company, and ULA.\n",
      "definition: Customer companies may be referred to as entities that purchase goods or services from their suppliers.\n",
      "relation_phrase: ['AEROJET ROCKETDYNE HOLDINGS INC is a supplier of DoD, NASA, Boeing, Lockheed Martin, Orbital Sciences Corporation, Raytheon Company, and ULA.']\n",
      "align: True\n"
     ]
    }
   ],
   "source": [
    "generated_definitions = annotator.extract_rules(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The loss of EchoStar or the heavy equipment OEM as a customer, a deterioration in either customer’s overall business, or a decrease in either customer’s volume of sales, could result in decreased sales for CalAmp Corp and could have a material adverse impact on CalAmp Corp ability to grow CalAmp Corp business.\"\n",
    "sentence = \"ALABAMA POWER CO reports that Southern Company's financial success is directly tied to the satisfaction of its customers\"\n",
    "sentence = \"Southern Company, Alabama Power, Georgia Power, Mississippi Power (with the exception of its cost-based MRA electric tariffs described below), and Southern Company Gas each have a diversified base of customers and no single customer or industry comprises 10% or more of each company's revenues\"\n",
    "sentence = '''As part of our merger with Spansion, we acquired agreements with Fujitsu Semiconductor Limited (\"FSL\"), XMC and SK Hynix Inc. (\"SK Hynix\"). Agreements with FSL include agreements for the supply of product wafer foundry services, sort services and assembly and test services relating to the microcontroller and analog businesses. These agreements are at competitive market rates and enable us to leverage FSL's existing manufacturing capabilities and relationships with its partners spanning across various technologies, processes, geometries and wafer sizes in their wafer fabrication facilities and package solutions in their back end manufacturing facilities, until such time that we can either move these internally to our fabrication and back end facilities or find alternative solutions. For FSL, the fabrication facilities are all located in Japan, while the back end facilities are in Japan and other Asian countries. The supply agreements do not call for any minimum purchase commitments. The arrangement with XMC provides production support for advanced NOR technology products at 65, 45 and development of 32 nanometers. The arrangement with SK Hynix provides for the development and supply of SLC NAND products at the 4x and 3x nodes.\t'''\n",
    "explanation_prompt = annotator.generate_explanation_prompt(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(self, prompt):\n",
    "    response = None\n",
    "    while not response:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4-1106-preview\",\n",
    "                messages=messages,\n",
    "                temperature=self.card['temperature'] # this is the degree of randomness of the model's output\n",
    "            )\n",
    "        except:\n",
    "            time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_prompt = '''\n",
    "Extratc the organization names as entities from the following sentence:\n",
    "\n",
    "#Instructions:\n",
    "- Explain why you extracted every entity with using the context of each entity\n",
    "\n",
    "Sentence:TRIUMPH GROUP Inc reports that Systems and Support has experienced an increase in its military end market primarily from volume on military rotorcraft, and Aerospace Structures has experienced a decrease in its military end market due to reduced volume in the C-130 program and certain military rotorcraft\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 13:06:59 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": explanation_prompt}]\n",
    "response = client.chat.completions.create(\n",
    "    model=annotator.card['model'],\n",
    "    messages=messages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "\"explanation\": \"The report mentions that as part of their merger with Spansion, they acquired agreements with Fujitsu Semiconductor Limited (FSL), XMC, and SK Hynix Inc. These agreements include supply agreements for various services and products. Therefore, the companies mentioned in the report are in a supplier and customer relation.\",\n",
      "\"span with definition\": {\"span\": \"As part of our merger with Spansion, we acquired agreements with Fujitsu Semiconductor Limited (\\\"FSL\\\"), XMC and SK Hynix Inc. (\\\"SK Hynix\\\").\", \"definition\": \"Supplier companies may be referred to as vendors or providers or sellers of services, products, or materials to customer companies.\"},\n",
      "\"link between span and defintion\": \"The report explicitly mentions that the agreements include supply agreements, which aligns with the definition of a supplier and customer relation. The companies mentioned in the report, namely FSL, XMC, and SK Hynix, are referred to as providers or sellers of services and products to the acquiring company.\",\n",
      "\"relation phrase\": \"Fujitsu Semiconductor Limited, XMC, and SK Hynix Inc. are suppliers to the acquiring company.\",\n",
      "\n",
      "'supplier_and_customer': [{'customer': 'Acquiring Company', 'supplier': ['Fujitsu Semiconductor Limited', 'XMC', 'SK Hynix Inc.']}],\n",
      "'financial_trade': [],\n",
      "'nothing': []\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Update Prompts Template_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_prompt= \"\"\"\n",
    "Your task is to create a definition from the following report which is associated with supply chain relation fact\n",
    "\n",
    "## Report\n",
    "{sentence}\n",
    "\n",
    "## Facts\n",
    "- {facts}\n",
    "\n",
    "\n",
    "\n",
    "## Output structure\n",
    "{\n",
    "\"definition 1\": <Defination can be used to indicate this relation>\n",
    "\"definition 2\": <Another definition can be used to indicate this relation menationed on the facts>\n",
    "...\n",
    "}\n",
    "\n",
    "## Rules to follow for creating output \n",
    "- Write one definition or more that can be used to describe why {facts} from the context of the Report\n",
    "- Don't include company or products names.\n",
    "- Definitions must align with the report.\n",
    "- Definition must be aplicable to descripe how {facts} based on the report\n",
    "- Definitions must be semantically close to the report\n",
    "- Phrase the definition with this intro {intro}.\n",
    "- Encapsulate your answer in 20 words or less.\n",
    "\"\"\"\n",
    "annotator.card['rule_prompt'] = rule_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_prompt= \"\"\"\n",
    "Your task is to create a definition from the following report which is associated with supply chain relation fact\n",
    "\n",
    "## Report\n",
    "{sentence}\n",
    "\n",
    "## Facts\n",
    "- {facts}\n",
    "\n",
    "\n",
    "\n",
    "## Output structure\n",
    "{\n",
    "\"definition 1\": <Defination can be used to indicate this relation>\n",
    "\"definition 2\": <Another definition can be used to describe how {facts}>\n",
    "...\n",
    "}\n",
    "\n",
    "## Rules to follow for creating output \n",
    "- Write one definition or more that can be used to describe why {facts} from the context of the Report\n",
    "- Don't include company or products names\n",
    "- Phrase the definition with this intro {intro}\n",
    "- Encapsulate your answer in 20 words or less\n",
    "\"\"\"\n",
    "annotator.card['rule_prompt'] = rule_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Explanation_prompt  ='''\n",
    "Your task is to provide explanation about the relation between companies mentioned in the report given in ``` quote.\n",
    "possible relation - {supplier, customer, financial_trade, nothing}\n",
    "\n",
    "##Report\n",
    "```\n",
    "{sentence}\n",
    "\n",
    "```\n",
    "\n",
    "## Definitions\n",
    "here is some defintions that might help to understand how to identify relation between companies\n",
    "\n",
    "{definitions}\n",
    "\n",
    "  \n",
    "## definitions to follow for creating output -\n",
    "{explanation_output_rules}\n",
    "\n",
    "\n",
    "## Output structure\n",
    "[{\n",
    "\"explanation\": explain with clarity who is supplier or customer or in financial_trade and to whom, with respect to the definitions, choose to answer with `nothing` if no definition fits with the report,\n",
    "\"span with definition\": {\"span\": span from the report that refer to certain definition, \"definition\": The exact text of definition that represent the explanation},\n",
    "\"link between span and defintion\": explain how the span and the definition are aligned with eachother,\n",
    "\"relation phrase\": Company_X is (supplier of or customer of or  in finantial_trade with or nothing) company_Y,\n",
    "'supplier_and_customer' : [ {'customer': 'company_acting_as_customer', 'supplier': 'company_acting_as_supplier'} ],\n",
    "'financial_trade': [ [company1_name, company2_name] , [company1_name, company2_name] ], \n",
    "'nothing': [ [company1_name, company2_name] , [company1_name, company2_name]]\n",
    "}]\n",
    "\n",
    "'''\n",
    "\n",
    "annotator.card['explanation_prompt'] = Explanation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explanation_prompt  ='''\n",
    "Your task is to provide explanation about the relation between companies mentioned in the report given in ``` quote.\n",
    "possible relation - {supplier, customer, financial_trade, nothing}\n",
    "\n",
    "##Report\n",
    "```\n",
    "{sentence}\n",
    "\n",
    "```\n",
    "\n",
    "## Definitions\n",
    "here is some defintions that might help to understand how to identify relation between companies\n",
    "\n",
    "{definitions}\n",
    "\n",
    "  \n",
    "## definitions to follow for creating output -\n",
    "{explanation_output_rules}\n",
    "\n",
    "\n",
    "## Output Structure\n",
    "[{\n",
    "\"explanation\": Provide a clear explanation of whether the companies are suppliers, customers, involved in financial trade, or if no definition applies to the report. Choose to answer with `nothing` if no definition fits the report.\n",
    "\"span with definition\": {\"span\": The span from the report that refers to a certain definition, \"definition\": The exact text of the definition that represents the explanation},\n",
    "\"link between span and definition\": Explain how the span and the definition align with each other,\n",
    "\"relation phrase\": Company_X is (a supplier of, a customer of, involved in financial trade with, or nothing) company_Y,\n",
    "'supplier_and_customer': [{'customer': 'company_acting_as_customer', 'supplier': 'company_acting_as_supplier'}],\n",
    "'financial_trade': [[company1_name, company2_name], [company1_name, company2_name]],\n",
    "'nothing': [[company1_name, company2_name], [company1_name, company2_name]]\n",
    "}]\n",
    "\n",
    "'''\n",
    "\n",
    "annotator.card['explanation_prompt'] = Explanation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definitions\n",
    "Here are some definitions that might help to understand how to identify the relation between companies:\n",
    "\n",
    "{definitions}\n",
    "\n",
    "\n",
    "## Definitions to Follow for Creating Output\n",
    "{explanation_output_rules}\n",
    "\n",
    "## Output Structure\n",
    "[{\n",
    "\"explanation\": Provide a clear explanation of whether the companies are suppliers, customers, involved in financial trade, or if no definition applies to the report. Choose to answer with `nothing` if no definition fits the report.\n",
    "\"span with definition\": {\"span\": The span from the report that refers to a certain definition, \"definition\": The exact text of the definition that represents the explanation},\n",
    "\"link between span and definition\": Explain how the span and the definition align with each other,\n",
    "\"relation phrase\": Company_X is (a supplier of, a customer of, involved in financial trade with, or nothing) company_Y,\n",
    "'supplier_and_customer': [{'customer': 'company_acting_as_customer', 'supplier': 'company_acting_as_supplier'}],\n",
    " 'financial_trade': [[company1_name, company2_name], [company1_name, company2_name]],\n",
    " 'nothing': [[company1_name, company2_name], [company1_name, company2_name]]\n",
    "}]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **_Write updates_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your task is to provide explanation about the relation between companies mentioned in the report given in ``` quote.\n",
      "possible relation - {supplier, customer, financial_trade, nothing}\n",
      "\n",
      "##Report\n",
      "```\n",
      "{sentence}\n",
      "\n",
      "```\n",
      "\n",
      "## Definitions\n",
      "here is some defintions that might help to understand how to identify relation between companies\n",
      "{definitions}\n",
      "\n",
      "\n",
      "## Complex definitions for financial_trade, supplier or customer relation\n",
      "- If two companies are involved in collaboration agreement or joint development, then think in following steps -\n",
      "  1. find which company is paying money to another company in joint development\n",
      "  2. if it is not clear who is paying money, then relation is financial_trade\n",
      "  3. if it is clear who is payee, the payee is customer\n",
      "\n",
      "  \n",
      "## definitions to follow for creating output -\n",
      "{explanation_output_rules}\n",
      "\n",
      "\n",
      "## Output structure\n",
      "[\n",
      "{\n",
      "\"explanation\": explain with clarity who is supplier or customer or financial_trade and to whom, with respect to the definition, choose to answer with `nothing` if no definition fits with the report \n",
      "\"span with definition\": {\"span\": the text span that indicate certain definition, \"definition\": The exact text of definition that represent the explanation}\n",
      "\"link between span and defintion\": explain how the span and the definition are aligned with eachother,\n",
      "\"relation phrase\": Company_X is (supplier of or customer of or  in finantial_trade with or nothing) company_Y ,\n",
      "'customer_supplier_relations' : [ {'is customer': 'company_acting_as_customer' or [list of companies that are customers], 'is supplier': 'company_acting_as_supplier' or [list of companies that are suppliers] } ],\n",
      "'financial_trade': [ [company1_name, company2_name] , [company1_name, company2_name] ], \n",
      "'nothing': [ [company1_name, company2_name] , [company1_name, company2_name]]}\n",
      "]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(annotator.card['explanation_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.card['explanation_prompt'] =\"\"\"\n",
    "Your task is to provide explanation about the relation between companies mentioned in the report given in ``` quote.\n",
    "possible relation - {supplier, customer, financial_trade, nothing}\n",
    "\n",
    "##Report\n",
    "```\n",
    "{sentence}\n",
    "\n",
    "```\n",
    "\n",
    "## Definitions\n",
    "here is some defintions that might help to understand how to identify relation between companies\n",
    "{definitions}\n",
    "\n",
    "\n",
    "## Complex definitions for financial_trade, supplier or customer relation\n",
    "- If two companies are involved in collaboration agreement or joint development, then think in following steps -\n",
    "  1. find which company is paying money to another company in joint development\n",
    "  2. if it is not clear who is paying money, then relation is financial_trade\n",
    "  3. if it is clear who is payee, the payee is customer\n",
    "\n",
    "  \n",
    "## definitions to follow for creating output -\n",
    "{explanation_output_rules}\n",
    "\n",
    "\n",
    "## Output structure\n",
    "[{\n",
    "\"explanation\": explain with clarity who is supplier or customer or financial_trade and to whom, with respect to the definition, choose to answer with `nothing` if no definition fits with the report \n",
    "\"span with definition\": {\"span\": the text span that indicate certain definition, \"definition\": The exact text of definition that represent the explanation}\n",
    "\"link between span and defintion\": explain how the span and the definition are aligned with eachother,\n",
    "\"relation phrase\": Company_X is (supplier of or customer of or in finantial_trade with or nothing) company_Y ,\n",
    "'customer_supplier_relations' : [ {'is customer': 'company_acting_as_customer', 'is supplier': 'company_acting_as_supplier'} ],\n",
    "'financial_trade': [ [company1_name, company2_name] , [company1_name, company2_name] ], \n",
    "'nothing': [ [company1_name, company2_name] , [company1_name, company2_name]]\n",
    "}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rule = {\"Supplier companies may be referred to as companies that are eligible for potential milestone payments and royalties based on the commercialization of products arising from research under a collaboration agreement.\":\n",
    " {\n",
    "  'source_file': str(annotator.facts_source),\n",
    "  'source_idx': 189,\n",
    "  \"source_semantic_score\": 0.7847796,\n",
    "  \"approved\":True,\n",
    "  \"type\":\"LLM\"\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################Refactor Definition File##################\n",
    "\n",
    "# f_dif = annotator.card.instructions.copy()\n",
    "# d_fs = {}\n",
    "\n",
    "# for definition in list(chain(*f_dif.values())):\n",
    "#     d_fs[definition] = {\n",
    "#         \"approved\":True,\n",
    "#         \"source_file\":\"unknown\",\n",
    "#         \"source_idx\":\"unknown\",\n",
    "#         \"source_align\":\"unknown\",\n",
    "#         \"type\":\"SME\" }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotator._definitions, 'w') as ob:\n",
    "    yaml.safe_dump(d_fs, ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(src_dir / f\"data/llms_datasets/templates/v{str(annotator.version)}/card.yaml\", 'w') as obj:\n",
    "    yaml.safe_dump(dict(annotator.card), obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(src_dir / f\"data/llms_datasets/templates/v{str(annotator.version)}/definitions.yaml\", 'w') as obj:\n",
    "    yaml.safe_dump(dict(annotator.instructions), obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting InstructorEmbedding\n",
      "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/08/2023 00:04:15 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: hkunlp/instructor-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6107caaa4845faaa7ccd91b89b9d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)62736/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b73629229e041cb95c40315b91936c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb172212553402586e5ccb873499044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/2_Dense/config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371a8cc93b5e485b85a0a7c56f9466c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7228bcb83c3943ebade0108239f2282b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)15e6562736/README.md:   0%|          | 0.00/66.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5142f04a2a9c4349a0afb8409a6617a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e6562736/config.json:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5437d4c67787434382911068bfb3ca6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82456757d0fb40e29973dd3163cc2876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c0e4474ec64b629b819e8fab69836a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6333390e50e14b469b6873dfa8637177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a54356bb1c44d6da5869a0cdbdd3e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f50c39288e468c9dc7088cf149f11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)62736/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b8a60a0a8d4b3b96d8eb26515eda98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52942b5fa77341158f583d8bf7c71119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)6562736/modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fused_layer_norm_cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mInstructorEmbedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INSTRUCTOR\n\u001b[0;32m----> 2\u001b[0m model_ins \u001b[38;5;241m=\u001b[39m \u001b[43mINSTRUCTOR\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhkunlp/instructor-base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3D ActionSLAM: wearable person tracking in multi-floor environments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m instruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepresent the Science title:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sentence_transformers/SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[1;32m     88\u001b[0m                             cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[1;32m     89\u001b[0m                             library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m                             library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[1;32m     91\u001b[0m                             ignore_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflax_model.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrust_model.ot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     92\u001b[0m                             use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/InstructorEmbedding/instructor.py:474\u001b[0m, in \u001b[0;36mINSTRUCTOR._load_sbert_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m         module_class \u001b[38;5;241m=\u001b[39m import_from_string(module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 474\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     modules[module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modules\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/InstructorEmbedding/instructor.py:306\u001b[0m, in \u001b[0;36mINSTRUCTOR_Transformer.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sbert_config_path) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[1;32m    305\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mINSTRUCTOR_Transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/InstructorEmbedding/instructor.py:240\u001b[0m, in \u001b[0;36mINSTRUCTOR_Transformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m#No max_seq_length set. Try to infer from model\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# print('max_seq_length ', max_seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sentence_transformers/models/Transformer.py:47\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the transformer model\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, T5Config):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_t5_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, config\u001b[38;5;241m=\u001b[39mconfig, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sentence_transformers/models/Transformer.py:55\u001b[0m, in \u001b[0;36mTransformer._load_t5_model\u001b[0;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5EncoderModel\n\u001b[1;32m     54\u001b[0m T5EncoderModel\u001b[38;5;241m.\u001b[39m_keys_to_ignore_on_load_unexpected \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder.*\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mT5EncoderModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py:2113\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 2113\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_no_split_modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py:1763\u001b[0m, in \u001b[0;36mT5EncoderModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1761\u001b[0m encoder_config\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m encoder_config\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1763\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mT5Stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py:843\u001b[0m, in \u001b[0;36mT5Stack.__init__\u001b[0;34m(self, config, embed_tokens)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m embed_tokens\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 843\u001b[0m     [T5Block(config, has_relative_attention_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_layers)]\n\u001b[1;32m    844\u001b[0m )\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py:843\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m embed_tokens\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 843\u001b[0m     [\u001b[43mT5Block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_layers)]\n\u001b[1;32m    844\u001b[0m )\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py:627\u001b[0m, in \u001b[0;36mT5Block.__init__\u001b[0;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList()\n\u001b[0;32m--> 627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mappend(\u001b[43mT5LayerSelfAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mappend(T5LayerCrossAttention(config))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py:558\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.__init__\u001b[0;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSelfAttention \u001b[38;5;241m=\u001b[39m T5Attention(config, has_relative_attention_bias\u001b[38;5;241m=\u001b[39mhas_relative_attention_bias)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm \u001b[38;5;241m=\u001b[39m \u001b[43mT5LayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/notebooks/inferess-relation-extraction/apex/normalization/fused_layer_norm.py:364\u001b[0m, in \u001b[0;36mFusedRMSNorm.__init__\u001b[0;34m(self, normalized_shape, eps, elementwise_affine)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m fused_layer_norm_cuda\n\u001b[0;32m--> 364\u001b[0m fused_layer_norm_cuda \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused_layer_norm_cuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(normalized_shape, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m    367\u001b[0m     normalized_shape \u001b[38;5;241m=\u001b[39m (normalized_shape,)\n",
      "File \u001b[0;32m/usr/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fused_layer_norm_cuda'"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model_ins = INSTRUCTOR('hkunlp/instructor-base')\n",
    "\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model_ins.encode([[instruction,sentence]])\n",
    "print(embeddings.shape)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)\n",
    "\n",
    "# FAISS index setup\n",
    "dimension = 768  # Instructor-XL output dimension\n",
    "index_ins = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Extract and vectorize data\n",
    "db_filename = 'arxiv-metadata-10000.json'\n",
    "num_lines = 10000\n",
    "batch_size = 4\n",
    "\n",
    "# Load all papers from JSON\n",
    "with open(db_filename, 'r') as f:\n",
    "    papers = [json.loads(line) for line in f]\n",
    "\n",
    "# Extract the papers' titles and abstracts\n",
    "texts = [f\"{paper['title']}: {paper['abstract']}\" for paper in papers]\n",
    "\n",
    "# Preparation for encoding\n",
    "instructions = [\"Represent the science titles and abstracts: \"] * len(texts)\n",
    "\n",
    "# Prepare the inputs\n",
    "inputs = [[instr, txt] for instr, txt in zip(instructions, texts)]\n",
    "\n",
    "# Create vectors using Instructor\n",
    "vectors = model_ins.encode(\n",
    "    sentences=inputs[:num_lines],\n",
    "    batch_size=batch_size,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    device=str(device)\n",
    ")\n",
    "\n",
    "# Add the vectors to the FAISS index\n",
    "index_ins.add(np.array(vectors).astype('float32'))\n",
    "\n",
    "print(f\"Added {num_lines} papers to the FAISS index.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "def search_ins(query, k=5):\n",
    "    vector = model_ins.encode([\"Represent the query to a science database: \", query])\n",
    "    _, indices = index_ins.search(np.array(vector[1]).reshape(1, -1).astype('float32'), k)\n",
    "    return indices[0]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Question: {query}\\n\")\n",
    "    line_numbers = search_ins(query, k=2)\n",
    "    print_paper_details(line_numbers)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaBase",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
