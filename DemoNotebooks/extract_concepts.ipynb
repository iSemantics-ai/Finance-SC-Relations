{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1eb4946-42ee-4848-ad71-6c4a9e00bf33",
   "metadata": {},
   "source": [
    "# **_Train Concept Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca8a65b-7618-4f90-bb6e-fde334811a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root==> /notebooks/inferess-relation-extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1975831ba641493a969c40db7c9f5672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a1b204567d4ebd9759cc58157a3910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 08:27:51,311 — SCClassifier — INFO — loading checkpoint from `concept_model`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f72ad68496748988c937ddd5f601b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/4.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba255fb5d504d0d9de132ae1d328757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/227k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe1f1a8e6d64a9e85f93f95e145021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/3.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02 08:27:56,216 — SCClassifier — INFO — inference mode...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys \n",
    "import yaml\n",
    "src_dir = Path.cwd().parent\n",
    "sys.path.append(str(src_dir))\n",
    "import pandas as pd\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from src.sc_classifier.config.core import config, PACKAGE_ROOT\n",
    "from src.sc_classifier.trainer import Trainer\n",
    "from src.sc_classifier.models import constructor\n",
    "from src.utils import dict2dot\n",
    "\n",
    "# Read params file\n",
    "with open(PACKAGE_ROOT / 'params.yaml') as o:\n",
    "    params = dict2dot(yaml.safe_load(o))\n",
    "    \n",
    "# mutate train args to fit\n",
    "config.app_config.package_name = params.concept_train.package_name\n",
    "config.train_args.load_pretrained = True \n",
    "config.model_config.target = \"concept_class\"\n",
    "config.model_config.classes = params['concept_train']['classes']\n",
    "config.train_args = params.concept_train\n",
    "config.train_args.metric_dir = \"concept_metrics\"\n",
    "config.train_args.max_stratify = 500\n",
    "config.train_args.prune_stratify = True\n",
    "trainer = Trainer(\n",
    "        loss_function=CrossEntropyLoss() , \n",
    "        optimizer=AdamW,\n",
    "        load_data=False,\n",
    "        model_name= \"concept_model\",\n",
    "        config = config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35507945-0e83-472a-8453-12a34e447344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_top2(trainer, text):\n",
    "    scores, labels = trainer.predict(text)\n",
    "    # calc concepts scores\n",
    "    classes_scores  =  list(map(lambda x: {trainer.model.config.id2label[k]:v for k,v in enumerate(x)} , scores))\n",
    "    soreted_scores = list(map(lambda x: sorted(x.items(), key=lambda x: x[1], reverse=True) , classes_scores))\n",
    "    # top_2 cocepts\n",
    "    top_2 = list(map(lambda x: (x[0][0], x[1][0]) , soreted_scores ))\n",
    "    # 1st prediction\n",
    "    predictions = list(map(lambda x: trainer.model.config.id2label[x], labels))\n",
    "    return pd.DataFrame({\"text\":text,\n",
    "                  \"predictions\":predictions,\n",
    "                  \"top_2\": top_2,\n",
    "                  \"score\":list(scores.max(1)),\n",
    "                  \"scores_dist\": soreted_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ff9a4-a723-487d-b37f-d98e89d1351c",
   "metadata": {},
   "source": [
    "# **_Read text sequences_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c4a26c-8ddc-4eb8-a37a-9bf97ddf88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_json(src_dir / \"data/train/valid.json\").drop_duplicates(['orig_sents'])['orig_sents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f9b9ee0-4b0c-443f-bd41-3dbac2bec63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.read_excel(src_dir / \"data/tasks/test_neg_relations_report_sentences.xlsx\")\n",
    "neg.dropna(inplace=True)\n",
    "neg.reset_index(drop=True, inplace=True) \n",
    "pos = pd.read_excel(src_dir / \"data/tasks/test_pos_relations_report_sentences.xlsx\")\n",
    "pos.dropna(inplace=True)\n",
    "pos.reset_index(drop=True, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d16e8c-6455-404a-b167-167fc05a1262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8d4ac-0999-4cba-a1c8-46f2f1b45cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87391340-bd3b-4bf0-8db1-6c249518d151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 592/592 [06:15<00:00,  1.58batch/s]\n"
     ]
    }
   ],
   "source": [
    "pos_preds = _predict_top2(trainer,list(pos['sentence']))\n",
    "pos['concept_class'] = pos_preds['predictions']\n",
    "pos['top2concepts'] = pos_preds['top_2']\n",
    "pos['concept_score'] = pos_preds['score']\n",
    "pos_errors = pos[pos['old_new_match'] == False]\n",
    "pos_errors_concepts  = pos_errors.concept_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67f88e84-8384-4f6e-9213-f1f5c2a8edf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8063e975-8a62-4f8c-8220-40fe074daad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9f189e5-3fe7-4b4d-9c87-377abf004889",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_preds = _predict_top2(trainer,list(neg['sentence']))\n",
    "neg['concept_class'] = neg_preds['predictions']\n",
    "neg['top2concepts'] = neg_preds['top_2']\n",
    "neg['concept_score'] = neg_preds['score']\n",
    "\n",
    "neg_errors = neg[neg['old_new_match'] == False]\n",
    "neg_errors_concepts  = neg_errors.concept_class.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "175257fe-4d6f-40c5-8427-13d8190130f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg.to_excel(src_dir / \"data/tasks/test_neg_relations_report_sentences_w_concepts.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "01f966a2-5a1a-4596-8cdf-ec53542ec8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.to_excel(src_dir / \"data/tasks/test_pos_relations_report_sentences_w_concepts.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e6306ab-d39e-44ca-b518-927112bf96e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POS: Distribution of Concepts over errors\n",
      "\n",
      "{'supply_chain': {'count': 1058, 'frac': 0.23},\n",
      " 'licensing_and_ip': {'count': 871, 'frac': 0.19},\n",
      " 'agreement_and_partnership': {'count': 706, 'frac': 0.16},\n",
      " 'unknown': {'count': 447, 'frac': 0.1},\n",
      " 'revenue': {'count': 420, 'frac': 0.09},\n",
      " 'product_related': {'count': 297, 'frac': 0.07},\n",
      " 'investment_related': {'count': 242, 'frac': 0.05},\n",
      " 'services agreement': {'count': 173, 'frac': 0.04},\n",
      " 'royalties': {'count': 97, 'frac': 0.02},\n",
      " 'financial_statements': {'count': 96, 'frac': 0.02},\n",
      " 'real_estate': {'count': 64, 'frac': 0.01},\n",
      " 'legal_and_regulatory': {'count': 54, 'frac': 0.01}}\n",
      "\n",
      "NEG: Distribution of Concepts over errors\n",
      "\n",
      "{'agreement_and_partnership': {'count': 1486, 'frac': 0.24},\n",
      " 'unknown': {'count': 818, 'frac': 0.13},\n",
      " 'revenue': {'count': 812, 'frac': 0.13},\n",
      " 'supply_chain': {'count': 740, 'frac': 0.12},\n",
      " 'licensing_and_ip': {'count': 706, 'frac': 0.11},\n",
      " 'investment_related': {'count': 343, 'frac': 0.05},\n",
      " 'services agreement': {'count': 328, 'frac': 0.05},\n",
      " 'product_related': {'count': 288, 'frac': 0.05},\n",
      " 'legal_and_regulatory': {'count': 251, 'frac': 0.04},\n",
      " 'real_estate': {'count': 209, 'frac': 0.03},\n",
      " 'financial_statements': {'count': 187, 'frac': 0.03},\n",
      " 'royalties': {'count': 128, 'frac': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(\"\\nPOS: Distribution of Concepts over errors\\n\")\n",
    "pos_dist = {k:{\"count\":x, \"frac\":round(y,2)} for k,x,y in \\\n",
    "            list(zip(pos_errors_concepts.index,\n",
    "                     pos_errors_concepts,\n",
    "                     pos_errors_concepts / len(pos_errors)))}\n",
    "\n",
    "pos_dist = dict(sorted(pos_dist.items(), key=lambda x : x[1]['count'], reverse=True))\n",
    "pprint(pos_dist,sort_dicts=False)\n",
    "\n",
    "print(\"\\nNEG: Distribution of Concepts over errors\\n\")\n",
    "neg_dist = {k:{\"count\":x, \"frac\":round(y,2)} for k,x,y in \\\n",
    "            list(zip(neg_errors_concepts.index,\n",
    "                     neg_errors_concepts,\n",
    "                     neg_errors_concepts / len(neg_errors)))}\n",
    "\n",
    "neg_dist = dict(sorted(neg_dist.items(), key=lambda x : x[1]['count'], reverse=True))\n",
    "pprint(neg_dist,sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab954e-2fe1-4f8e-8866-d32b865a5a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
